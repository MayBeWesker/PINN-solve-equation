{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59213/82325636.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:34:05.294256Z",
     "start_time": "2022-10-23T08:34:04.368778Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "plt.rcParams.update({'font.size':18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1024):\n",
    "#     random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "#     torch.use_deterministic_algorithms(True)  # 有检查操作，看下文区别\n",
    " \n",
    "seed_torch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:12:57.792915Z",
     "start_time": "2022-10-23T08:12:57.778897Z"
    }
   },
   "outputs": [],
   "source": [
    "domain = (-1, 1, -1, 1)\n",
    "xmin, xmax, ymin, ymax = domain\n",
    "mlp_layers = [2, 128, 128, 128, 128, 128, 128, 1]\n",
    "Nsd = 10000\n",
    "n_b = 128\n",
    "lr=1e-3\n",
    "adam_epoch = 25000\n",
    "lbfgs_epoch = 1000\n",
    "gamma = 0.7\n",
    "step_size = 1000\n",
    "newton_iter = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = r'./model'\n",
    "train_info_path = r'./'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:12:57.808906Z",
     "start_time": "2022-10-23T08:12:57.794910Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 3 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 81\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[1;32m     80\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DatasetAC(domain)\n\u001b[0;32m---> 81\u001b[0m X_res, X_bcs \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_res\u001b[38;5;241m.\u001b[39mshape, X_bcs\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mDatasetAC.train_data\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m         xy_res2 \u001b[38;5;241m=\u001b[39m (ub2\u001b[38;5;241m-\u001b[39mlb2)\u001b[38;5;241m*\u001b[39mlhs(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mint\u001b[39m(Nsd\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m+\u001b[39mlb2\n\u001b[1;32m     18\u001b[0m         xy_res3 \u001b[38;5;241m=\u001b[39m (ub3\u001b[38;5;241m-\u001b[39mlb3)\u001b[38;5;241m*\u001b[39mlhs(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mint\u001b[39m(Nsd\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m+\u001b[39mlb3\n\u001b[0;32m---> 20\u001b[0m         xy \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxy_res1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_res2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_res3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#         lb = np.array([-1.0, -1.0])\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         ub = np.array([1.0, 1.0])\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         xy = (ub-lb)*lhs(2, Nsd)+lb\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#         xy_bcs_y = np.concatenate([xy_bcs_4,xy_bcs_5,xy_bcs_6],0)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#         X_bcs = np.concatenate([xy_bcs_x,xy_bcs_y],0)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         bound_1 \u001b[38;5;241m=\u001b[39m lhs(\u001b[38;5;241m1\u001b[39m, n_b)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# -1 -> 0\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 3 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "class DatasetAC:\n",
    "    def __init__(self, domain):\n",
    "        self.domain = domain\n",
    "    \n",
    "    def train_data(self, verbose=None):\n",
    "        xmin, xmax, ymin, ymax = self.domain\n",
    "        # 内部点采样\n",
    "        \n",
    "        lb1 = np.array([-1., -1.])\n",
    "        ub1 = np.array([0., 0.])\n",
    "        lb2 = np.array([-1., 0.])\n",
    "        ub2 = np.array([0., 1.])\n",
    "        lb3 = np.array([0.0, -1.])\n",
    "        ub3 = np.array([1., 0.])\n",
    "\n",
    "        xy_res1 = (ub1-lb1)*lhs(2, int(Nsd/3))+lb1\n",
    "        xy_res2 = (ub2-lb2)*lhs(2, int(Nsd/3))+lb2\n",
    "        xy_res3 = (ub3-lb3)*lhs(2, int(Nsd/3))+lb3\n",
    "        print(xy_res)\n",
    "        xy = np.concatenate([xy_res1, xy_res2, xy_res3], 0)\n",
    "\n",
    "#         lb = np.array([-1.0, -1.0])\n",
    "#         ub = np.array([1.0, 1.0])\n",
    "#         xy = (ub-lb)*lhs(2, Nsd)+lb\n",
    "#         xy = xy[~((xy[:,0]>=0) * (xy[:,1]>=0))]\n",
    "        \n",
    "        # 边界点采样\n",
    "        \n",
    "#         # 对于x\n",
    "#         lb_bcs_1 = np.array([-1., -1.])\n",
    "#         ub_bcs_1 = np.array([1., -1.])\n",
    "#         lb_bcs_2 = np.array([-1., 1.])\n",
    "#         ub_bcs_2 = np.array([0.0, 1.])\n",
    "#         lb_bcs_3 = np.array([0.0, 0.0])\n",
    "#         ub_bcs_3 = np.array([1., 0.0])\n",
    "#         xy_bcs_1 = (ub_bcs_1-lb_bcs_1)*lhs(2, n_bcs)+lb_bcs_1\n",
    "#         xy_bcs_2 = (ub_bcs_2-lb_bcs_2)*lhs(2, n_bcs)+lb_bcs_2\n",
    "#         xy_bcs_3 = (ub_bcs_3-lb_bcs_3)*lhs(2, n_bcs)+lb_bcs_3\n",
    "#         xy_bcs_x = np.concatenate([xy_bcs_1,xy_bcs_2,xy_bcs_3],0)\n",
    "#         # 对于y\n",
    "#         lb_bcs_4 = np.array([-1., -1.])\n",
    "#         ub_bcs_4 = np.array([-1., 1.])\n",
    "#         lb_bcs_5 = np.array([0.0, 0.0])\n",
    "#         ub_bcs_5 = np.array([0.0, 1.])\n",
    "#         lb_bcs_6 = np.array([1., -1.])\n",
    "#         ub_bcs_6 = np.array([1., 0.0])\n",
    "#         xy_bcs_4 = (ub_bcs_4-lb_bcs_4)*lhs(2, n_bcs)+lb_bcs_4\n",
    "#         xy_bcs_5 = (ub_bcs_5-lb_bcs_5)*lhs(2, n_bcs)+lb_bcs_5\n",
    "#         xy_bcs_6 = (ub_bcs_6-lb_bcs_6)*lhs(2, n_bcs)+lb_bcs_6\n",
    "#         xy_bcs_y = np.concatenate([xy_bcs_4,xy_bcs_5,xy_bcs_6],0)\n",
    "#         X_bcs = np.concatenate([xy_bcs_x,xy_bcs_y],0)\n",
    "\n",
    "\n",
    "        bound_1 = lhs(1, n_b)-1 # -1 -> 0\n",
    "        bound_1 = bound_1.reshape(-1,1)\n",
    "        \n",
    "        bound_2 = lhs(1, n_b) # 0 -> 1\n",
    "        bound_2 = bound_2.reshape(-1,1)\n",
    "        \n",
    "        xy_b_1 = np.hstack((bound_1, bound_1*0-1))\n",
    "        xy_b_2 = np.hstack((bound_2, bound_2*0-1))\n",
    "        xy_b_3 = np.hstack((bound_1*0-1, bound_1))\n",
    "        xy_b_4 = np.hstack((bound_1*0-1, bound_2))\n",
    "        xy_b_5 = np.hstack((bound_1, bound_1*0+1))\n",
    "        xy_b_6 = np.hstack((bound_2, bound_1*0))\n",
    "        xy_b_7 = np.hstack((bound_1*0+1, bound_1))\n",
    "        xy_b_8 = np.hstack((bound_1*0, bound_2))        \n",
    "        xy_b = np.vstack([xy_b_1, xy_b_2, xy_b_3, xy_b_4, xy_b_5, xy_b_6, xy_b_7, xy_b_8])\n",
    "        \n",
    "        xy = torch.from_numpy(xy).float().to(device)\n",
    "        xy_b = torch.from_numpy(xy_b).float().to(device)\n",
    "        return xy, xy_b\n",
    "    \n",
    "    def sample_xy(self, x, y):\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        X = np.concatenate([xx.reshape((-1, 1)), yy.reshape((-1, 1))], axis=1)\n",
    "        return X\n",
    "    \n",
    "\n",
    "dataset = DatasetAC(domain)\n",
    "X_res, X_bcs = dataset.train_data()\n",
    "print(X_res.shape, X_bcs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN主干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:12:57.832911Z",
     "start_time": "2022-10-23T08:12:57.810905Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, mlp_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        for i in range(len(mlp_layers)-2):\n",
    "            layer = nn.Sequential()\n",
    "            layer.add_module(f'fc{i}', nn.Linear(mlp_layers[i], mlp_layers[i+1], bias=True))\n",
    "            layer.add_module(f'act{i}', nn.Tanh())\n",
    "            self.model.add_module(f'layer{i}', layer)\n",
    "\n",
    "        last_layer = nn.Sequential()\n",
    "        last_layer.add_module(f'fc{len(mlp_layers)-2}', nn.Linear(mlp_layers[-2], mlp_layers[-1], bias=False))\n",
    "        self.model.add_module(f'layer{len(mlp_layers)-2}', last_layer)\n",
    "        \n",
    "        for param in self.parameters():\n",
    "            if len(param.shape) > 1:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    \n",
    "backbone = MLP(mlp_layers)\n",
    "backbone.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预设的权重函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_weight_fn1(X):\n",
    "    if torch.is_tensor(X):\n",
    "        d = torch.sqrt((X[:, [0]]-1)**2 + (X[:, [1]]-1)**2)\n",
    "    else:\n",
    "        d = np.sqrt((X[:, [0]]-1)**2 + (X[:, [1]]-1)**2)\n",
    "    return -2 * d + 6.2\n",
    "\n",
    "def points_weight_fn2(X):\n",
    "    if torch.is_tensor(X):\n",
    "        d = torch.sqrt((X[:, [0]]-1)**2 + (X[:, [1]]-1)**2)\n",
    "        return 8 * torch.exp(-0.78*d)\n",
    "    else:\n",
    "        d = np.sqrt((X[:, [0]]-1)**2 + (X[:, [1]]-1)**2)\n",
    "        return 8 * np.exp(-0.78*d)\n",
    "\n",
    "def points_weight_fn3(X):\n",
    "    if torch.is_tensor(X):\n",
    "        d = torch.sqrt((X[:, [0]]-1)**2 + (X[:, [1]]-1)**2)\n",
    "    else:\n",
    "        d = np.sqrt((X[:, [0]]-1)**2 + (X[:, [1]]-1)**2)\n",
    "    return -0.3*d**2 + 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_w1 = points_weight_fn1(X_res).cpu()\n",
    "fixed_w2 = points_weight_fn2(X_res).cpu()\n",
    "fixed_w3 = points_weight_fn3(X_res).cpu()\n",
    "X_res = X_res.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X_res[:, 0], X_res[:, 1], c=fixed_w1[:, 0], cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('Fixed points weight 1')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X_res[:, 0], X_res[:, 1], c=fixed_w2[:, 0], cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('Fixed points weight 2')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X_res[:, 0], X_res[:, 1], c=fixed_w3[:, 0], cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('Fixed points weight 3')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('weight_possion_Lshape.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:12:57.855915Z",
     "start_time": "2022-10-23T08:12:57.836911Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs,\n",
    "                               grad_outputs=torch.ones_like(outputs),\n",
    "                               create_graph=True, \n",
    "                               retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:12:57.870917Z",
     "start_time": "2022-10-23T08:12:57.857916Z"
    }
   },
   "outputs": [],
   "source": [
    "class PINNAC(nn.Module):\n",
    "    def __init__(self, backbone, mu=None, sigma=None, points_weight_fn=None):\n",
    "        super(PINNAC, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.d = 0.0001\n",
    "        if mu is not None and sigma is not None:\n",
    "            self.is_inputs_normalization = True\n",
    "            self.mu = mu\n",
    "            self.sigma = sigma\n",
    "            print(f'forward with normalization, mu={self.mu.tolist()}, sigma={self.sigma.tolist()}')\n",
    "        else:\n",
    "            self.is_inputs_normalization = False\n",
    "            \n",
    "        if points_weight_fn is not None:\n",
    "            self.is_pw_fn = True\n",
    "            self.pw_fn = points_weight_fn\n",
    "        else:\n",
    "            self.is_pw_fn = False\n",
    "    \n",
    "    def forward(self, X_res, X_bcs):\n",
    "        if self.is_pw_fn:\n",
    "            pw_res = self.pw_fn(X_res)\n",
    "            pw_res.requires_grad_(False)\n",
    "            loss_res = torch.mean(self.net_f(pw_res * X_res)**2)\n",
    "        else:\n",
    "            loss_res = torch.mean(self.net_f(X_res)**2)\n",
    "        loss_bcs = torch.mean(self.net_u(X_bcs)**2)\n",
    "        return loss_res, loss_bcs\n",
    "    \n",
    "    def net_u(self, X):\n",
    "        if self.is_inputs_normalization == True:\n",
    "            X = (X - self.mu) / self.sigma\n",
    "        return self.backbone(X)\n",
    "    \n",
    "    def net_f(self, X_res):\n",
    "        X_res.requires_grad_(True)\n",
    "        u = self.net_u(X_res)\n",
    "\n",
    "        grad_u = grad(u, X_res)[0]\n",
    "        u_x = grad_u[:,[0]]\n",
    "        u_y = grad_u[:,[1]]\n",
    "        u_xx = grad(u_x, X_res)[0][:,[0]]\n",
    "        u_yy = grad(u_y, X_res)[0][:,[1]]\n",
    "\n",
    "        return 1 + u_xx + u_yy\n",
    "    \n",
    "\n",
    "pinn = PINNAC(backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-23T08:12:56.726Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "dataset = DatasetAC(domain)\n",
    "X_res, X_bcs = dataset.train_data()\n",
    "\n",
    "\n",
    "mu = X_res.mean(dim=0)\n",
    "sigma = X_res.std(dim=0)  # 求样本标准差\n",
    "\n",
    "backbone = MLP(mlp_layers)\n",
    "# 使用第一种权重生成方法\n",
    "pinn = PINNAC(backbone, mu, sigma, points_weight_fn=points_weight_fn2).to(device)\n",
    "\n",
    "optimizer_adam = optim.Adam(pinn.parameters(), lr=lr)\n",
    "# lr_sche_step = int( adam_epoch / (np.log(1e-3) / np.log(lr_sche_gamma)) )\n",
    "# print(f\"ExponentialLR, gamma: {lr_sche_gamma}, step: {lr_sche_step}\")\n",
    "lr_sche = optim.lr_scheduler.ExponentialLR(optimizer_adam, gamma=gamma, verbose=True)\n",
    "\n",
    "loss_r_log_adam = []\n",
    "loss_b_log_adam = []\n",
    "best_loss = 1e9\n",
    "\n",
    "with open(train_info_path + 'train_info.txt', 'w') as f:\n",
    "    f.write('Training by Adam:\\n')\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(adam_epoch):\n",
    "    pinn.zero_grad()\n",
    "    \n",
    "    loss_res, loss_bcs = pinn(X_res, X_bcs)\n",
    "    loss = loss_res + 100*loss_bcs\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_adam.step()\n",
    "    \n",
    "    loss_r_log_adam.append(loss_res.item())\n",
    "    loss_b_log_adam.append(loss_bcs.item())\n",
    "        \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        info = f'Epoch # {epoch+1:5d}/{adam_epoch}\\ttime:{time.time()-start_time:.1e}\\t' + \\\n",
    "            f'loss:{loss.item():.2e}, loss_r:{loss_res.item():.2e}, loss_b:{loss_bcs.item():.2e}'\n",
    "        with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "            f.write(info + '\\n')\n",
    "        print(info)\n",
    "        model_state = {'epoch': epoch+1, 'state_dict': pinn.backbone.state_dict()}\n",
    "#         backbone_path = os.path.join(model_path, f'backbone_{epoch+1}.pth')\n",
    "#         torch.save(model_state, backbone_path)\n",
    "        if loss.item() < best_loss:\n",
    "            # 保存训练loss最低的模型\n",
    "            torch.save(model_state, os.path.join(model_path, f'backbone_adam.pth'))\n",
    "            best_loss = loss.item()\n",
    "            \n",
    "    if ((epoch + 1)>5000) and ((epoch + 1)<=15000):\n",
    "        if (epoch + 1 -5000) % step_size == 0:\n",
    "            lr_sche.step()\n",
    "    if (epoch+1) % 1000 ==0:\n",
    "        X_res, X_bcs = dataset.train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu = X_res.mean(dim=0)\n",
    "sigma = X_res.std(dim=0)  # 求样本标准差\n",
    "\n",
    "backbone = MLP(mlp_layers)\n",
    "# 使用第一种权重生成方法\n",
    "pinn = PINNAC(backbone, mu, sigma).to(device)\n",
    "\n",
    "model_state = torch.load(os.path.join(model_path, 'backbone_adam.pth'))\n",
    "pinn.backbone.load_state_dict(model_state['state_dict'])\n",
    "\n",
    "optimizer_lbfgs = optim.LBFGS(pinn.backbone.parameters(), max_iter=newton_iter, line_search_fn=\"strong_wolfe\",tolerance_grad=1.e-5,lr=0.8, tolerance_change=1.e-9)\n",
    "\n",
    "loss_r_log_lbfgs = []\n",
    "loss_b_log_lbfgs = []\n",
    "it = 0\n",
    "with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "    f.write('Training by LBFGS:\\n')\n",
    "\n",
    "\n",
    "def closure():\n",
    "    global it\n",
    "    pinn.zero_grad()\n",
    "    loss_res, loss_bcs = pinn(X_res, X_bcs)\n",
    "    loss = loss_res + 100*loss_bcs\n",
    "    loss.backward()\n",
    "    it = it + 1\n",
    "    loss_r_log_lbfgs.append(loss_res.item())\n",
    "    loss_b_log_lbfgs.append(loss_bcs.item())\n",
    "    if (it + 1) % 100 == 0:\n",
    "        info = f'Iter # {it + 1:4d}' +  f'loss:{loss.item():.2e}, loss_r:{loss_res.item():.2e}, loss_b:{loss_bcs.item():.2e}'\n",
    "        with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "            f.write(info + '\\n')\n",
    "        print(info)\n",
    "        if loss.item() < best_loss:\n",
    "            # 保存训练loss最低的模型\n",
    "            torch.save(model_state, os.path.join(model_path, f'backbone_lbfgs.pth'))\n",
    "            best_loss = loss.item()\n",
    "    \n",
    "        \n",
    "    return loss\n",
    "\n",
    "for epoch in range(lbfgs_epoch):\n",
    "    optimizer_lbfgs.step(closure)\n",
    "    if (epoch+1) % 1000 ==0:\n",
    "        X_res, X_bcs = dataset.train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-23T08:12:56.729Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(111)\n",
    "plt.plot(loss_r_log_adam+loss_r_log_lbfgs, label='$loss$')\n",
    "plt.plot(loss_b_log_adam+loss_b_log_lbfgs, label='$loss$')\n",
    "plt.xlabel('epochs')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('loss_log.png', dpi=100)\n",
    "plt.show()\n",
    "plt.savefig('loss_possion_Lshape.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:39:36.964074Z",
     "start_time": "2022-10-23T08:39:36.463962Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = scipy.io.loadmat('Lpoission_more.mat')\n",
    "\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "u_star = data['z']\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_position(('data', -1))\n",
    "ax.spines['left'].set_position(('data', -1))\n",
    "plt.scatter(x, y, c=u_star, s=1, marker='.', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title(r'Reference $u(x,y)$')\n",
    "plt.tight_layout()\n",
    "\n",
    "# print(x.shape)\n",
    "# xx, yy = np.meshgrid(x, y)\n",
    "X = np.concatenate([x.reshape((-1, 1)), y.reshape((-1, 1))], axis=1)\n",
    "u_star = u_star.reshape((1, -1))\n",
    "X.shape\n",
    "u_star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-23T08:12:56.731Z"
    }
   },
   "outputs": [],
   "source": [
    "pinn.eval()\n",
    "# X = np.hstack((xx.reshape(-1,1), yy.reshape(-1,1)))\n",
    "X = torch.from_numpy(X).double()\n",
    "\n",
    "pinn.mu = pinn.mu.cpu().double()\n",
    "pinn.sigma = pinn.sigma.cpu().double()\n",
    "pinn = pinn.cpu().double()\n",
    "u_pred = pinn.net_u(X).detach().numpy()\n",
    "u_pred = u_pred.reshape(x.shape)\n",
    "\n",
    "error = np.linalg.norm(u_pred - u_star) / np.linalg.norm(u_star)\n",
    "print('Relative l2 error: {:.3e}'.format(error))\n",
    "u_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_position(('data', -1))\n",
    "ax.spines['left'].set_position(('data', -1))\n",
    "plt.scatter(x, y, c=u_pred, s=1, marker='.', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title(r'Predicted $u(x,y)$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':18})\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(18, 5))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "ax1.spines['bottom'].set_position(('data', -1))\n",
    "ax1.spines['left'].set_position(('data', -1))\n",
    "plt.scatter(x, y, c=u_star, s=1, marker='.', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title(r'Reference $u(x,y)$')\n",
    "plt.tight_layout()\n",
    "ax1.set_aspect(1./ax1.get_data_ratio())\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax2.spines['bottom'].set_position(('data', -1))\n",
    "ax2.spines['left'].set_position(('data', -1))\n",
    "plt.scatter(x, y, c=u_pred, s=1, marker='.', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title(r'Predicted $u(x,y)$')\n",
    "plt.tight_layout()\n",
    "ax2.set_aspect(1./ax2.get_data_ratio())\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['bottom'].set_visible(False)\n",
    "ax3.spines['left'].set_visible(False)\n",
    "ax3.spines['bottom'].set_position(('data', -1))\n",
    "ax3.spines['left'].set_position(('data', -1))\n",
    "plt.scatter(x, y, c=np.abs(u_star-u_pred), s=1, marker='.', cmap='jet')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0,0))\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title(r'Absolute error')\n",
    "plt.tight_layout()\n",
    "ax3.set_aspect(1./ax3.get_data_ratio())\n",
    "plt.savefig('result_possion_Lshape.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch39",
   "language": "python",
   "name": "torch39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
