{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd803e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c4ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "from pyDOE import lhs\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "plt.rcParams.update({'font.size':18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d2dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1024):\n",
    "#     random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "#     torch.use_deterministic_algorithms(True)  # 有检查操作，看下文区别\n",
    " \n",
    "seed_torch(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ecd45",
   "metadata": {},
   "source": [
    "## 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce93def",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "pf=1000;# kg/m-3\n",
    "ps=2700;\n",
    "pp=5540;\n",
    "p=1000;# 水的密度\n",
    "d31=-210e-12;\n",
    "Cp=89.5e-9;\n",
    "hp=0.3e-3;\n",
    "hs=0.15e-3;\n",
    "ha=-(hs+hp)/2;\n",
    "hb=(hs-hp)/2;\n",
    "hc=(hs+hp)/2;\n",
    "Es=70e9; # KN/m2\n",
    "Ep=15.857e9;# KN/m2\n",
    "D=16e-3;\n",
    "Lc=45e-3;\n",
    "M0=0.01;\n",
    "b=18e-3;\n",
    "L=100e-3;\n",
    "Mf=pf*pi*D**2*Lc/4+(33/140)*pi*pf*b**2*(L/4);\n",
    "M=M0+Mf;\n",
    "It=(M*(D/2)**2)/2;\n",
    "m=ps*hs*b+pp*hp*b;\n",
    "k1=0.086;# 阻尼比\n",
    "K=b*(Es*(hb**3-ha**3)+Ep*(hc**3-hb**3))/3;\n",
    "CD=2;\n",
    "C1=0.3;\n",
    "U=1;  # 速度\n",
    "lam=1;\n",
    "keci=0.3;\n",
    "A=12;\n",
    "St=0.2;\n",
    "wf=2*pi*St*U/D;\n",
    "R=0.5e6;\n",
    "\n",
    "e31=-Ep*d31;\n",
    "theta=-e31*b*(hc**2-hb**2)/(2*hp);\n",
    "lamda=0.808646;\n",
    "wn=lamda**2*(K/(m*L**4))**0.5; # 固有频率\n",
    "\n",
    "#f_L=double(subs(f,x,L));\n",
    "#df_L=double(subs(df,x,L));\n",
    "#fi=(f_L+0.5*D*df_L);\n",
    "f_L=-6.1894;\n",
    "df_L=-92.8022;\n",
    "fi=-6.9318;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211dfbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = (0, 1.5, -0.0025, 0.0025)\n",
    "tmin, tmax, xmin, xmax = domain\n",
    "backbone_layers = [2] + [20]*4 + [1]\n",
    "# nn_lam_layers = [1] + [20]*3 + [2]\n",
    "adam_iters = 20000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = r'./model'\n",
    "train_info_path = r'./'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189dba40",
   "metadata": {},
   "source": [
    "## 数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63f7fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2, 5) (100, 2, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, domain):\n",
    "        self.domain = domain\n",
    "    \n",
    "    def train_data(self, verbose=None):\n",
    "        tmin, tmax, xmin, xmax = self.domain\n",
    "        # 内部点采样\n",
    "        t_res = np.linspace(tmin, tmax, 50)\n",
    "        x_res = np.linspace(xmin, xmax, 80)\n",
    "        X_res = self.sample_xy(t_res, x_res)\n",
    "        \n",
    "        X_res = np.expand_dims(X_res, axis=2)\n",
    "        X_res = np.repeat(X_res,5,axis=2)\n",
    "        \n",
    "        # 初始点采样\n",
    "        X_ics =self.sample_xy(np.array([tmin]), np.linspace(xmin, xmax, 100))\n",
    "#         X_ics = np.concatenate([X_ics, self.sample_xy(np.array([tmin]), np.linspace(xmin,xmax,100))], axis=0)\n",
    "        X_ics = np.expand_dims(X_ics, axis=2)\n",
    "        X_ics = np.repeat(X_ics,5,axis=2)\n",
    "        return X_res, X_ics\n",
    "    \n",
    "    def sample_xy(self, x, y):\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        X = np.concatenate([xx.reshape((-1, 1)), yy.reshape((-1, 1))], axis=1)\n",
    "        return X\n",
    "\n",
    "    \n",
    "dataset = Dataset(domain)\n",
    "X_res, X_ics = dataset.train_data()\n",
    "# X_res_1 = X_res_2 =X_res_3 =X_res_4 =X_res_5 =X_res\n",
    "print(X_res.shape, X_ics.shape)\n",
    "X_res[:,1].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02b722",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852c7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, mlp_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        for i in range(len(mlp_layers)-2):\n",
    "            layer = nn.Sequential()\n",
    "            layer.add_module(f'fc{i}', nn.Linear(mlp_layers[i], mlp_layers[i+1], bias=True))\n",
    "            layer.add_module(f'act{i}', nn.Tanh())\n",
    "            self.model.add_module(f'layer{i}', layer)\n",
    "\n",
    "        last_layer = nn.Sequential()\n",
    "        last_layer.add_module(f'fc{len(mlp_layers)-2}', nn.Linear(mlp_layers[-2], mlp_layers[-1], bias=False))\n",
    "        self.model.add_module(f'layer{len(mlp_layers)-2}', last_layer)\n",
    "        \n",
    "#         for param in self.parameters():\n",
    "#             if len(param.shape) > 1:\n",
    "#                 nn.init.kaiming_normal_(param)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "backbone1 = MLP(backbone_layers)\n",
    "backbone2 = MLP(backbone_layers)\n",
    "backbone3 = MLP(backbone_layers)\n",
    "backbone4 = MLP(backbone_layers)\n",
    "backbone5 = MLP(backbone_layers)\n",
    "\n",
    "# nn_lam = MLP(nn_lam_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5963b8",
   "metadata": {},
   "source": [
    "## 主干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf72473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs,\n",
    "                               grad_outputs=torch.ones_like(outputs),\n",
    "                               create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebf1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, backbone1, backbone2, backbone3, backbone4, backbone5, mu=None, sigma=None):\n",
    "        super(PINN, self).__init__()\n",
    "        self.backbone1 = backbone1\n",
    "        self.backbone2 = backbone2\n",
    "        self.backbone3 = backbone3\n",
    "        self.backbone4 = backbone4\n",
    "        self.backbone5 = backbone5\n",
    "\n",
    "    def forward(self, X_res, X_ics):\n",
    "        \n",
    "        loss_res_1 = torch.mean(self.net_E1(X_res)** 2)\n",
    "        loss_res_2 = torch.mean(self.net_E2(X_res)** 2)\n",
    "        loss_res_3 = torch.mean(self.net_E3(X_res)** 2)\n",
    "        loss_res_4 = torch.mean(self.net_E4(X_res)** 2)\n",
    "        loss_res_5 = torch.mean(self.net_E5(X_res)** 2)\n",
    "        loss_ics = torch.mean(self.net_ics(X_ics)**2)\n",
    "        return loss_res_1, loss_res_2, loss_res_3, loss_res_4, loss_res_5, loss_ics \n",
    "\n",
    "    def net_pred1(self, X):\n",
    "        return self.backbone1(X)\n",
    "    \n",
    "    def net_pred2(self, X):\n",
    "        return self.backbone2(X)\n",
    "    \n",
    "    def net_pred3(self, X):\n",
    "        return self.backbone3(X)\n",
    "    \n",
    "    def net_pred4(self, X):\n",
    "        return self.backbone4(X)\n",
    "    \n",
    "    def net_pred5(self, X):\n",
    "        return self.backbone5(X)\n",
    "    \n",
    "    def net_X_res_pred(self, X):\n",
    "        X1_star = X[:,:,0]\n",
    "        X2_star = X[:,:,1]\n",
    "        X3_star = X[:,:,2]\n",
    "        X4_star = X[:,:,3]\n",
    "        X5_star = X[:,:,4]\n",
    "        \n",
    "        X1_star.requires_grad_(True)\n",
    "        X2_star.requires_grad_(True)\n",
    "        X3_star.requires_grad_(True)\n",
    "        X4_star.requires_grad_(True)\n",
    "        X5_star.requires_grad_(True)\n",
    "        \n",
    "        X1 = self.net_pred1(X1_star)\n",
    "        X2 = self.net_pred2(X2_star)\n",
    "        X3 = self.net_pred3(X3_star)\n",
    "        X4 = self.net_pred4(X4_star)\n",
    "        X5 = self.net_pred5(X5_star)\n",
    "        return X1,X2,X3,X4,X5\n",
    "        \n",
    "\n",
    "    def net_E1(self, X):\n",
    "        X.requires_grad_(True)\n",
    "        \n",
    "        X1_star = X[:,:,0]\n",
    "        X2_star = X[:,:,1]\n",
    "        X1_star.requires_grad_(True)\n",
    "        X2_star.requires_grad_(True)\n",
    "        \n",
    "        X1 = self.net_pred1(X1_star)\n",
    "        X2 = self.net_pred2(X2_star)\n",
    "\n",
    "        grad_X1 = grad(X1, X1_star)[0]\n",
    "        X1_pred_t = grad_X1[:, [0]]\n",
    "        \n",
    "        return X1_pred_t - X2  \n",
    "    \n",
    "    def net_E2(self,X):\n",
    "        X1_star = X[:,:,0]\n",
    "        X2_star = X[:,:,1]\n",
    "        X3_star = X[:,:,2]\n",
    "        X4_star = X[:,:,3]\n",
    "        X5_star = X[:,:,4]\n",
    "        \n",
    "        X1_star.requires_grad_(True)\n",
    "        X2_star.requires_grad_(True)\n",
    "        X3_star.requires_grad_(True)\n",
    "        X5_star.requires_grad_(True)\n",
    "\n",
    "        X1 = self.net_pred1(X1_star)\n",
    "        X2 = self.net_pred2(X2_star)\n",
    "        X3 = self.net_pred3(X3_star)\n",
    "        X5 = self.net_pred5(X5_star)\n",
    "        \n",
    "        grad_X = grad(X2, X2_star)[0]\n",
    "        X2_pred_t = grad_X[:, [0]]\n",
    "        \n",
    "        return X2_pred_t + (2*k1*wn+0.5*CD*p*D*U*Lc*fi**2)*X2-wn**2*X1-theta*df_L*X5+0.25*C1*p*D*U**2*Lc*fi*X3\n",
    "    \n",
    "    def net_E3(self, X):\n",
    "        X1_star = X[:,:,0]\n",
    "        X2_star = X[:,:,1]\n",
    "        X3_star = X[:,:,2]\n",
    "        X4_star = X[:,:,3]\n",
    "        X5_star = X[:,:,4]\n",
    "        \n",
    "        X1_star.requires_grad_(True)\n",
    "        X3_star.requires_grad_(True)\n",
    "        \n",
    "        X3 = self.net_pred3(X3_star)\n",
    "        X4 = self.net_pred4(X4_star)\n",
    "        \n",
    "        grad_X = grad(X3, X3_star)[0]\n",
    "        X3_pred_t = grad_X[:, [0]]\n",
    "        return X3_pred_t-X4\n",
    "    \n",
    "    def net_E4(self, X):\n",
    "        X1_star = X[:,:,0]\n",
    "        X2_star = X[:,:,1]\n",
    "        X3_star = X[:,:,2]\n",
    "        X4_star = X[:,:,3]\n",
    "        X5_star = X[:,:,4]\n",
    "        \n",
    "        X4_star.requires_grad_(True)\n",
    "        X1 = self.net_pred1(X1_star)\n",
    "        X2 = self.net_pred2(X2_star)\n",
    "        X3 = self.net_pred3(X3_star)\n",
    "        X4 = self.net_pred4(X4_star)\n",
    "        X5 = self.net_pred5(X5_star)\n",
    "        \n",
    "        grad_X = grad(X4, X4_star)[0]\n",
    "        X4_pred_t = grad_X[:, [0]]\n",
    "        \n",
    "        return X4_pred_t - (-lam*keci*wf*(X3)**2*X4+lam*keci*wf*X4-wf**2*X3+A/D*fi*(-(2*k1*wn+0.5*CD*p*D*U*Lc*fi**2)*X2-wn**2*X1-theta*df_L*X5+0.25*C1*p*D*U**2*Lc*fi*X3))\n",
    "    \n",
    "    def net_E5(self,X):\n",
    "        X1_star = X[:,:,0]\n",
    "        X2_star = X[:,:,1]\n",
    "        X3_star = X[:,:,2]\n",
    "        X4_star = X[:,:,3]\n",
    "        X5_star = X[:,:,4]\n",
    "        \n",
    "        X4_star.requires_grad_(True)\n",
    "        X2 = self.net_pred2(X2_star)\n",
    "        X5 = self.net_pred5(X5_star)\n",
    "        \n",
    "        grad_X = grad(X5, X5_star)[0]\n",
    "        X5_pred_t = grad_X[:, [0]]\n",
    "        \n",
    "        return X5_pred_t-((-X5/R+theta*df_L*X2)/Cp)\n",
    "        \n",
    "    def net_ics(self,X):\n",
    "        X1 = X[:,1,0]\n",
    "        X2 = X[:,1,1:]\n",
    "        X1 = np.add(X1, -np.ones((X1.shape))*0.0002).reshape((-1,1))\n",
    "        X_ics = torch.cat((X1,X2),1)\n",
    "        return X_ics\n",
    "        \n",
    "pinn = PINN(backbone_layers,backbone_layers,backbone_layers,backbone_layers,backbone_layers)\n",
    "# pinn.net_E1(torch.tensor(X_res_1),torch.tensor(X_res_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948e16f",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75b7c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #    500/20000\tloss:1.82e+06, loss_r_1:4.74e-03, loss_r_2:2.93e+01, loss_r_3:1.21e-03,loss_r_4:3.50e+03,loss_r_5:1.47e+04 loss_i:2.13e-06  Valid # loss:6.99e+03, loss_r:4.74e-03, loss_i:2.13e-06\n",
      "Iter #   1000/20000\tloss:4.37e+05, loss_r_1:4.46e-03, loss_r_2:2.76e+01, loss_r_3:1.19e-03,loss_r_4:6.98e+02,loss_r_5:3.65e+03 loss_i:2.13e-06  Valid # loss:1.42e+03, loss_r:4.46e-03, loss_i:2.13e-06\n",
      "Iter #   1500/20000\tloss:3.74e+05, loss_r_1:4.41e-03, loss_r_2:2.73e+01, loss_r_3:1.18e-03,loss_r_4:5.75e+02,loss_r_5:3.14e+03 loss_i:2.13e-06  Valid # loss:1.18e+03, loss_r:4.41e-03, loss_i:2.13e-06\n",
      "Iter #   2000/20000\tloss:3.37e+05, loss_r_1:4.42e-03, loss_r_2:2.73e+01, loss_r_3:1.16e-03,loss_r_4:5.06e+02,loss_r_5:2.84e+03 loss_i:2.13e-06  Valid # loss:1.04e+03, loss_r:4.42e-03, loss_i:2.13e-06\n",
      "Iter #   2500/20000\tloss:2.96e+05, loss_r_1:4.35e-03, loss_r_2:2.67e+01, loss_r_3:1.09e-03,loss_r_4:5.65e+02,loss_r_5:2.37e+03 loss_i:2.13e-06  Valid # loss:1.37e+03, loss_r:4.35e-03, loss_i:2.13e-06\n",
      "Iter #   3000/20000\tloss:2.61e+05, loss_r_1:4.24e-03, loss_r_2:2.60e+01, loss_r_3:9.69e-04,loss_r_4:6.53e+02,loss_r_5:1.93e+03 loss_i:2.13e-06  Valid # loss:1.33e+03, loss_r:4.24e-03, loss_i:2.13e-06\n",
      "Iter #   3500/20000\tloss:1.59e+05, loss_r_1:3.97e-03, loss_r_2:2.44e+01, loss_r_3:7.75e-04,loss_r_4:9.50e+02,loss_r_5:6.16e+02 loss_i:2.13e-06  Valid # loss:1.92e+03, loss_r:3.97e-03, loss_i:2.13e-06\n",
      "Iter #   4000/20000\tloss:1.09e+05, loss_r_1:3.88e-03, loss_r_2:2.38e+01, loss_r_3:7.63e-04,loss_r_4:7.89e+02,loss_r_5:2.79e+02 loss_i:2.13e-06  Valid # loss:1.60e+03, loss_r:3.88e-03, loss_i:2.13e-06\n",
      "Iter #   4500/20000\tloss:2.12e+09, loss_r_1:3.59e-03, loss_r_2:3.10e+01, loss_r_3:6.34e-04,loss_r_4:2.12e+07,loss_r_5:2.54e+02 loss_i:2.13e-06  Valid # loss:1.17e+07, loss_r:3.83e-03, loss_i:2.13e-06\n",
      "Iter #   5000/20000\tloss:3.93e+08, loss_r_1:3.67e-03, loss_r_2:1.91e+01, loss_r_3:6.50e-04,loss_r_4:3.93e+06,loss_r_5:6.98e+01 loss_i:2.13e-06  Valid # loss:2.10e+06, loss_r:3.57e-03, loss_i:2.13e-06\n",
      "Iter #   5500/20000\tloss:1.13e+05, loss_r_1:3.46e-03, loss_r_2:2.12e+01, loss_r_3:5.27e-04,loss_r_4:1.08e+03,loss_r_5:2.90e+01 loss_i:2.13e-06  Valid # loss:2.11e+03, loss_r:3.46e-03, loss_i:2.13e-06\n",
      "Iter #   6000/20000\tloss:1.29e+05, loss_r_1:3.30e-03, loss_r_2:2.03e+01, loss_r_3:4.40e-04,loss_r_4:1.25e+03,loss_r_5:1.48e+01 loss_i:2.13e-06  Valid # loss:2.36e+03, loss_r:3.31e-03, loss_i:2.13e-06\n",
      "Iter #   6500/20000\tloss:5.08e+08, loss_r_1:3.23e-03, loss_r_2:1.62e+01, loss_r_3:3.97e-04,loss_r_4:5.08e+06,loss_r_5:1.62e+01 loss_i:2.13e-06  Valid # loss:5.11e+06, loss_r:3.11e-03, loss_i:2.13e-06\n",
      "Iter #   7000/20000\tloss:9.21e+04, loss_r_1:3.14e-03, loss_r_2:1.93e+01, loss_r_3:3.53e-04,loss_r_4:8.95e+02,loss_r_5:5.84e+00 loss_i:2.13e-06  Valid # loss:1.81e+03, loss_r:3.14e-03, loss_i:2.13e-06\n",
      "Iter #   7500/20000\tloss:8.51e+04, loss_r_1:3.04e-03, loss_r_2:1.87e+01, loss_r_3:3.03e-04,loss_r_4:8.30e+02,loss_r_5:2.59e+00 loss_i:2.13e-06  Valid # loss:1.68e+03, loss_r:3.04e-03, loss_i:2.13e-06\n",
      "Iter #   8000/20000\tloss:4.20e+05, loss_r_1:2.98e-03, loss_r_2:1.82e+01, loss_r_3:2.71e-04,loss_r_4:4.18e+03,loss_r_5:1.55e+00 loss_i:2.13e-06  Valid # loss:1.18e+04, loss_r:2.98e-03, loss_i:2.13e-06\n",
      "Iter #   8500/20000\tloss:5.87e+08, loss_r_1:3.03e-03, loss_r_2:1.48e+01, loss_r_3:2.74e-04,loss_r_4:5.87e+06,loss_r_5:4.17e+00 loss_i:2.13e-06  Valid # loss:3.90e+06, loss_r:2.91e-03, loss_i:2.13e-06\n",
      "Iter #   9000/20000\tloss:9.48e+06, loss_r_1:2.89e-03, loss_r_2:1.73e+01, loss_r_3:2.14e-04,loss_r_4:9.48e+04,loss_r_5:2.08e+00 loss_i:2.13e-06  Valid # loss:7.09e+04, loss_r:2.89e-03, loss_i:2.13e-06\n",
      "Iter #   9500/20000\tloss:3.72e+04, loss_r_1:2.88e-03, loss_r_2:1.77e+01, loss_r_3:2.07e-04,loss_r_4:3.53e+02,loss_r_5:9.58e-01 loss_i:2.13e-06  Valid # loss:7.24e+02, loss_r:2.88e-03, loss_i:2.13e-06\n",
      "Iter #  10000/20000\tloss:2.74e+04, loss_r_1:2.86e-03, loss_r_2:1.75e+01, loss_r_3:1.84e-04,loss_r_4:2.56e+02,loss_r_5:5.16e-01 loss_i:2.13e-06  Valid # loss:5.30e+02, loss_r:2.86e-03, loss_i:2.13e-06\n",
      "Iter #  10500/20000\tloss:1.89e+04, loss_r_1:2.85e-03, loss_r_2:1.75e+01, loss_r_3:1.69e-04,loss_r_4:1.71e+02,loss_r_5:4.75e-01 loss_i:2.13e-06  Valid # loss:3.58e+02, loss_r:2.85e-03, loss_i:2.13e-06\n",
      "Iter #  11000/20000\tloss:1.37e+04, loss_r_1:2.85e-03, loss_r_2:1.75e+01, loss_r_3:1.50e-04,loss_r_4:1.19e+02,loss_r_5:4.57e-01 loss_i:2.13e-06  Valid # loss:2.42e+02, loss_r:2.85e-03, loss_i:2.13e-06\n",
      "Iter #  11500/20000\tloss:7.96e+03, loss_r_1:2.85e-03, loss_r_2:1.75e+01, loss_r_3:1.39e-04,loss_r_4:6.17e+01,loss_r_5:4.83e-01 loss_i:2.13e-06  Valid # loss:1.41e+02, loss_r:2.85e-03, loss_i:2.13e-06\n",
      "Iter #  12000/20000\tloss:3.63e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.11e-04,loss_r_4:1.75e+01,loss_r_5:9.46e-01 loss_i:2.13e-06  Valid # loss:5.29e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  12500/20000\tloss:3.30e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.11e-04,loss_r_4:1.45e+01,loss_r_5:6.29e-01 loss_i:2.13e-06  Valid # loss:4.69e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  13000/20000\tloss:3.11e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.10e-04,loss_r_4:1.27e+01,loss_r_5:4.84e-01 loss_i:2.13e-06  Valid # loss:4.33e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  13500/20000\tloss:2.96e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.10e-04,loss_r_4:1.13e+01,loss_r_5:4.19e-01 loss_i:2.13e-06  Valid # loss:4.05e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  14000/20000\tloss:2.85e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.10e-04,loss_r_4:1.03e+01,loss_r_5:3.71e-01 loss_i:2.13e-06  Valid # loss:3.85e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  14500/20000\tloss:2.79e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.10e-04,loss_r_4:9.73e+00,loss_r_5:3.19e-01 loss_i:2.13e-06  Valid # loss:3.73e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  15000/20000\tloss:2.75e+03, loss_r_1:2.92e-03, loss_r_2:1.78e+01, loss_r_3:1.10e-04,loss_r_4:9.41e+00,loss_r_5:2.64e-01 loss_i:2.13e-06  Valid # loss:3.66e+01, loss_r:2.92e-03, loss_i:2.13e-06\n",
      "Iter #  15500/20000\tloss:1.25e+05, loss_r_1:3.03e-03, loss_r_2:1.85e+01, loss_r_3:9.31e-05,loss_r_4:1.22e+03,loss_r_5:2.69e+00 loss_i:2.13e-06  Valid # loss:2.45e+03, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  16000/20000\tloss:2.41e+04, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.26e-05,loss_r_4:2.20e+02,loss_r_5:2.07e+00 loss_i:2.13e-06  Valid # loss:4.58e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  16500/20000\tloss:2.11e+04, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.29e-05,loss_r_4:1.91e+02,loss_r_5:1.67e+00 loss_i:2.13e-06  Valid # loss:4.00e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  17000/20000\tloss:1.82e+04, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.33e-05,loss_r_4:1.63e+02,loss_r_5:1.29e+00 loss_i:2.13e-06  Valid # loss:3.44e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  17500/20000\tloss:1.52e+04, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.39e-05,loss_r_4:1.33e+02,loss_r_5:9.51e-01 loss_i:2.13e-06  Valid # loss:2.84e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  18000/20000\tloss:1.21e+04, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.44e-05,loss_r_4:1.02e+02,loss_r_5:6.74e-01 loss_i:2.13e-06  Valid # loss:2.23e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  18500/20000\tloss:9.20e+03, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.50e-05,loss_r_4:7.31e+01,loss_r_5:4.62e-01 loss_i:2.13e-06  Valid # loss:1.64e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  19000/20000\tloss:6.65e+03, loss_r_1:3.03e-03, loss_r_2:1.84e+01, loss_r_3:9.55e-05,loss_r_4:4.77e+01,loss_r_5:3.11e-01 loss_i:2.13e-06  Valid # loss:1.14e+02, loss_r:3.03e-03, loss_i:2.13e-06\n",
      "Iter #  19500/20000\tloss:1.10e+04, loss_r_1:3.06e-03, loss_r_2:1.86e+01, loss_r_3:8.59e-05,loss_r_4:9.10e+01,loss_r_5:7.79e-02 loss_i:2.13e-06  Valid # loss:2.01e+02, loss_r:3.06e-03, loss_i:2.13e-06\n",
      "Iter #  20000/20000\tloss:7.46e+03, loss_r_1:3.06e-03, loss_r_2:1.86e+01, loss_r_3:8.67e-05,loss_r_4:5.59e+01,loss_r_5:8.03e-02 loss_i:2.13e-06  Valid # loss:1.30e+02, loss_r:3.06e-03, loss_i:2.13e-06\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(domain)\n",
    "X_res, X_ics = dataset.train_data()\n",
    "X_res = torch.from_numpy(X_res).float().to(device)\n",
    "X_ics = torch.from_numpy(X_ics).float().to(device)\n",
    "\n",
    "mu = X_res.mean(dim=0)\n",
    "sigma = X_res.std(dim=0)  # 求样本标准差\n",
    "\n",
    "backbone1 = MLP(backbone_layers)  # 主干网络\n",
    "backbone2 = MLP(backbone_layers)\n",
    "backbone3 = MLP(backbone_layers)\n",
    "backbone4 = MLP(backbone_layers)\n",
    "backbone5 = MLP(backbone_layers)\n",
    "pinn = PINN(backbone1, backbone2, backbone3, backbone4, backbone5, mu, sigma).to(device)\n",
    "\n",
    "optimizer_adam = optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "\n",
    "lr_sche = optim.lr_scheduler.ExponentialLR(optimizer_adam, gamma=0.8)  # 指数衰减学习率\n",
    "logger = {\n",
    "    \"loss\": [], \n",
    "    \"loss_res_1\": [],\n",
    "    \"loss_res_2\": [],\n",
    "    \"loss_res_3\": [],\n",
    "    \"loss_res_4\": [],\n",
    "    \"loss_res_5\": [],\n",
    "    \"loss_ics\": [],\n",
    "    \"iter\": [],\n",
    "    \"mu\": mu,\n",
    "    \"sigma\": sigma\n",
    "}\n",
    "best_loss = 1e9\n",
    "\n",
    "# 训练\n",
    "start_time = time.time()\n",
    "for it in range(adam_iters):\n",
    "    # 计算loss并更新网络 -------\n",
    "    pinn.train()\n",
    "    pinn.zero_grad()\n",
    "    \n",
    "    loss_res_1, loss_res_2, loss_res_3, loss_res_4, loss_res_5, loss_ics   = pinn(X_res, X_ics)\n",
    "    loss = loss_res_1 + 100*loss_res_2 + loss_res_3 + 100*loss_res_4 + 100*loss_res_5 + loss_ics \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_adam.step()\n",
    "#     optimizer_adam_lam.step()\n",
    "    # 计算loss并更新网络 -------\n",
    "    \n",
    "    \n",
    "    if (it + 1) % 100 == 0:\n",
    "        # 保存loss信息\n",
    "        pinn.train(False)\n",
    "        loss_res_1_valid, loss_res_2_valid, loss_res_3_valid, loss_res_4_valid, loss_res_5_valid, loss_ics_valid  = pinn(X_res, X_ics)\n",
    "        loss_valid = loss_res_1_valid + loss_res_2_valid + loss_res_3_valid + loss_res_4_valid + loss_res_4_valid + loss_ics_valid\n",
    "        \n",
    "        logger[\"loss\"].append(loss_valid.item())\n",
    "        logger[\"loss_res_1\"].append(loss_res_1_valid.item())\n",
    "        logger[\"loss_res_2\"].append(loss_res_2_valid.item())\n",
    "        logger[\"loss_res_3\"].append(loss_res_3_valid.item())\n",
    "        logger[\"loss_res_4\"].append(loss_res_4_valid.item())\n",
    "        logger[\"loss_res_5\"].append(loss_res_5_valid.item())\n",
    "        logger[\"loss_ics\"].append(loss_ics_valid.item())\n",
    "        logger[\"iter\"].append(it+1)\n",
    "        \n",
    "        # 保存训练loss最低的模型\n",
    "        if loss_valid.item() < best_loss:\n",
    "            model_state = {'iter': it+1, 'backbone_state': pinn.state_dict()}\n",
    "            torch.save(model_state, os.path.join(model_path, 'pinn_adam.pth'))\n",
    "            best_loss = loss_valid.item()\n",
    "        \n",
    "        if (it + 1) % 500 == 0:\n",
    "            # 保存并打印训练日志\n",
    "            info = f'Iter # {it+1:6d}/{adam_iters}\\t' + \\\n",
    "                f'loss:{loss.item():.2e}, loss_r_1:{loss_res_1.item():.2e}, loss_r_2:{loss_res_2.item():.2e}, loss_r_3:{loss_res_3.item():.2e},loss_r_4:{loss_res_4.item():.2e},loss_r_5:{loss_res_5.item():.2e} loss_i:{loss_ics.item():.2e}  ' + \\\n",
    "                f'Valid # loss:{loss_valid.item():.2e}, loss_r:{loss_res_1_valid.item():.2e}, loss_i:{loss_ics_valid.item():.2e}'\n",
    "            with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "                f.write(info + '\\n')\n",
    "            print(info)\n",
    "            \n",
    "        # 衰减学习率\n",
    "        if (it + 1) % 4000 == 0:\n",
    "            lr_sche.step()\n",
    "#             lr_sche_lam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e0cea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iter': 15200,\n",
       " 'backbone_state': OrderedDict([('backbone1.model.layer0.fc0.weight',\n",
       "               tensor([[-0.0358,  0.0177],\n",
       "                       [-0.0798, -0.2192],\n",
       "                       [-0.0641, -0.3130],\n",
       "                       [-0.4999,  0.3371],\n",
       "                       [ 0.5578,  0.5608],\n",
       "                       [ 0.2956,  0.2098],\n",
       "                       [-0.3711, -0.4889],\n",
       "                       [-0.3028,  0.6162],\n",
       "                       [ 0.2283,  0.5697],\n",
       "                       [ 0.0756, -0.3372],\n",
       "                       [ 0.4132, -0.7416],\n",
       "                       [ 0.1312,  0.3682],\n",
       "                       [-0.3563, -0.0512],\n",
       "                       [ 0.4759,  0.6426],\n",
       "                       [-0.0650, -0.5644],\n",
       "                       [ 0.1938, -0.4770],\n",
       "                       [ 0.1055,  0.4573],\n",
       "                       [-0.1772,  0.3956],\n",
       "                       [ 0.0442, -0.5170],\n",
       "                       [-0.5771, -0.2005]])),\n",
       "              ('backbone1.model.layer0.fc0.bias',\n",
       "               tensor([ 0.1365, -0.1183,  0.2049,  0.3222,  0.3024, -0.3949, -0.5063,  0.2076,\n",
       "                        0.4922, -0.2850, -0.3757, -0.3388, -0.3099,  0.0494, -0.4025, -0.5021,\n",
       "                        0.1179, -0.1316,  0.5141,  0.3972])),\n",
       "              ('backbone1.model.layer1.fc1.weight',\n",
       "               tensor([[-0.1384,  0.2081, -0.1984, -0.0521,  0.1927,  0.0682,  0.1501, -0.0037,\n",
       "                        -0.0685,  0.0691, -0.0936, -0.0196,  0.0727, -0.0603,  0.1148, -0.0808,\n",
       "                        -0.2086, -0.0688,  0.0907, -0.0105],\n",
       "                       [ 0.1753, -0.0140,  0.1059, -0.0731,  0.2249,  0.0645, -0.2134,  0.1467,\n",
       "                         0.0057, -0.2381,  0.1219, -0.2086,  0.1480, -0.0519,  0.0033,  0.1760,\n",
       "                        -0.0503, -0.1293, -0.2045,  0.1880],\n",
       "                       [ 0.0341,  0.0162, -0.2023,  0.1677,  0.0542, -0.1680,  0.1374,  0.1058,\n",
       "                        -0.0322, -0.0123,  0.1436,  0.0185,  0.1067, -0.1967,  0.0176, -0.0365,\n",
       "                         0.1051,  0.0177, -0.2039, -0.1378],\n",
       "                       [ 0.1031, -0.0823,  0.0656,  0.2415,  0.0809,  0.2149,  0.1245, -0.1477,\n",
       "                        -0.0174,  0.0191, -0.1401, -0.0009, -0.0241,  0.1513, -0.0276, -0.0269,\n",
       "                         0.1525,  0.0719, -0.0161,  0.2541],\n",
       "                       [-0.1968,  0.1648,  0.0137,  0.1075,  0.1378,  0.0703, -0.1149, -0.2040,\n",
       "                        -0.0949,  0.0760,  0.2202,  0.0953,  0.0965, -0.1397, -0.0715, -0.0446,\n",
       "                        -0.0887, -0.0404, -0.0904, -0.0149],\n",
       "                       [ 0.1280, -0.2012,  0.2219,  0.0465,  0.1169,  0.0253, -0.1375,  0.0384,\n",
       "                         0.1587, -0.1282, -0.1985, -0.0164,  0.0645,  0.0909,  0.0959,  0.0245,\n",
       "                         0.0074,  0.2122, -0.1254, -0.1489],\n",
       "                       [ 0.2438, -0.0784, -0.1660, -0.1561,  0.1380, -0.0579, -0.1724, -0.1939,\n",
       "                        -0.1756, -0.2440,  0.0655,  0.0952, -0.0248, -0.1262,  0.0666,  0.0238,\n",
       "                        -0.0289, -0.0728,  0.2368,  0.1163],\n",
       "                       [-0.0796, -0.1838, -0.2191,  0.0143,  0.0841, -0.2173, -0.1937, -0.0909,\n",
       "                        -0.2142,  0.1650,  0.1583,  0.1607, -0.0472,  0.0990,  0.0716, -0.1760,\n",
       "                        -0.0324,  0.0018,  0.1842,  0.0475],\n",
       "                       [ 0.0737, -0.1398, -0.1864, -0.0814,  0.2172, -0.2117,  0.0345, -0.1796,\n",
       "                        -0.1344,  0.0742, -0.0065, -0.0747,  0.1544, -0.1581,  0.1577,  0.0010,\n",
       "                         0.1137,  0.0101, -0.1109, -0.0887],\n",
       "                       [ 0.1029,  0.1482,  0.1704, -0.1237,  0.1664,  0.1274,  0.1781, -0.0011,\n",
       "                        -0.0572,  0.1472,  0.0135, -0.0391,  0.0418,  0.1732,  0.1524, -0.1211,\n",
       "                        -0.1485,  0.1041,  0.1931, -0.0244],\n",
       "                       [-0.0801,  0.1147, -0.0538, -0.1068, -0.1371, -0.1075,  0.1794, -0.1998,\n",
       "                         0.0781, -0.1562, -0.0482,  0.1222, -0.0555,  0.1703,  0.0278, -0.0741,\n",
       "                         0.2162,  0.0891,  0.1738, -0.1852],\n",
       "                       [-0.1398, -0.0755,  0.2215, -0.1233,  0.0362, -0.2391,  0.1739, -0.0805,\n",
       "                        -0.1138, -0.1396,  0.0301, -0.2170, -0.0079, -0.1175,  0.1510, -0.1937,\n",
       "                         0.1240,  0.0515,  0.1681,  0.1711],\n",
       "                       [-0.0300, -0.0906,  0.0956, -0.1801,  0.1493, -0.0242,  0.1148,  0.0305,\n",
       "                        -0.1601, -0.1206, -0.1602,  0.1685, -0.1467, -0.0089,  0.0198,  0.0838,\n",
       "                        -0.1337,  0.0760, -0.1492,  0.1133],\n",
       "                       [-0.1709, -0.0768,  0.1839,  0.0132, -0.0068, -0.1024,  0.0266,  0.2220,\n",
       "                         0.0915, -0.2065, -0.2008, -0.0673,  0.0157, -0.0004,  0.2377,  0.1480,\n",
       "                        -0.0586,  0.1595,  0.0111,  0.0110],\n",
       "                       [-0.1066, -0.0579, -0.0116,  0.1182, -0.2032,  0.0741, -0.1220,  0.0794,\n",
       "                        -0.2256, -0.1351,  0.1580,  0.2162, -0.1370,  0.1327, -0.1185, -0.1676,\n",
       "                        -0.0449, -0.0180,  0.0760,  0.1065],\n",
       "                       [ 0.1733,  0.1323,  0.1421, -0.0491, -0.0189,  0.0600,  0.0435, -0.2255,\n",
       "                         0.1467, -0.0824, -0.2043, -0.0986,  0.0255, -0.1042,  0.1596, -0.0371,\n",
       "                        -0.0375, -0.2657, -0.1269, -0.1320],\n",
       "                       [-0.0638, -0.1929, -0.1592, -0.3065, -0.0914,  0.0201,  0.0249, -0.1546,\n",
       "                        -0.0545,  0.0373,  0.0028,  0.0948, -0.0728,  0.1924, -0.1985,  0.1328,\n",
       "                        -0.1827,  0.0069,  0.1540,  0.1135],\n",
       "                       [ 0.1368, -0.0271, -0.1922,  0.0689,  0.0671,  0.1403,  0.1772, -0.0636,\n",
       "                         0.0878,  0.1138,  0.0089, -0.1594, -0.0690, -0.1407,  0.0198, -0.0159,\n",
       "                        -0.1008, -0.0635,  0.1627,  0.1464],\n",
       "                       [-0.1568,  0.2041,  0.0030,  0.2078,  0.0926,  0.1602,  0.0409, -0.2010,\n",
       "                         0.1277,  0.2441,  0.0772,  0.0603, -0.0045, -0.1729,  0.2076,  0.0628,\n",
       "                        -0.1870, -0.1011, -0.0498, -0.0956],\n",
       "                       [-0.0995,  0.0033, -0.0770,  0.1987,  0.1302,  0.2590,  0.0294,  0.2823,\n",
       "                         0.0193,  0.0456, -0.1662, -0.0886,  0.0252, -0.0035,  0.0459,  0.2749,\n",
       "                        -0.2448,  0.2630,  0.0493,  0.1665]])),\n",
       "              ('backbone1.model.layer1.fc1.bias',\n",
       "               tensor([-0.0370, -0.1939,  0.1053,  0.0039,  0.2149,  0.1033, -0.1704,  0.1566,\n",
       "                       -0.0567, -0.0894, -0.1999, -0.0757, -0.1679,  0.0533, -0.0439, -0.0048,\n",
       "                       -0.0791,  0.1693,  0.0432,  0.0416])),\n",
       "              ('backbone1.model.layer2.fc2.weight',\n",
       "               tensor([[ 4.5987e-02, -2.0054e-01, -2.4774e-02,  1.1356e-01,  1.0729e-01,\n",
       "                         3.4116e-03,  2.2031e-01, -1.1396e-01, -2.4011e-01,  1.6263e-01,\n",
       "                        -1.9769e-01,  1.0760e-02, -1.2293e-01, -1.6747e-02, -1.0707e-01,\n",
       "                         8.8255e-02,  1.2167e-01,  1.0077e-01,  4.1822e-02, -1.7625e-01],\n",
       "                       [ 2.6673e-02,  1.7501e-01,  1.4160e-01,  1.5367e-01,  2.0537e-01,\n",
       "                        -8.7618e-02,  1.2017e-02,  1.6991e-01,  1.8227e-01,  1.6261e-01,\n",
       "                         1.6603e-01, -4.6304e-02, -2.3006e-02,  6.5075e-02, -3.0871e-02,\n",
       "                         1.8184e-01, -1.6273e-02,  8.9458e-02, -1.3465e-01,  7.8170e-02],\n",
       "                       [ 1.7899e-01,  8.1936e-02,  8.6201e-02,  1.2147e-01, -5.6837e-02,\n",
       "                        -1.3759e-01,  1.1570e-01,  2.7712e-03,  1.3446e-01,  8.5435e-02,\n",
       "                         1.1064e-01, -7.6816e-02, -1.3395e-01, -1.0110e-01,  2.0420e-01,\n",
       "                        -1.7786e-02, -2.5920e-02, -3.5423e-02, -1.7996e-01, -2.0522e-01],\n",
       "                       [ 1.0704e-01, -1.3152e-01, -1.8576e-01,  1.5318e-01, -1.1094e-01,\n",
       "                         1.5549e-01,  4.8682e-02,  1.4261e-01,  1.0613e-01,  1.3552e-01,\n",
       "                        -1.9645e-01,  7.1151e-02, -2.0737e-02, -4.9945e-02, -5.4427e-02,\n",
       "                        -2.0754e-01, -5.7056e-02,  2.0070e-01,  9.4459e-02, -2.0414e-01],\n",
       "                       [ 6.9774e-02, -2.1155e-01, -1.2756e-01, -7.9119e-02,  1.2469e-01,\n",
       "                        -1.8418e-01, -1.0417e-01, -6.1756e-02, -1.5362e-01,  8.5351e-02,\n",
       "                        -5.3612e-02, -1.3315e-01, -1.8687e-01,  4.6485e-02, -1.2497e-01,\n",
       "                         8.4382e-02, -1.0125e-01, -1.2358e-01, -1.9786e-01,  1.8329e-01],\n",
       "                       [ 1.3894e-02,  9.8125e-02, -1.2211e-01, -2.5718e-03, -8.9840e-02,\n",
       "                        -1.8251e-01, -4.1645e-02, -1.0073e-02, -6.1525e-02,  2.3464e-02,\n",
       "                         2.1049e-01, -1.2339e-01, -1.5706e-01, -3.2785e-04,  1.5246e-01,\n",
       "                         1.4122e-01,  1.5666e-01,  1.1530e-01, -2.6131e-02,  1.1424e-01],\n",
       "                       [ 3.1223e-01,  2.5801e-01, -1.0104e-01, -3.1607e-02, -6.2114e-02,\n",
       "                         3.0536e-03, -2.3819e-01, -1.3162e-01,  2.0436e-02, -7.3512e-02,\n",
       "                         2.1258e-01, -1.5253e-01,  4.0799e-02, -2.5257e-01,  1.4172e-01,\n",
       "                         2.5974e-01, -1.8952e-01, -4.5186e-02, -8.8311e-02, -1.3506e-02],\n",
       "                       [-9.2750e-02,  6.2780e-02, -2.2754e-01,  8.1127e-02, -1.2018e-01,\n",
       "                        -1.0189e-01,  1.4422e-01,  1.2499e-01, -9.6048e-02,  1.0351e-01,\n",
       "                        -1.8603e-01,  8.2894e-02, -1.3351e-01,  8.1349e-02, -1.4248e-01,\n",
       "                         8.4034e-02,  1.2604e-01,  7.2054e-02,  6.6820e-02, -3.5925e-02],\n",
       "                       [ 1.1693e-01,  1.7416e-01,  1.0433e-01,  1.2363e-01,  2.4366e-01,\n",
       "                        -2.7918e-03,  2.2640e-01,  3.2361e-03, -9.3561e-02,  9.5127e-02,\n",
       "                        -1.4579e-01, -2.5169e-01,  8.5001e-02, -6.7903e-02, -1.3674e-01,\n",
       "                        -1.3023e-04,  1.3138e-01,  2.3423e-01, -6.6803e-02, -1.2312e-01],\n",
       "                       [-9.7359e-02, -1.0765e-01,  2.2240e-01,  1.3915e-01,  1.7292e-01,\n",
       "                        -1.8500e-01, -4.6697e-02, -4.0232e-02,  9.8038e-02, -2.8936e-02,\n",
       "                         8.9853e-02, -7.8449e-02, -5.7803e-02,  1.2642e-01, -4.9553e-02,\n",
       "                         2.2132e-01,  1.2810e-01, -4.6622e-02, -1.0357e-01,  1.7045e-02],\n",
       "                       [-1.3561e-01,  3.1530e-02, -1.8220e-01, -1.7085e-01,  1.2467e-01,\n",
       "                        -9.7890e-02, -6.9305e-02, -1.9833e-01, -3.8294e-02, -1.6841e-01,\n",
       "                         4.1971e-02, -3.6000e-02, -4.7738e-02, -2.2698e-01, -1.4950e-02,\n",
       "                        -2.1734e-01,  1.3023e-01,  2.0520e-01,  1.3653e-01, -1.8200e-01],\n",
       "                       [-3.2057e-02,  1.6194e-01,  1.4971e-01, -5.2609e-02,  7.8436e-02,\n",
       "                         5.2963e-02,  9.2875e-04, -1.6593e-01,  5.1735e-02, -1.1630e-01,\n",
       "                        -1.6737e-01, -1.0804e-01, -5.7130e-02, -6.8314e-03, -5.9328e-03,\n",
       "                         1.2971e-01, -1.1497e-01,  1.5506e-01, -2.2121e-01,  1.8222e-01],\n",
       "                       [ 1.6985e-01, -1.1864e-01, -1.8606e-01,  6.9159e-02,  1.6525e-01,\n",
       "                         4.3195e-02,  1.2378e-01,  1.9870e-01, -8.0824e-02, -2.6038e-02,\n",
       "                         1.4850e-01,  1.6687e-01, -1.1887e-01,  1.4384e-01, -8.0047e-02,\n",
       "                        -3.6874e-02, -4.2783e-02, -1.4336e-01,  1.9444e-01,  1.8232e-01],\n",
       "                       [-5.4273e-02,  1.6181e-01, -1.0691e-01,  1.0198e-01, -1.4089e-01,\n",
       "                        -1.6534e-01,  1.4223e-01, -2.1114e-01, -1.0144e-01,  1.9576e-01,\n",
       "                         5.8783e-02, -1.3666e-01,  1.6557e-02, -6.2082e-02,  1.1015e-01,\n",
       "                        -8.2182e-02, -2.5231e-01, -1.5344e-01, -1.0390e-01,  3.2942e-02],\n",
       "                       [ 7.1157e-03, -1.4548e-01, -1.1713e-01,  2.5310e-02,  1.9546e-01,\n",
       "                         6.2803e-02, -7.7995e-02, -8.8676e-02,  1.2775e-01, -1.1442e-01,\n",
       "                        -9.8156e-02,  3.1093e-02, -1.3517e-01,  1.9721e-01, -4.8365e-02,\n",
       "                         2.1523e-01, -3.4862e-02, -1.9373e-01, -4.7839e-02, -3.6446e-02],\n",
       "                       [ 1.1480e-01, -1.9086e-01,  8.3333e-03,  1.6325e-01,  1.8469e-01,\n",
       "                        -2.1217e-01, -1.6847e-01,  7.6628e-02, -1.7674e-01,  7.6547e-02,\n",
       "                        -1.8505e-01, -6.8267e-02, -1.1304e-01, -3.6848e-02,  4.9378e-02,\n",
       "                        -7.3854e-02,  8.2913e-02, -1.3814e-01,  1.8384e-01, -1.4603e-01],\n",
       "                       [-6.1008e-02,  8.5872e-02, -7.3028e-02, -1.8842e-01, -6.0845e-02,\n",
       "                        -1.2832e-01,  1.9148e-01,  2.0321e-01, -2.6501e-02, -7.2368e-02,\n",
       "                         6.1734e-02, -1.5694e-01, -8.1057e-03,  1.4554e-01,  2.0409e-01,\n",
       "                         1.5274e-01, -9.4827e-02,  8.2328e-02, -6.6291e-02,  3.2578e-02],\n",
       "                       [-2.5952e-02,  3.0706e-02,  1.9660e-01,  6.7017e-02, -7.0413e-02,\n",
       "                        -1.1288e-01,  6.4949e-02,  1.5029e-01,  5.3126e-02,  1.5688e-01,\n",
       "                         1.4571e-01,  1.5653e-02,  1.3977e-01, -6.3135e-02,  1.8399e-02,\n",
       "                         1.6104e-01, -2.1012e-02,  2.1163e-01, -1.8744e-01, -5.1072e-02],\n",
       "                       [-2.2796e-01,  1.1642e-01,  2.9231e-02, -1.8706e-01,  8.8389e-02,\n",
       "                         1.4222e-01,  3.0980e-02,  1.2941e-01, -1.6620e-01,  1.3197e-01,\n",
       "                         2.2180e-01, -1.5018e-01,  1.6581e-01, -1.4044e-01,  1.0217e-01,\n",
       "                        -1.9922e-02,  9.7519e-02, -1.8799e-01, -4.8453e-03, -2.0963e-01],\n",
       "                       [-2.1192e-01,  6.9479e-02,  6.6217e-02, -9.5092e-02,  1.1724e-01,\n",
       "                        -2.0774e-02,  1.0568e-01, -4.1934e-02,  1.6448e-02,  2.7551e-02,\n",
       "                        -2.0622e-01,  4.9600e-02, -1.1899e-01,  1.1560e-01,  5.3409e-03,\n",
       "                        -1.1102e-01,  9.4705e-02,  8.9137e-02, -4.9827e-02, -5.7078e-02]])),\n",
       "              ('backbone1.model.layer2.fc2.bias',\n",
       "               tensor([-0.1317,  0.0280,  0.0422, -0.0174, -0.0283,  0.1861,  0.1272, -0.1508,\n",
       "                       -0.1219,  0.1169, -0.1932, -0.1942,  0.1787,  0.1143, -0.1142,  0.1134,\n",
       "                       -0.0713,  0.0057, -0.1642, -0.1057])),\n",
       "              ('backbone1.model.layer3.fc3.weight',\n",
       "               tensor([[-2.1155e-01,  1.0261e-01, -4.7686e-02,  1.9795e-01, -1.1937e-01,\n",
       "                         2.3138e-02,  1.6375e-02, -9.2220e-02,  1.3571e-02, -1.7473e-01,\n",
       "                        -7.6209e-02,  1.5302e-01,  3.3110e-02,  2.0155e-01,  1.6153e-01,\n",
       "                         6.6097e-02, -1.7138e-02, -4.7793e-02,  1.7689e-01, -9.9952e-02],\n",
       "                       [ 1.2224e-01,  1.1932e-02, -2.2564e-01,  2.2549e-01,  1.5038e-01,\n",
       "                         2.0805e-01, -7.7741e-02,  1.8594e-01,  1.1424e-01, -2.0256e-02,\n",
       "                         1.8788e-01, -7.1952e-02,  1.6462e-01, -3.7820e-02,  1.4598e-01,\n",
       "                         1.3904e-02,  8.9686e-02, -8.0374e-02, -4.4771e-02, -1.4652e-01],\n",
       "                       [ 2.0890e-01, -2.2872e-01, -1.0418e-01,  1.5651e-01,  2.0848e-01,\n",
       "                         1.7180e-02, -9.0376e-02,  1.4195e-01, -3.2155e-02,  1.3291e-01,\n",
       "                         8.3867e-02,  1.8993e-01,  2.7217e-02, -9.1020e-02, -1.7529e-01,\n",
       "                        -5.0456e-02,  6.7863e-02, -6.4476e-02,  2.0961e-01,  9.2602e-02],\n",
       "                       [ 1.1606e-01,  1.3850e-01, -1.8397e-01, -7.0433e-02, -8.6157e-02,\n",
       "                        -8.9029e-02,  1.5853e-01,  1.5939e-01, -9.0692e-02, -1.4737e-01,\n",
       "                        -2.0895e-02,  3.5848e-02,  4.2676e-02, -1.1366e-01,  1.6489e-01,\n",
       "                         6.4993e-02, -1.4931e-01,  1.5647e-01,  1.1113e-01, -1.7500e-01],\n",
       "                       [ 1.5457e-01, -1.2085e-01,  8.1866e-02,  1.8932e-01,  1.6193e-01,\n",
       "                         1.6342e-01, -1.7414e-01,  3.5627e-02,  1.2286e-01, -2.0560e-01,\n",
       "                        -1.3724e-02, -1.2447e-01,  1.5199e-01,  1.9278e-01, -1.9146e-01,\n",
       "                         4.8784e-02,  2.1516e-01, -1.1549e-01,  1.2488e-02,  1.9149e-01],\n",
       "                       [ 1.9783e-01,  1.2587e-03,  1.5071e-01, -1.0460e-02,  1.6751e-01,\n",
       "                         9.6583e-02,  1.2274e-01,  3.1972e-02, -2.2074e-01, -2.0878e-01,\n",
       "                         1.8851e-01,  3.3097e-02,  6.4486e-02,  2.3198e-01, -3.6263e-02,\n",
       "                         4.6959e-02, -1.6539e-01,  3.2105e-02,  1.4746e-01, -9.5500e-02],\n",
       "                       [-9.7135e-02, -5.0870e-02, -8.5161e-02, -1.5147e-01,  1.3854e-01,\n",
       "                         8.3562e-02, -1.4881e-01,  1.7221e-01, -7.5023e-02, -8.7814e-03,\n",
       "                        -1.1985e-01, -1.2883e-01,  5.4830e-02, -4.5749e-02,  1.8993e-01,\n",
       "                        -5.5088e-03,  1.6348e-02, -9.3489e-02,  5.5229e-03, -1.1153e-01],\n",
       "                       [ 4.2049e-02,  1.0032e-01,  8.1792e-02,  8.9303e-02,  2.9841e-02,\n",
       "                        -2.0557e-01,  9.7222e-02, -2.3095e-02,  1.7407e-01, -9.1614e-02,\n",
       "                         8.3619e-02,  1.4412e-01, -1.2925e-01, -9.0961e-02, -1.8158e-01,\n",
       "                        -5.4250e-02,  3.2008e-02,  1.0879e-01, -4.4430e-02,  2.0941e-02],\n",
       "                       [-1.6767e-01, -1.5975e-01, -8.5007e-02,  1.7690e-01,  1.5944e-01,\n",
       "                        -1.3782e-01, -1.8112e-01, -7.3928e-02, -9.3145e-02,  5.4587e-02,\n",
       "                        -1.0013e-01,  7.4517e-02,  8.7377e-02,  4.7792e-02, -1.0217e-01,\n",
       "                        -2.0529e-01,  2.2984e-01,  1.6778e-01,  6.0194e-02,  1.0815e-01],\n",
       "                       [-5.1318e-02,  3.4552e-02, -4.3139e-02, -2.1523e-01,  6.7814e-02,\n",
       "                        -6.4543e-02, -1.8947e-01, -1.0657e-01, -8.3673e-02, -1.7435e-01,\n",
       "                        -6.8447e-02, -2.0541e-01, -2.0574e-01,  7.3722e-02,  5.3203e-02,\n",
       "                         1.1372e-02, -1.4886e-01,  6.0603e-02,  2.0568e-01,  2.0732e-01],\n",
       "                       [ 2.2158e-01,  1.3610e-01, -1.6418e-02, -1.0363e-01,  7.8193e-02,\n",
       "                         1.7090e-01,  1.2419e-01, -9.6663e-02,  7.8892e-02, -2.0339e-01,\n",
       "                         1.7419e-01, -1.8800e-01,  4.8156e-02,  1.8105e-01,  1.2642e-01,\n",
       "                         9.5589e-02,  1.4275e-01, -1.7307e-01,  1.9575e-01,  2.0535e-01],\n",
       "                       [ 2.4571e-02,  1.4395e-01, -1.5805e-01, -3.1195e-02,  1.4555e-01,\n",
       "                        -9.4758e-03, -3.4838e-02, -5.1180e-02, -1.4349e-01, -1.7276e-01,\n",
       "                        -7.0524e-02, -2.0254e-01, -1.0878e-01,  1.2636e-01,  1.8052e-01,\n",
       "                        -1.6670e-01,  5.3944e-03, -6.7580e-03, -9.4583e-02, -1.9844e-01],\n",
       "                       [-3.4093e-02, -2.4068e-02, -1.1859e-01, -2.0847e-01,  9.8044e-02,\n",
       "                        -6.0386e-02,  9.6448e-03,  1.9302e-01,  1.2246e-01, -9.7040e-02,\n",
       "                         6.9402e-02, -4.6637e-02,  6.1148e-02, -2.1964e-01,  1.5840e-01,\n",
       "                        -1.9942e-01, -2.2644e-01,  2.1728e-01,  1.6236e-01, -1.1607e-01],\n",
       "                       [-2.3830e-01, -4.6571e-02, -5.3822e-03, -1.0570e-01,  1.5983e-01,\n",
       "                         1.6421e-01, -1.1614e-01,  3.9718e-02, -1.5083e-01,  1.6373e-01,\n",
       "                         5.2202e-02,  1.6337e-01,  1.0445e-01, -1.2733e-01,  1.6320e-01,\n",
       "                        -8.6124e-02,  2.3482e-01,  1.8043e-01, -8.5694e-02,  1.1655e-01],\n",
       "                       [-1.3944e-01,  1.2491e-01, -9.7537e-02, -1.8625e-01,  1.5788e-01,\n",
       "                         5.9747e-02, -1.3354e-01, -1.0738e-01,  8.0341e-03, -7.4465e-02,\n",
       "                        -2.0808e-01, -1.8842e-01, -6.1618e-02,  1.2543e-01, -9.2606e-02,\n",
       "                         2.7118e-02, -2.5417e-02,  1.5360e-02, -9.0493e-03, -2.7354e-02],\n",
       "                       [-9.8927e-02, -1.0701e-01, -7.5700e-03,  7.6860e-03, -1.5308e-01,\n",
       "                        -1.4936e-01, -1.3168e-01, -1.2889e-01,  4.5671e-02,  1.9501e-01,\n",
       "                         1.7141e-01, -1.7768e-01, -1.6437e-01, -1.1124e-01, -1.6606e-01,\n",
       "                         4.2051e-02,  1.7249e-01,  8.2668e-02,  1.3882e-01,  4.7279e-02],\n",
       "                       [-2.0816e-01,  3.5282e-02, -5.4648e-02,  7.7843e-02, -1.3350e-01,\n",
       "                         2.0012e-01, -2.1890e-01, -1.5890e-01, -8.4113e-02, -1.6560e-01,\n",
       "                         1.5861e-01,  1.0939e-01, -1.9091e-01,  1.2117e-01,  5.0540e-02,\n",
       "                        -1.6056e-01, -4.4327e-02, -2.5237e-02, -8.6343e-02,  1.3538e-01],\n",
       "                       [ 2.0748e-01,  1.2422e-01, -1.4600e-01, -1.4671e-01, -1.5343e-01,\n",
       "                         2.2629e-01, -1.7703e-01,  2.7969e-03,  7.9645e-02,  8.1712e-03,\n",
       "                         1.7147e-01, -5.1872e-02,  6.8385e-02, -1.0492e-01,  1.8885e-01,\n",
       "                        -1.0316e-01, -6.2579e-02, -1.4724e-01, -9.3543e-02, -1.3181e-01],\n",
       "                       [ 1.0197e-01, -1.0336e-02, -6.8387e-02, -1.1601e-01, -2.0044e-01,\n",
       "                        -1.9735e-01, -1.5575e-01, -1.1626e-01,  1.1984e-01,  7.8489e-02,\n",
       "                        -1.2745e-01,  2.5341e-02, -1.4295e-01, -1.8086e-02, -6.6652e-02,\n",
       "                        -2.1654e-01, -7.6559e-02,  4.8316e-02,  6.6401e-02, -6.5950e-02],\n",
       "                       [-2.0670e-01,  1.8024e-01, -1.9377e-01, -8.4054e-05,  1.1507e-01,\n",
       "                         5.9587e-02,  9.5719e-02, -1.8173e-01, -9.9591e-02,  1.8952e-01,\n",
       "                         1.8429e-01,  5.7015e-02, -1.2999e-01,  1.1754e-01,  1.4953e-01,\n",
       "                         5.2575e-02, -1.9554e-01,  3.0908e-02, -1.2742e-01,  2.0237e-01]])),\n",
       "              ('backbone1.model.layer3.fc3.bias',\n",
       "               tensor([-0.1625,  0.0109, -0.1499, -0.2130, -0.2062, -0.0599,  0.1956,  0.0310,\n",
       "                       -0.1249,  0.0496,  0.1826, -0.1631, -0.0345, -0.0010,  0.1470, -0.1360,\n",
       "                       -0.1473,  0.2045, -0.0098, -0.0936])),\n",
       "              ('backbone1.model.layer4.fc4.weight',\n",
       "               tensor([[ 0.1049, -0.1036,  0.1091,  0.1809,  0.0097,  0.0238, -0.0983,  0.0554,\n",
       "                         0.1075,  0.0583, -0.1256, -0.1672, -0.1002,  0.0105,  0.1876,  0.0273,\n",
       "                        -0.1488,  0.1695, -0.1384, -0.0170]])),\n",
       "              ('backbone2.model.layer0.fc0.weight',\n",
       "               tensor([[-0.2559, -0.3312],\n",
       "                       [ 0.3863,  0.5066],\n",
       "                       [ 0.0838,  0.2560],\n",
       "                       [-0.5060, -0.5394],\n",
       "                       [-0.4005,  0.1218],\n",
       "                       [ 0.1814, -0.0058],\n",
       "                       [ 0.1389, -0.1041],\n",
       "                       [-0.5185,  0.4147],\n",
       "                       [-0.0172,  0.2535],\n",
       "                       [-0.2721,  0.3487],\n",
       "                       [ 0.4328,  0.1163],\n",
       "                       [ 0.0674, -0.4222],\n",
       "                       [-0.2299,  0.0171],\n",
       "                       [ 0.0574,  0.4953],\n",
       "                       [ 0.6646, -0.3666],\n",
       "                       [-0.2921, -0.0662],\n",
       "                       [ 0.2951,  0.6068],\n",
       "                       [ 0.3179,  0.0939],\n",
       "                       [-0.2609, -0.0523],\n",
       "                       [-0.0722, -0.2195]])),\n",
       "              ('backbone2.model.layer0.fc0.bias',\n",
       "               tensor([ 0.5330, -0.1742,  0.3211,  0.4505, -0.5337, -0.1508, -0.4423, -0.0045,\n",
       "                       -0.0100,  0.3172, -0.0620,  0.1854,  0.3906,  0.4490,  0.4619, -0.5246,\n",
       "                        0.1641,  0.2651, -0.6647, -0.3961])),\n",
       "              ('backbone2.model.layer1.fc1.weight',\n",
       "               tensor([[-1.1628e-01,  1.9359e-01, -7.4852e-02,  1.4792e-01, -7.0466e-03,\n",
       "                         5.4301e-02,  1.8577e-01, -2.4322e-02, -1.3291e-01,  1.9864e-01,\n",
       "                        -1.2450e-01, -1.0055e-02,  2.6539e-02,  1.3787e-01, -1.3034e-01,\n",
       "                        -1.3106e-01, -2.0445e-01, -1.6189e-01,  1.3280e-02,  1.3980e-01],\n",
       "                       [-4.9639e-02, -1.7610e-01,  2.3159e-01, -6.6642e-02, -2.1447e-01,\n",
       "                         2.1239e-01, -3.8577e-02,  9.4731e-02, -1.9444e-01, -1.0670e-02,\n",
       "                        -4.3733e-02,  2.3770e-02,  3.6405e-02,  1.7674e-01, -5.9546e-02,\n",
       "                        -3.7133e-02, -1.8848e-01, -5.2502e-03,  4.2941e-02,  8.7785e-03],\n",
       "                       [ 1.0042e-01, -6.0083e-02,  3.1211e-02,  1.6779e-01, -1.1305e-01,\n",
       "                        -4.1882e-02, -2.0833e-01, -1.6875e-03,  2.1470e-02,  2.9792e-02,\n",
       "                         4.9291e-02,  1.7056e-01,  5.5787e-02, -7.0431e-02,  1.1499e-01,\n",
       "                        -1.1918e-02,  1.4654e-02, -1.3761e-01,  1.9271e-01,  1.1438e-02],\n",
       "                       [ 2.0457e-01, -1.9574e-01,  1.6730e-01,  7.4526e-02, -1.9703e-01,\n",
       "                         1.9974e-02, -1.3058e-02, -5.0210e-02, -2.3705e-02,  4.8886e-02,\n",
       "                         1.7930e-01, -1.5878e-01, -5.9674e-02,  2.2135e-02,  2.7301e-02,\n",
       "                         1.4363e-01,  7.3901e-02,  9.3543e-02, -3.5107e-02,  2.0414e-01],\n",
       "                       [ 1.6513e-02,  7.8652e-02, -1.5716e-01, -1.9265e-01, -3.9404e-02,\n",
       "                        -5.1812e-02,  1.0902e-01, -2.1261e-01, -2.3065e-01,  7.7039e-02,\n",
       "                         2.4045e-01,  1.7223e-01,  1.8504e-01, -9.0267e-02, -1.8695e-01,\n",
       "                        -1.0520e-01, -6.2920e-03,  1.0353e-01,  1.1417e-01,  7.4310e-03],\n",
       "                       [-7.8991e-02, -1.3490e-01,  1.2349e-01,  1.1304e-01,  4.8667e-02,\n",
       "                        -1.8972e-01,  4.3256e-02, -9.2277e-02, -8.8947e-02, -5.3716e-02,\n",
       "                         1.3035e-01, -1.7244e-01, -4.4233e-02, -2.0881e-01,  1.6573e-01,\n",
       "                         1.0826e-01, -2.0335e-02, -3.2150e-03,  8.5413e-02,  1.7633e-03],\n",
       "                       [ 4.7390e-02,  6.8390e-02, -7.7296e-02,  1.1779e-01, -2.5920e-02,\n",
       "                         1.9548e-01,  1.2172e-01,  2.6053e-02,  2.0288e-01, -2.0341e-01,\n",
       "                        -2.2958e-01,  6.4181e-02,  7.3050e-03, -1.3808e-03,  8.4382e-02,\n",
       "                        -4.7786e-02,  1.6332e-01, -7.8569e-02, -8.2381e-02, -2.0772e-02],\n",
       "                       [-8.2140e-02, -6.5012e-03, -1.6088e-01, -6.6026e-02,  9.9007e-02,\n",
       "                         4.8954e-02, -1.2488e-01,  1.2332e-01,  1.7903e-01,  4.6371e-02,\n",
       "                        -3.6738e-02,  1.2225e-01,  1.7415e-01,  1.6823e-01,  5.3844e-02,\n",
       "                        -9.6068e-02,  5.7209e-02, -1.0443e-01, -2.3657e-02,  8.9381e-02],\n",
       "                       [ 1.4209e-01, -1.3778e-01,  1.1946e-01,  6.9771e-02, -1.9807e-01,\n",
       "                        -8.7462e-02, -1.4193e-01,  4.5010e-02,  9.8164e-02, -4.0986e-02,\n",
       "                        -6.7082e-02,  1.4957e-01,  6.3281e-02, -1.0349e-01, -1.6381e-01,\n",
       "                        -2.4574e-02, -1.3128e-02, -2.6056e-02,  1.2843e-01, -2.2309e-01],\n",
       "                       [ 1.7669e-01, -9.3445e-02,  4.8700e-02,  4.4950e-02,  1.3789e-01,\n",
       "                        -1.4978e-01,  5.8154e-03,  8.6576e-02,  1.5148e-01, -1.7102e-01,\n",
       "                         1.9324e-01,  1.6696e-01, -5.5451e-02, -6.8568e-02,  1.6512e-01,\n",
       "                         8.2707e-02,  1.1872e-01,  1.6085e-01,  2.0468e-01,  7.1702e-02],\n",
       "                       [ 3.2260e-03,  8.6819e-02, -1.0363e-01, -2.2775e-01, -6.6585e-02,\n",
       "                        -2.1530e-02,  8.6101e-02, -1.0802e-01, -1.4609e-01, -1.8447e-01,\n",
       "                        -1.7706e-02,  6.8630e-03,  8.4350e-02, -1.1946e-02,  9.8609e-02,\n",
       "                         1.1466e-01,  2.0321e-02, -2.1312e-01,  1.7925e-01, -1.8383e-01],\n",
       "                       [-9.6811e-02,  8.3639e-02, -1.4306e-01, -5.7345e-02,  6.2738e-03,\n",
       "                        -1.2866e-01, -3.9189e-02, -1.0627e-01,  2.3088e-01,  6.6883e-02,\n",
       "                        -9.2466e-02, -1.6657e-01,  1.2918e-01, -2.4277e-02,  5.0074e-02,\n",
       "                         2.4981e-02,  2.3950e-03,  1.1750e-01, -1.9507e-01,  1.4120e-02],\n",
       "                       [ 1.7014e-01,  7.2028e-02,  1.9299e-02,  1.7296e-02,  3.8672e-02,\n",
       "                         2.0102e-01, -1.0181e-01,  9.3705e-02,  1.1465e-01, -1.7845e-02,\n",
       "                        -2.9400e-02, -5.0228e-02, -2.3685e-02, -1.1189e-01,  1.1522e-01,\n",
       "                         7.2311e-02,  3.2322e-02, -5.6437e-02, -2.4425e-01,  2.8465e-02],\n",
       "                       [ 9.9149e-02, -2.6472e-02, -2.2096e-03, -2.1641e-02, -1.0084e-01,\n",
       "                        -1.1745e-02, -2.0333e-01, -6.2486e-02,  1.3622e-01,  8.8080e-02,\n",
       "                         1.6368e-01, -6.6657e-02,  3.6948e-02, -1.6847e-01, -9.9798e-02,\n",
       "                        -4.9327e-02, -8.9641e-02,  6.9684e-02,  1.7678e-01,  7.7983e-02],\n",
       "                       [ 2.0731e-01,  1.3409e-01, -1.7626e-01, -1.0770e-01,  1.6601e-01,\n",
       "                        -1.1296e-01, -1.4182e-01,  3.2948e-02,  3.2022e-03, -1.2973e-01,\n",
       "                        -5.2193e-02, -3.4511e-02, -1.8702e-01, -9.7120e-02, -1.4275e-01,\n",
       "                         1.4694e-02, -1.5668e-01,  1.9491e-01, -8.1967e-02, -2.0967e-01],\n",
       "                       [ 6.6452e-02, -4.5594e-02,  7.2574e-02,  6.9410e-02,  1.2864e-01,\n",
       "                         3.2863e-02, -1.5154e-02, -1.6810e-01, -7.1040e-02,  1.6199e-02,\n",
       "                        -1.3455e-01,  2.1453e-01,  4.9875e-02, -1.5936e-01, -1.5852e-01,\n",
       "                        -1.1197e-01, -1.4704e-01,  7.5883e-02,  1.9773e-01,  1.3784e-01],\n",
       "                       [-1.2574e-01, -1.3663e-01,  1.8388e-01,  1.5700e-01, -2.3695e-01,\n",
       "                         2.3283e-01, -1.7186e-01, -9.8023e-02, -9.9286e-02,  1.4226e-01,\n",
       "                        -1.8872e-02, -1.1053e-01,  1.8511e-01,  6.9959e-04, -8.0946e-02,\n",
       "                         1.4994e-01,  1.5127e-02,  1.1868e-01,  1.1644e-01, -1.4006e-02],\n",
       "                       [ 1.3929e-01,  1.0247e-01, -1.6814e-01,  2.0612e-01, -4.0692e-03,\n",
       "                         1.5516e-01,  8.2128e-02,  1.2210e-01,  1.8007e-01, -2.4190e-02,\n",
       "                         1.9488e-01,  1.0436e-01,  1.7477e-01,  2.0504e-01, -3.1666e-02,\n",
       "                         1.0824e-01, -1.7361e-01,  1.0221e-01,  1.1485e-01, -2.2589e-01],\n",
       "                       [-1.5745e-01, -1.5091e-01, -1.0143e-01, -1.4945e-01,  2.2635e-03,\n",
       "                         1.9795e-01,  1.6889e-01,  1.3683e-01,  2.8216e-02,  2.8704e-02,\n",
       "                        -1.8876e-02,  9.9073e-02,  1.1724e-01, -1.9606e-01,  9.0271e-02,\n",
       "                        -5.8983e-02,  1.7409e-01,  2.1129e-01, -1.3826e-02, -1.5871e-01],\n",
       "                       [-1.1338e-01, -1.8728e-01, -1.3434e-01,  1.2264e-01,  7.1772e-02,\n",
       "                         2.1690e-01, -7.3615e-02,  1.8228e-01, -4.1512e-02,  1.6579e-01,\n",
       "                        -4.9932e-02,  1.1064e-01,  1.8408e-04,  6.8720e-02,  9.3036e-02,\n",
       "                         7.2787e-02,  1.3960e-01,  1.8976e-01, -5.2439e-02,  1.4545e-01]])),\n",
       "              ('backbone2.model.layer1.fc1.bias',\n",
       "               tensor([ 0.1202, -0.1443, -0.1336, -0.1498, -0.1929,  0.1497,  0.0867,  0.0450,\n",
       "                        0.1126, -0.2213, -0.1213, -0.1120, -0.1467,  0.0519, -0.1880, -0.1831,\n",
       "                       -0.1193, -0.0379, -0.0715,  0.0723])),\n",
       "              ('backbone2.model.layer2.fc2.weight',\n",
       "               tensor([[-0.1170,  0.1459,  0.0005,  0.1988,  0.2163, -0.0597, -0.0653, -0.1233,\n",
       "                         0.1058,  0.0056, -0.1790, -0.0217, -0.0225, -0.1077,  0.0951,  0.2017,\n",
       "                        -0.0061,  0.0788, -0.1902, -0.0053],\n",
       "                       [-0.1172, -0.0850, -0.1149, -0.1239, -0.0580,  0.1689,  0.2719,  0.1838,\n",
       "                        -0.1155, -0.0726, -0.1861, -0.0481, -0.1497, -0.1653,  0.1128,  0.0506,\n",
       "                        -0.1321,  0.0737,  0.0396,  0.2172],\n",
       "                       [ 0.1427,  0.2019, -0.0812,  0.0663,  0.0016,  0.1346, -0.1094, -0.1037,\n",
       "                        -0.2164,  0.0678,  0.2196, -0.1766, -0.1793, -0.0560, -0.1632,  0.0394,\n",
       "                        -0.1703,  0.2115, -0.1798, -0.1341],\n",
       "                       [-0.0548, -0.1065,  0.0606, -0.0884,  0.1207,  0.0003, -0.0912, -0.0401,\n",
       "                         0.1718, -0.1980, -0.0526,  0.2115, -0.0573,  0.1550, -0.0880,  0.1191,\n",
       "                         0.2116,  0.1993,  0.0584,  0.0488],\n",
       "                       [-0.0941,  0.2014, -0.1897,  0.1524,  0.1946,  0.0739, -0.0704,  0.0280,\n",
       "                         0.1279, -0.2138,  0.0574, -0.0543,  0.0379,  0.0057, -0.2200,  0.0047,\n",
       "                         0.2124, -0.1483,  0.1799, -0.0793],\n",
       "                       [-0.1013,  0.0128,  0.1886,  0.0210,  0.1515,  0.0693, -0.0800, -0.1908,\n",
       "                        -0.1238,  0.0391, -0.0435, -0.0656, -0.1409,  0.0807,  0.1255, -0.0398,\n",
       "                         0.1330,  0.1922,  0.0047,  0.1604],\n",
       "                       [ 0.0041, -0.0692,  0.1349, -0.0667,  0.1004, -0.1366,  0.0641,  0.2009,\n",
       "                         0.0761, -0.1116, -0.2353, -0.1992,  0.1908,  0.1387, -0.1713,  0.1545,\n",
       "                         0.1587, -0.1235, -0.1878,  0.1852],\n",
       "                       [ 0.1014, -0.1236,  0.1135,  0.0782, -0.1669, -0.1815,  0.2229, -0.0403,\n",
       "                        -0.1591,  0.0886,  0.0644, -0.1192, -0.0799, -0.1296, -0.1919, -0.1801,\n",
       "                        -0.0153, -0.0774, -0.0866, -0.1324],\n",
       "                       [-0.0431, -0.1168,  0.0048, -0.2038, -0.1535, -0.0994, -0.0776,  0.0209,\n",
       "                        -0.2537,  0.1463,  0.0101,  0.0259, -0.1536,  0.0984, -0.1587, -0.0065,\n",
       "                        -0.0393, -0.1352, -0.0515,  0.0962],\n",
       "                       [ 0.0346, -0.0559,  0.1901,  0.0708, -0.1010, -0.1562,  0.1043,  0.0903,\n",
       "                         0.1851,  0.1901,  0.0349,  0.0195, -0.0383,  0.1204, -0.1619, -0.0417,\n",
       "                        -0.0265, -0.0501,  0.0307,  0.0818],\n",
       "                       [ 0.1415,  0.0121, -0.1441, -0.0238,  0.0479, -0.0665, -0.0482,  0.1469,\n",
       "                         0.1062, -0.2221, -0.1925,  0.1023,  0.0943, -0.0282, -0.0258, -0.1185,\n",
       "                        -0.2093,  0.0331, -0.0966, -0.2217],\n",
       "                       [ 0.0209,  0.0483, -0.0122, -0.0852,  0.1644,  0.0125, -0.1247, -0.0525,\n",
       "                         0.0665,  0.0408, -0.1707, -0.2153, -0.1498,  0.1229,  0.0926,  0.1097,\n",
       "                        -0.0064, -0.1748,  0.2182, -0.2095],\n",
       "                       [ 0.2289, -0.0120, -0.0506, -0.0999,  0.1665, -0.0497, -0.0116,  0.1425,\n",
       "                        -0.1102,  0.0124, -0.1123,  0.2153, -0.0286,  0.0899, -0.1469, -0.0039,\n",
       "                         0.1921,  0.2089, -0.1117, -0.1098],\n",
       "                       [ 0.2086,  0.1562,  0.0619,  0.1635, -0.0346,  0.1465,  0.0886, -0.1331,\n",
       "                        -0.1349, -0.0281,  0.0755, -0.1632,  0.0993,  0.1414,  0.0632,  0.1266,\n",
       "                        -0.1216, -0.1405, -0.1749,  0.0884],\n",
       "                       [-0.1448,  0.0348, -0.0148,  0.2111,  0.1546,  0.0894,  0.0740, -0.1842,\n",
       "                        -0.0901,  0.0535,  0.1602, -0.1430, -0.1495,  0.2150, -0.2289,  0.0964,\n",
       "                         0.0569, -0.0369, -0.2346, -0.0570],\n",
       "                       [-0.0891, -0.1065,  0.0076,  0.1460,  0.0976,  0.0643, -0.1087,  0.1942,\n",
       "                         0.1687, -0.1084, -0.1943,  0.1512,  0.2197,  0.0058, -0.1456, -0.0270,\n",
       "                         0.1562,  0.1047, -0.0133,  0.0625],\n",
       "                       [ 0.0964, -0.1164,  0.2013,  0.0927,  0.0713, -0.1311,  0.1199, -0.1286,\n",
       "                         0.0879,  0.1629, -0.0306,  0.1458,  0.0054, -0.0755, -0.1301,  0.2294,\n",
       "                        -0.2275, -0.1594, -0.0500,  0.0511],\n",
       "                       [-0.1061,  0.0347, -0.1059,  0.1421, -0.1901,  0.0337,  0.1571,  0.1152,\n",
       "                         0.1076,  0.1360, -0.1444, -0.0819,  0.0233, -0.0796,  0.0040, -0.1918,\n",
       "                         0.2015,  0.0370, -0.2394,  0.0773],\n",
       "                       [-0.1729,  0.0701,  0.1317,  0.0657,  0.2232, -0.0580,  0.0465,  0.0510,\n",
       "                         0.0179,  0.1344, -0.0485, -0.0381,  0.1563, -0.1654, -0.1401,  0.1447,\n",
       "                        -0.1570, -0.0281,  0.0695,  0.1021],\n",
       "                       [-0.0910,  0.1432, -0.2234, -0.1637, -0.0417, -0.1364,  0.0279,  0.2564,\n",
       "                        -0.0011,  0.0426,  0.1299, -0.0112,  0.0436, -0.1255, -0.0957,  0.1155,\n",
       "                        -0.1659, -0.1835,  0.1040,  0.1025]])),\n",
       "              ('backbone2.model.layer2.fc2.bias',\n",
       "               tensor([ 0.0081, -0.1045,  0.1584, -0.1861, -0.1912, -0.1334, -0.1001, -0.0563,\n",
       "                        0.0255, -0.0896, -0.1834,  0.1149,  0.0684,  0.2176, -0.0376, -0.1734,\n",
       "                        0.0781,  0.1916,  0.1548,  0.0234])),\n",
       "              ('backbone2.model.layer3.fc3.weight',\n",
       "               tensor([[ 0.0680,  0.2184,  0.1544,  0.1669, -0.0637,  0.2152, -0.0967,  0.0382,\n",
       "                         0.1920, -0.0679,  0.1612,  0.0465,  0.1282,  0.0071, -0.0270,  0.0491,\n",
       "                         0.2016, -0.1276,  0.0759, -0.1781],\n",
       "                       [-0.1056,  0.0512,  0.0753, -0.1901,  0.0260,  0.1911, -0.0642, -0.2083,\n",
       "                         0.0387, -0.0879,  0.1427,  0.0557,  0.1825,  0.1530,  0.2006, -0.0984,\n",
       "                         0.1452,  0.1028,  0.0078, -0.0120],\n",
       "                       [ 0.2713,  0.1012,  0.1380, -0.1077, -0.1385, -0.0277, -0.0390, -0.0363,\n",
       "                        -0.2257, -0.0373,  0.0930,  0.1453,  0.0331, -0.0443,  0.0091, -0.1471,\n",
       "                         0.0678, -0.1967, -0.2131,  0.2246],\n",
       "                       [ 0.1138, -0.0710,  0.0547, -0.1109, -0.1610, -0.0520,  0.0912, -0.0069,\n",
       "                        -0.1883,  0.0637, -0.0229,  0.1919,  0.0828, -0.1051, -0.1727, -0.0831,\n",
       "                         0.1581,  0.0253,  0.1744, -0.1062],\n",
       "                       [ 0.0358,  0.1028, -0.1683,  0.0941,  0.0161, -0.0271,  0.2337,  0.0165,\n",
       "                        -0.1228,  0.0895, -0.1492, -0.0058,  0.0635,  0.1836,  0.2221,  0.0230,\n",
       "                         0.1156,  0.0676,  0.0053, -0.0494],\n",
       "                       [ 0.1027, -0.1338, -0.0165,  0.0316,  0.1193,  0.1708,  0.1273,  0.0815,\n",
       "                        -0.1548, -0.1098, -0.0055, -0.0123,  0.0205, -0.1935, -0.0212,  0.0839,\n",
       "                         0.1102,  0.0810, -0.0443,  0.0843],\n",
       "                       [-0.1881, -0.1641, -0.0539, -0.1637,  0.0374, -0.0814, -0.0522, -0.0588,\n",
       "                         0.1276,  0.0165, -0.0927,  0.1324, -0.1111, -0.1261,  0.1030, -0.1755,\n",
       "                        -0.2051, -0.0392, -0.2129,  0.0666],\n",
       "                       [-0.1900, -0.1300, -0.0040,  0.0575, -0.0201,  0.0941,  0.1568, -0.1929,\n",
       "                         0.0944, -0.1213,  0.0817, -0.1331,  0.1065, -0.0080,  0.1604, -0.1616,\n",
       "                        -0.0328, -0.2014, -0.1373, -0.0819],\n",
       "                       [ 0.1482,  0.2094, -0.0785, -0.0511,  0.1780, -0.1063, -0.0360, -0.1058,\n",
       "                         0.2195,  0.1052,  0.1832,  0.0824,  0.0976, -0.0133, -0.0624, -0.2243,\n",
       "                         0.1695,  0.1784, -0.0714, -0.1559],\n",
       "                       [-0.1286,  0.0064, -0.0468, -0.1752,  0.1383,  0.0256, -0.1643,  0.2152,\n",
       "                        -0.0739,  0.0967,  0.1248, -0.1941, -0.1919,  0.1557,  0.0210,  0.1833,\n",
       "                         0.0115, -0.1338, -0.0518,  0.0399],\n",
       "                       [ 0.0162, -0.0381,  0.1623,  0.0032,  0.0667,  0.1169,  0.0658,  0.0953,\n",
       "                        -0.0877, -0.1585, -0.0488, -0.1755,  0.0986, -0.1484,  0.1739,  0.1849,\n",
       "                         0.2202,  0.0781,  0.0277, -0.0163],\n",
       "                       [-0.1345, -0.1022, -0.0045, -0.2129,  0.2239,  0.1811, -0.2000,  0.1098,\n",
       "                         0.1799, -0.2049,  0.0520,  0.2039,  0.1475,  0.2086,  0.1844, -0.1670,\n",
       "                        -0.2015,  0.0047,  0.1388, -0.2080],\n",
       "                       [ 0.1524,  0.1601,  0.0446,  0.0788, -0.1757,  0.0596, -0.2190, -0.1508,\n",
       "                        -0.1367, -0.0794,  0.1921,  0.0253, -0.1903, -0.1723, -0.1351, -0.1288,\n",
       "                         0.1976, -0.2148,  0.0538,  0.1634],\n",
       "                       [ 0.1190, -0.1434, -0.0671, -0.1745, -0.2168,  0.0828,  0.0672, -0.1831,\n",
       "                         0.0392,  0.0597,  0.0281, -0.1909, -0.2025,  0.0392, -0.0932,  0.1755,\n",
       "                        -0.0038,  0.1862, -0.0816,  0.2047],\n",
       "                       [ 0.0696,  0.1130,  0.0019,  0.0422,  0.2017,  0.1008,  0.0221,  0.1758,\n",
       "                         0.0494, -0.1457, -0.1127,  0.0528, -0.0532,  0.0019,  0.0231,  0.1875,\n",
       "                         0.2229,  0.1283,  0.1054,  0.0800],\n",
       "                       [ 0.1346, -0.0806,  0.1092,  0.2071,  0.1167, -0.2005,  0.0411, -0.1523,\n",
       "                         0.0115, -0.0311,  0.0312,  0.1526,  0.1764,  0.1847,  0.1449, -0.2164,\n",
       "                         0.1783, -0.1066,  0.1967,  0.1437],\n",
       "                       [ 0.0007,  0.1096, -0.0527, -0.0232, -0.0569, -0.1787,  0.1517, -0.0059,\n",
       "                         0.0550, -0.0779, -0.0253, -0.0918, -0.0675, -0.1147, -0.0530, -0.1036,\n",
       "                        -0.1634,  0.0844, -0.1862,  0.1338],\n",
       "                       [ 0.0970, -0.0066, -0.1690, -0.0769,  0.2335, -0.0926, -0.1388, -0.0980,\n",
       "                         0.1786,  0.0742, -0.1334,  0.0193, -0.2025, -0.0836, -0.0706,  0.1057,\n",
       "                         0.1478, -0.0122,  0.1083, -0.0427],\n",
       "                       [-0.0004,  0.0411, -0.1592, -0.1874, -0.0723,  0.0507, -0.1969, -0.0475,\n",
       "                        -0.0728, -0.1154,  0.0801,  0.1113,  0.0675,  0.0153,  0.1392, -0.0457,\n",
       "                         0.1691, -0.0016,  0.0903,  0.1874],\n",
       "                       [-0.0700, -0.0538, -0.0419, -0.0355,  0.1056,  0.0964,  0.2055, -0.0586,\n",
       "                         0.1334,  0.2198, -0.1092,  0.1019,  0.1131, -0.1899,  0.0994, -0.0247,\n",
       "                         0.1015,  0.2091,  0.2024,  0.1494]])),\n",
       "              ('backbone2.model.layer3.fc3.bias',\n",
       "               tensor([ 0.0662,  0.0163,  0.0947, -0.1570,  0.0678,  0.1988,  0.0858, -0.1466,\n",
       "                        0.1645,  0.0219, -0.0028, -0.0014,  0.1556, -0.1881, -0.0803,  0.1705,\n",
       "                       -0.2064,  0.2034,  0.0128,  0.0035])),\n",
       "              ('backbone2.model.layer4.fc4.weight',\n",
       "               tensor([[ 0.0970, -0.1843, -0.0003, -0.0874,  0.0217, -0.0215,  0.1460, -0.1977,\n",
       "                         0.0453, -0.0083, -0.0909, -0.1102, -0.0928,  0.0420,  0.1307,  0.1875,\n",
       "                        -0.1243, -0.1405, -0.1067, -0.1995]])),\n",
       "              ('backbone3.model.layer0.fc0.weight',\n",
       "               tensor([[ 0.2297, -0.5510],\n",
       "                       [-0.3480,  0.3782],\n",
       "                       [ 0.4928, -0.4464],\n",
       "                       [-0.5296,  0.3571],\n",
       "                       [-0.1502, -0.1191],\n",
       "                       [-0.1988,  0.2671],\n",
       "                       [-0.2016,  0.6540],\n",
       "                       [ 0.0017, -0.4985],\n",
       "                       [-0.2752, -0.1680],\n",
       "                       [ 0.2184,  0.6002],\n",
       "                       [ 0.4733,  0.6255],\n",
       "                       [ 0.3647,  0.3922],\n",
       "                       [-0.0425, -0.1035],\n",
       "                       [ 0.0744, -0.1441],\n",
       "                       [-0.3468,  0.2387],\n",
       "                       [-0.6543, -0.0038],\n",
       "                       [-0.2354,  0.0725],\n",
       "                       [-0.3097,  0.3095],\n",
       "                       [ 0.4672,  0.5250],\n",
       "                       [ 0.1062, -0.1356]])),\n",
       "              ('backbone3.model.layer0.fc0.bias',\n",
       "               tensor([-0.1601,  0.3569, -0.3627, -0.0569,  0.1696,  0.4490, -0.0693, -0.0019,\n",
       "                       -0.5115,  0.3160,  0.1482, -0.3318, -0.0477, -0.6896,  0.5356, -0.3865,\n",
       "                        0.3001, -0.4626, -0.4568,  0.0993])),\n",
       "              ('backbone3.model.layer1.fc1.weight',\n",
       "               tensor([[-0.2581, -0.1974, -0.1728,  0.2313, -0.0093, -0.0493,  0.1577,  0.1957,\n",
       "                        -0.1414, -0.2422,  0.1102,  0.0865,  0.0699,  0.0191,  0.0094, -0.0704,\n",
       "                        -0.0391,  0.0198,  0.0595,  0.1815],\n",
       "                       [-0.0783, -0.1019, -0.1555,  0.0774, -0.2244,  0.1683, -0.0541, -0.0901,\n",
       "                        -0.0792, -0.0616,  0.0843,  0.2080,  0.1220,  0.0437,  0.2063,  0.1455,\n",
       "                         0.1319,  0.0919, -0.0301,  0.1514],\n",
       "                       [ 0.1237,  0.0403,  0.0067, -0.0109, -0.1383, -0.1746, -0.2075, -0.1490,\n",
       "                        -0.1660,  0.1966, -0.2110, -0.1467,  0.0582,  0.0705,  0.0452,  0.0521,\n",
       "                         0.1499, -0.0014, -0.0607,  0.0122],\n",
       "                       [-0.2423, -0.2387, -0.1036, -0.0784, -0.1495,  0.1536,  0.2256,  0.1681,\n",
       "                         0.0278, -0.1238,  0.1802,  0.2125, -0.1710, -0.0976, -0.1189,  0.1834,\n",
       "                         0.1390, -0.1212,  0.0221, -0.1018],\n",
       "                       [-0.1443,  0.0378,  0.1776,  0.0676,  0.0465,  0.0043, -0.0056, -0.1146,\n",
       "                         0.1370,  0.1004,  0.0826, -0.0415,  0.0050,  0.0115, -0.2207,  0.0121,\n",
       "                        -0.2505, -0.1337, -0.0127, -0.0968],\n",
       "                       [-0.0700,  0.0382, -0.1596,  0.1511, -0.1806,  0.1523, -0.0935,  0.0905,\n",
       "                         0.0512,  0.1363, -0.0716,  0.0923, -0.1576, -0.0190, -0.1476,  0.1523,\n",
       "                        -0.0512,  0.0488, -0.0981, -0.1180],\n",
       "                       [-0.0126,  0.1196,  0.1821,  0.0189,  0.1361, -0.1877, -0.0141, -0.1257,\n",
       "                        -0.1360,  0.0074, -0.1727, -0.1137,  0.0105, -0.0139, -0.0716,  0.1034,\n",
       "                         0.1654,  0.1549,  0.2021, -0.1620],\n",
       "                       [-0.0953,  0.0510, -0.0826, -0.0755,  0.2222, -0.1696,  0.1475, -0.1349,\n",
       "                        -0.1181,  0.2425, -0.1832,  0.0426, -0.2455,  0.1101,  0.1375, -0.0726,\n",
       "                         0.2241, -0.1375, -0.2004,  0.1718],\n",
       "                       [ 0.1744,  0.2174, -0.0345,  0.1879,  0.1247,  0.0792, -0.1907, -0.0020,\n",
       "                         0.1828, -0.1193, -0.1397, -0.0847, -0.1465,  0.1352, -0.0652, -0.1891,\n",
       "                        -0.1986, -0.0504,  0.0320, -0.1111],\n",
       "                       [-0.0397,  0.1210, -0.0186, -0.1250, -0.2291, -0.2606,  0.2411,  0.2129,\n",
       "                        -0.1634, -0.0668,  0.0682,  0.1298, -0.1292,  0.2448,  0.0306,  0.0369,\n",
       "                         0.0442, -0.1620,  0.1037, -0.0354],\n",
       "                       [ 0.1160,  0.0945, -0.0502, -0.0619, -0.1904,  0.0016, -0.1153, -0.2347,\n",
       "                        -0.1832,  0.0081,  0.2056,  0.0926,  0.0044, -0.1905, -0.0603,  0.2111,\n",
       "                         0.1778, -0.0138,  0.0755, -0.1112],\n",
       "                       [-0.1752,  0.1384, -0.0746, -0.0151,  0.0047, -0.1646,  0.0279, -0.0842,\n",
       "                        -0.0984,  0.1632, -0.0543, -0.0949, -0.1351, -0.1130,  0.1157, -0.0899,\n",
       "                        -0.0973,  0.1729,  0.0901,  0.2369],\n",
       "                       [-0.1582,  0.1276,  0.1789,  0.0507,  0.0917, -0.0608,  0.2250, -0.1410,\n",
       "                        -0.1908,  0.0137,  0.0178,  0.0721, -0.0772, -0.1410,  0.1174, -0.0782,\n",
       "                         0.0486,  0.1051, -0.1416, -0.0387],\n",
       "                       [-0.1222,  0.0250,  0.0587, -0.2010, -0.1873,  0.0597,  0.0217, -0.0651,\n",
       "                         0.0613,  0.1939, -0.1232,  0.1992, -0.2280, -0.1073, -0.1269, -0.1455,\n",
       "                         0.0878,  0.1051,  0.1180, -0.1549],\n",
       "                       [ 0.1467, -0.0206,  0.0965, -0.1070, -0.0376, -0.0059,  0.0098,  0.0676,\n",
       "                        -0.1752,  0.1892,  0.0588,  0.0600, -0.1048,  0.0207,  0.1865, -0.0737,\n",
       "                        -0.1960,  0.0962, -0.1073, -0.1536],\n",
       "                       [-0.1218, -0.0709,  0.1797, -0.0557, -0.0351, -0.0902, -0.0096,  0.1402,\n",
       "                         0.1106,  0.1941,  0.1146,  0.1069,  0.0903,  0.1251,  0.0070,  0.0932,\n",
       "                        -0.0290,  0.1250, -0.0719,  0.2203],\n",
       "                       [-0.1109, -0.1426, -0.2265, -0.0513, -0.1196, -0.0010,  0.0243, -0.1753,\n",
       "                        -0.0231, -0.0374,  0.0586,  0.0316,  0.0231,  0.1593, -0.0991,  0.0777,\n",
       "                        -0.0135, -0.1316,  0.1041,  0.0612],\n",
       "                       [ 0.1524,  0.1034,  0.0851, -0.1645, -0.0539,  0.0124, -0.1074, -0.0801,\n",
       "                         0.2182,  0.0886,  0.2092, -0.1775, -0.0851, -0.0199, -0.0821, -0.2069,\n",
       "                         0.1833, -0.1760, -0.1248, -0.1907],\n",
       "                       [ 0.1580,  0.1137, -0.0944,  0.0565,  0.1070, -0.0348,  0.0755, -0.0937,\n",
       "                         0.0965, -0.0772,  0.0697,  0.0885, -0.2049, -0.1107,  0.0396, -0.0233,\n",
       "                         0.1733, -0.1968, -0.1211,  0.0990],\n",
       "                       [ 0.0029,  0.1388, -0.1607, -0.2311,  0.0545,  0.1796, -0.1889,  0.1573,\n",
       "                         0.1746,  0.0993, -0.0026, -0.1174,  0.1155,  0.0757, -0.0257, -0.2292,\n",
       "                        -0.0786,  0.1831,  0.2049, -0.0339]])),\n",
       "              ('backbone3.model.layer1.fc1.bias',\n",
       "               tensor([ 0.0806,  0.1990,  0.0980, -0.0929,  0.0322,  0.0006,  0.1434, -0.1208,\n",
       "                        0.1301,  0.0242, -0.2110,  0.0803,  0.1639, -0.1773,  0.0503,  0.2144,\n",
       "                       -0.0706, -0.1099, -0.1725, -0.1063])),\n",
       "              ('backbone3.model.layer2.fc2.weight',\n",
       "               tensor([[ 1.3840e-01, -1.3910e-01,  5.9168e-02,  1.7266e-01,  1.3616e-01,\n",
       "                         5.3194e-02, -1.7261e-01, -7.2187e-02,  4.2486e-02, -9.3999e-02,\n",
       "                         1.6776e-01, -5.5093e-02, -2.1475e-01, -1.1276e-02,  1.9905e-01,\n",
       "                        -2.2329e-01,  2.0128e-01, -7.8796e-02, -3.3531e-02, -1.2002e-01],\n",
       "                       [ 1.3242e-01, -1.1025e-01, -9.8789e-02, -1.7256e-01,  8.2109e-02,\n",
       "                        -3.3111e-02, -5.0420e-02, -1.9381e-01, -8.9141e-02, -2.0026e-01,\n",
       "                         1.5506e-01,  2.0451e-01, -1.3938e-01, -9.0464e-02, -1.9037e-01,\n",
       "                        -1.8730e-01, -2.0558e-01,  1.9621e-01, -1.1357e-01, -3.0987e-02],\n",
       "                       [ 2.1505e-01, -1.3501e-01, -2.0691e-01,  4.2439e-02, -1.0216e-01,\n",
       "                         8.6935e-03,  1.5992e-01, -5.1841e-02, -1.4048e-01,  1.4055e-01,\n",
       "                         1.4705e-01,  1.5270e-01,  1.3431e-01, -1.2354e-02,  2.1891e-01,\n",
       "                        -7.4812e-02,  1.7643e-01, -3.8389e-02, -1.9284e-01, -1.7435e-01],\n",
       "                       [ 1.6261e-01,  7.7316e-02,  7.5385e-03,  8.9676e-02,  1.4907e-01,\n",
       "                         1.2614e-01, -1.1762e-01,  1.3541e-01,  1.3464e-01,  1.2599e-01,\n",
       "                        -1.2307e-02,  1.9271e-01,  1.8331e-01,  1.2368e-01,  8.1865e-03,\n",
       "                        -3.2908e-02, -1.6842e-01,  6.8114e-02, -1.8607e-01, -5.3528e-02],\n",
       "                       [ 3.3002e-02, -8.2329e-02,  1.3551e-01, -1.7409e-02,  2.0619e-01,\n",
       "                         5.4064e-02,  4.2324e-02,  1.4819e-01, -2.0041e-01, -9.3423e-02,\n",
       "                         1.4455e-01,  3.1148e-02,  1.6598e-01,  8.4807e-02, -1.5710e-01,\n",
       "                         1.6895e-01, -2.0922e-01, -1.5085e-02, -8.4616e-02, -1.7133e-01],\n",
       "                       [ 1.0333e-01,  2.4095e-01, -8.4702e-02, -1.6358e-01, -2.3836e-02,\n",
       "                        -1.8652e-01,  1.2019e-01,  4.3269e-02, -4.1148e-02, -2.2880e-02,\n",
       "                         2.5118e-01,  8.3306e-02,  2.3040e-01,  6.7205e-03, -1.6238e-01,\n",
       "                         2.3394e-01,  1.0813e-01, -1.3130e-01,  6.1175e-02, -1.4947e-01],\n",
       "                       [-4.9942e-02,  9.6395e-02, -1.6621e-01,  1.6695e-01, -5.0882e-03,\n",
       "                         8.2445e-02,  5.6534e-04,  8.7531e-02, -2.2382e-02, -1.1851e-01,\n",
       "                         1.7539e-01, -2.0533e-01,  5.0413e-02,  1.5403e-02, -8.8530e-02,\n",
       "                         4.5952e-02,  1.7730e-01,  8.3756e-02, -8.4950e-02, -9.3656e-02],\n",
       "                       [ 1.8333e-01,  1.0696e-01,  4.8610e-02, -1.1122e-01, -1.9768e-01,\n",
       "                         1.4526e-01, -1.8734e-01,  2.0508e-01, -1.3349e-01,  1.1313e-01,\n",
       "                        -1.4648e-02, -2.1227e-01, -1.6408e-01, -1.8811e-01,  1.2880e-01,\n",
       "                         7.9908e-02,  1.7559e-01,  1.8240e-01, -1.5533e-01, -1.3089e-01],\n",
       "                       [-8.2114e-02,  1.7974e-01,  1.6904e-01,  9.8578e-04, -9.0095e-02,\n",
       "                        -9.7144e-02, -6.9944e-03, -2.1894e-01,  4.6163e-02,  1.4159e-01,\n",
       "                         9.0691e-02, -2.2503e-01, -7.6050e-02,  6.3623e-02, -3.2491e-02,\n",
       "                        -1.6964e-02,  1.3614e-01, -1.6270e-02,  1.6045e-01,  6.5977e-02],\n",
       "                       [-1.6969e-01,  2.3671e-01,  1.9743e-01, -1.6091e-01,  5.2058e-02,\n",
       "                        -7.2160e-02,  2.4762e-02,  1.8312e-01, -4.0631e-03,  2.2187e-02,\n",
       "                         1.5083e-01, -1.4075e-01,  1.8637e-01,  1.4931e-01,  5.7996e-02,\n",
       "                         1.0030e-01,  1.2923e-01,  1.9662e-01,  1.8631e-01,  8.1368e-02],\n",
       "                       [-3.7082e-02,  1.5032e-01,  1.8019e-01,  1.0796e-01,  1.5259e-01,\n",
       "                         1.6036e-01, -2.0514e-01, -5.6758e-02,  1.5405e-01, -1.5002e-01,\n",
       "                         8.6699e-03,  7.8103e-02, -1.5649e-01, -1.2478e-01,  1.2680e-01,\n",
       "                         3.9726e-02, -7.4635e-02, -6.8357e-02, -7.3341e-03,  5.7436e-02],\n",
       "                       [ 4.7740e-02, -1.6359e-01,  1.0164e-01,  1.5671e-01,  6.0615e-02,\n",
       "                         6.6856e-02, -2.1481e-02,  2.4461e-03,  1.7894e-01,  6.9315e-02,\n",
       "                        -6.3136e-02,  1.2366e-01,  2.0493e-02,  4.5826e-02,  1.5848e-01,\n",
       "                        -1.2901e-01, -5.1242e-03, -1.9980e-01, -8.9141e-02,  1.1178e-01],\n",
       "                       [ 3.3051e-03, -5.3246e-02, -1.6272e-02, -1.8003e-01, -1.6519e-01,\n",
       "                        -1.1555e-01, -1.7800e-01, -1.5455e-01,  1.8690e-01, -1.6320e-01,\n",
       "                         1.1314e-01,  5.0245e-02,  4.2548e-03,  2.6203e-02,  2.1928e-01,\n",
       "                         6.9465e-02,  1.2452e-02, -1.9447e-01, -1.3041e-01, -6.0045e-02],\n",
       "                       [-1.4990e-01,  4.5761e-02,  1.2357e-01,  2.8624e-02, -1.2261e-01,\n",
       "                         6.2385e-02, -8.6965e-02, -1.5146e-01,  1.0745e-01,  1.9846e-01,\n",
       "                        -1.6130e-01,  1.6344e-01,  1.7644e-02,  5.8944e-02, -8.6792e-03,\n",
       "                         8.2261e-02,  2.7011e-02,  9.4255e-02,  2.2241e-03, -1.9487e-01],\n",
       "                       [-1.6707e-01,  1.5233e-02, -9.8405e-02, -2.7151e-02,  9.7828e-02,\n",
       "                         1.5601e-01, -9.8460e-02,  7.2770e-02,  1.1847e-01,  9.8802e-02,\n",
       "                        -7.6499e-02,  8.6497e-02, -1.3977e-01,  4.6273e-02,  1.5967e-01,\n",
       "                         2.6923e-02, -2.0027e-01,  7.4965e-02,  1.4248e-01,  1.1903e-01],\n",
       "                       [ 1.3070e-01,  1.8920e-01,  2.1079e-02, -1.2302e-01, -1.4240e-01,\n",
       "                         1.2349e-01, -1.1016e-01,  2.2033e-01,  1.9571e-01, -1.1268e-01,\n",
       "                         2.3787e-02,  1.0510e-01, -1.9049e-01, -3.4288e-02,  1.1264e-01,\n",
       "                         1.4778e-01, -5.5173e-02,  4.5721e-02,  1.6029e-01, -1.1563e-01],\n",
       "                       [-9.3887e-02,  1.6149e-01, -6.1646e-02,  1.8602e-01,  1.5331e-01,\n",
       "                        -1.5550e-01,  1.4259e-01,  2.1913e-01, -1.4940e-01,  1.6278e-01,\n",
       "                         1.0762e-01,  7.9664e-04, -1.8212e-01, -2.0842e-01,  2.4634e-02,\n",
       "                        -6.3602e-02,  1.5218e-01, -5.2527e-02, -5.5693e-02,  6.9344e-02],\n",
       "                       [-2.2554e-01, -1.0511e-01,  9.2662e-02,  1.3121e-02,  1.9824e-01,\n",
       "                        -1.6682e-01, -6.3266e-02, -1.3983e-01, -1.8024e-02,  1.1666e-01,\n",
       "                        -1.8849e-01,  1.9395e-01,  5.4133e-02, -1.7920e-01,  1.2387e-01,\n",
       "                        -1.3579e-01, -1.5182e-01, -1.3841e-01,  1.1732e-02,  1.1229e-01],\n",
       "                       [-1.8405e-01,  2.2285e-01,  5.5383e-02, -2.1366e-01, -1.7276e-01,\n",
       "                        -1.8130e-01,  2.8551e-02,  1.1892e-01,  8.4751e-02,  6.6602e-02,\n",
       "                        -6.4134e-02, -2.0609e-01,  1.4124e-01, -1.7321e-01,  5.9806e-02,\n",
       "                         7.7143e-02, -4.5831e-02, -3.7443e-02, -2.0507e-01, -6.4227e-02],\n",
       "                       [ 1.3628e-01,  9.9400e-02, -2.1033e-01,  7.2723e-02,  1.8623e-01,\n",
       "                         1.4975e-01,  7.7731e-02, -1.7007e-01, -2.3380e-04,  4.3888e-03,\n",
       "                         1.6639e-01, -1.0513e-01,  5.9787e-02, -1.1525e-01,  7.6525e-02,\n",
       "                        -1.2597e-01,  1.8941e-01, -1.5723e-03,  1.5277e-01, -1.5699e-01]])),\n",
       "              ('backbone3.model.layer2.fc2.bias',\n",
       "               tensor([ 0.1464,  0.0151, -0.0225,  0.1584, -0.0758, -0.0971,  0.0880, -0.0094,\n",
       "                        0.2095, -0.1943, -0.0216,  0.1487, -0.0547, -0.0614, -0.0430, -0.1369,\n",
       "                       -0.1123, -0.0931, -0.1499,  0.1979])),\n",
       "              ('backbone3.model.layer3.fc3.weight',\n",
       "               tensor([[ 0.0694,  0.1493, -0.0783,  0.0487, -0.1130, -0.1699, -0.0069,  0.0748,\n",
       "                        -0.0375, -0.2039,  0.1101, -0.1463, -0.0342,  0.0159, -0.0741, -0.1660,\n",
       "                        -0.0111,  0.2738,  0.0032, -0.0317],\n",
       "                       [ 0.0009, -0.1389,  0.1825, -0.1887,  0.1876, -0.0983, -0.1765,  0.1643,\n",
       "                        -0.2033,  0.0797,  0.0322,  0.1270,  0.1929,  0.1825,  0.1034,  0.1604,\n",
       "                         0.0905,  0.0057, -0.1335,  0.1784],\n",
       "                       [-0.0042,  0.0772, -0.2414, -0.1280,  0.1027, -0.1451,  0.0272, -0.0739,\n",
       "                         0.1121, -0.1560, -0.0492, -0.0296,  0.2064,  0.0529,  0.2104,  0.1835,\n",
       "                         0.1897,  0.0804,  0.2113, -0.2154],\n",
       "                       [ 0.0671, -0.1004, -0.1357, -0.0993,  0.0993, -0.0187,  0.1269,  0.1269,\n",
       "                        -0.0289, -0.0310, -0.2220,  0.0107,  0.0341,  0.1289, -0.1716, -0.0091,\n",
       "                        -0.0339, -0.1682, -0.1935,  0.1040],\n",
       "                       [-0.1884, -0.0086,  0.1033, -0.1358, -0.1838,  0.0432, -0.1642,  0.1921,\n",
       "                        -0.0393,  0.0335,  0.0081,  0.1571,  0.0612, -0.0228, -0.0147,  0.1722,\n",
       "                         0.2324, -0.2734, -0.0890,  0.1853],\n",
       "                       [-0.0765, -0.1393, -0.1326, -0.1792,  0.0822,  0.0844, -0.0203, -0.0383,\n",
       "                        -0.2127, -0.2216, -0.0431, -0.1488,  0.1585,  0.0946, -0.2119,  0.1824,\n",
       "                        -0.0631,  0.1006, -0.0872, -0.0567],\n",
       "                       [-0.1627, -0.0029, -0.0298,  0.1672, -0.1145,  0.1085,  0.1865, -0.1334,\n",
       "                         0.2112,  0.0425, -0.1883, -0.1189, -0.1008,  0.0397,  0.1053, -0.0079,\n",
       "                         0.1555, -0.0359,  0.1634, -0.0360],\n",
       "                       [-0.0541, -0.0957,  0.0306,  0.2000,  0.0669,  0.0889,  0.1635, -0.0606,\n",
       "                        -0.0646, -0.1001, -0.0523,  0.1726,  0.1777,  0.0527, -0.0648, -0.1553,\n",
       "                         0.0851,  0.1644, -0.1750,  0.1184],\n",
       "                       [-0.0049, -0.1446,  0.1024,  0.2124, -0.1130, -0.2080, -0.2117,  0.0962,\n",
       "                        -0.1501,  0.1207, -0.0613,  0.2305,  0.1010, -0.0761,  0.1163, -0.0485,\n",
       "                         0.2118, -0.1210, -0.0234,  0.0212],\n",
       "                       [ 0.0308,  0.0820, -0.1170, -0.0808,  0.0200,  0.0165, -0.1239, -0.0661,\n",
       "                        -0.0902, -0.0723, -0.1264,  0.2008, -0.0976,  0.0421,  0.0866,  0.0854,\n",
       "                         0.0224, -0.0578, -0.0135, -0.1513],\n",
       "                       [-0.1281, -0.0315, -0.0162, -0.1392, -0.0322, -0.0190,  0.1564, -0.2060,\n",
       "                        -0.0749,  0.0155,  0.1272, -0.0513,  0.1628, -0.1005,  0.0769,  0.1812,\n",
       "                         0.2605,  0.2800,  0.1054,  0.1069],\n",
       "                       [ 0.1348, -0.0853,  0.0913, -0.1022,  0.0855,  0.1947,  0.0056, -0.2295,\n",
       "                        -0.1771, -0.1037, -0.1987,  0.1314, -0.1327, -0.0053,  0.2056,  0.0782,\n",
       "                         0.1192,  0.0417, -0.0525,  0.1388],\n",
       "                       [ 0.1399,  0.1442,  0.1794,  0.0689, -0.0608,  0.0281,  0.1752,  0.0148,\n",
       "                        -0.0359,  0.0341, -0.1545,  0.1917, -0.0974,  0.1914, -0.2129, -0.0657,\n",
       "                        -0.0995,  0.1492, -0.0953,  0.0256],\n",
       "                       [-0.1277, -0.0779,  0.0878, -0.0947, -0.2330,  0.0938,  0.1900, -0.0246,\n",
       "                        -0.1698, -0.1538,  0.1958,  0.2150,  0.0487,  0.1644,  0.0203,  0.0049,\n",
       "                         0.0066,  0.0009,  0.1253, -0.2077],\n",
       "                       [ 0.0085,  0.0176,  0.0362, -0.0047, -0.1435, -0.0919,  0.0874, -0.0608,\n",
       "                        -0.0737, -0.0094, -0.0008, -0.1121,  0.0498, -0.1319,  0.0783,  0.1022,\n",
       "                         0.2044, -0.1174,  0.0088,  0.0868],\n",
       "                       [ 0.0573, -0.1825, -0.0054, -0.1666,  0.2687,  0.1068,  0.0378,  0.0224,\n",
       "                        -0.1586, -0.0365,  0.1465, -0.0853, -0.1848,  0.1210, -0.2208, -0.1654,\n",
       "                        -0.1358, -0.0239,  0.0905,  0.0246],\n",
       "                       [ 0.0159,  0.1811, -0.1622,  0.1864, -0.0170, -0.0646, -0.2092,  0.2031,\n",
       "                        -0.1393, -0.1362, -0.0911, -0.1859, -0.1437,  0.0407, -0.0791, -0.2027,\n",
       "                         0.1279,  0.1494,  0.1873,  0.1756],\n",
       "                       [-0.0930,  0.1388, -0.0300, -0.0169, -0.1338,  0.1833,  0.1271,  0.0315,\n",
       "                        -0.0405,  0.2132, -0.0804,  0.0496,  0.0302,  0.0809, -0.0939, -0.1743,\n",
       "                        -0.0406, -0.1496, -0.0038, -0.0680],\n",
       "                       [-0.1813,  0.1027, -0.0561, -0.0655, -0.0404,  0.1016, -0.1418, -0.1567,\n",
       "                        -0.0169, -0.1175,  0.1265, -0.1766, -0.0268,  0.1968,  0.1393, -0.0061,\n",
       "                        -0.1637,  0.2030, -0.1546,  0.1113],\n",
       "                       [-0.0737, -0.0940, -0.0715, -0.0184,  0.0759, -0.0574, -0.1333,  0.1855,\n",
       "                        -0.0299,  0.1769, -0.0302, -0.1082,  0.0442, -0.0069, -0.0356, -0.0988,\n",
       "                         0.0542,  0.1679,  0.0544, -0.1824]])),\n",
       "              ('backbone3.model.layer3.fc3.bias',\n",
       "               tensor([ 0.1755, -0.0751,  0.1718,  0.0740,  0.1930, -0.1823,  0.1039, -0.0759,\n",
       "                       -0.0895, -0.0993,  0.1017,  0.1508, -0.1174, -0.0944,  0.0367,  0.1834,\n",
       "                       -0.0279, -0.1775, -0.1628, -0.1373])),\n",
       "              ('backbone3.model.layer4.fc4.weight',\n",
       "               tensor([[-0.1785, -0.1238,  0.1060,  0.0737,  0.1058, -0.1879, -0.1944,  0.0289,\n",
       "                        -0.1691, -0.0038,  0.0047,  0.0455,  0.1167,  0.0696, -0.1124, -0.0533,\n",
       "                         0.0044, -0.2055, -0.0153,  0.1961]])),\n",
       "              ('backbone4.model.layer0.fc0.weight',\n",
       "               tensor([[-0.0154, -0.4895],\n",
       "                       [-0.2980,  0.3981],\n",
       "                       [-0.4923, -0.0389],\n",
       "                       [ 0.0909, -0.0096],\n",
       "                       [-0.0400, -0.4709],\n",
       "                       [ 0.4935, -0.7962],\n",
       "                       [ 0.6199,  0.3764],\n",
       "                       [-0.6061, -0.5439],\n",
       "                       [-0.0541,  0.4132],\n",
       "                       [-0.1960, -0.3311],\n",
       "                       [-0.0637, -0.3512],\n",
       "                       [ 0.3969, -0.6557],\n",
       "                       [-0.5908,  0.5036],\n",
       "                       [ 0.0743,  0.4950],\n",
       "                       [-0.3201, -0.3565],\n",
       "                       [ 0.3589, -0.2546],\n",
       "                       [ 0.4155,  0.3572],\n",
       "                       [ 0.3306,  0.4936],\n",
       "                       [ 0.1498, -0.2871],\n",
       "                       [ 0.0457, -0.5861]])),\n",
       "              ('backbone4.model.layer0.fc0.bias',\n",
       "               tensor([-0.3224,  0.2585, -0.4500, -0.2636,  0.3846, -0.6319,  0.6070,  0.5026,\n",
       "                       -0.6128,  0.1388,  0.1826, -0.2173, -0.0427,  0.2877, -0.1179,  0.4756,\n",
       "                        0.2059, -0.3696, -0.4739,  0.2401])),\n",
       "              ('backbone4.model.layer1.fc1.weight',\n",
       "               tensor([[-6.6166e-02, -1.6390e-01,  1.4653e-01,  9.8480e-02, -7.9414e-02,\n",
       "                        -1.7598e-01,  1.3094e-01, -1.9318e-01,  1.8979e-01, -2.8087e-03,\n",
       "                         1.9479e-01, -1.1315e-01,  1.5379e-01,  4.0367e-02, -4.7914e-02,\n",
       "                         5.3714e-02, -1.8269e-01, -2.2321e-01,  2.1417e-02,  1.8105e-01],\n",
       "                       [ 8.4471e-02,  1.2716e-01,  8.2804e-02, -1.2942e-01, -1.8462e-01,\n",
       "                         1.3154e-01,  1.4764e-01,  2.3792e-02,  5.3528e-02, -1.5375e-01,\n",
       "                         1.0249e-01,  1.4878e-01,  1.1655e-01, -5.9133e-02,  1.1923e-02,\n",
       "                        -4.0167e-02,  2.0153e-01,  6.2879e-02,  1.4238e-01, -8.8060e-02],\n",
       "                       [ 1.3017e-01,  6.6383e-02,  1.0370e-01, -1.6583e-01, -1.1621e-01,\n",
       "                        -3.5771e-02,  1.6222e-01, -1.1024e-01,  2.5551e-03,  1.5027e-01,\n",
       "                        -4.1065e-02,  1.3705e-01,  1.4826e-01,  2.3523e-01,  1.5573e-01,\n",
       "                        -7.1813e-03, -1.7855e-01, -5.6381e-02, -7.4856e-02,  5.4362e-02],\n",
       "                       [-9.7573e-02,  1.6187e-01, -2.8126e-02, -1.2532e-01,  9.9188e-02,\n",
       "                        -9.0542e-02,  1.7230e-01, -2.7111e-02, -1.5162e-01, -1.0356e-01,\n",
       "                        -2.4395e-01, -1.6312e-01, -2.6114e-02, -1.1749e-01, -1.6652e-01,\n",
       "                        -2.0257e-02, -2.4953e-01,  6.9625e-02, -1.7067e-01, -2.2797e-01],\n",
       "                       [-5.0355e-02,  1.7078e-01,  9.4205e-02, -1.7467e-01,  1.6074e-01,\n",
       "                        -1.4971e-01,  4.0455e-02,  1.5312e-01,  2.1655e-01,  2.3450e-01,\n",
       "                        -2.3877e-02,  2.0477e-01, -2.2731e-02, -2.5364e-02,  3.8848e-02,\n",
       "                        -1.8067e-01, -2.5699e-02,  8.8995e-02,  3.1097e-02,  1.8479e-01],\n",
       "                       [ 4.7354e-02, -9.7349e-02,  1.2486e-01,  2.7406e-02,  1.8371e-01,\n",
       "                         1.9554e-01,  1.0962e-02, -9.4342e-02, -1.0381e-01,  1.4859e-01,\n",
       "                         1.6433e-02, -1.9592e-01, -1.4595e-01,  1.8702e-01,  1.3366e-01,\n",
       "                         9.4774e-02,  1.2441e-01, -6.5670e-02, -9.4528e-02, -5.6848e-02],\n",
       "                       [ 1.4387e-01, -8.9173e-03,  7.6931e-02, -8.6950e-02, -1.2037e-01,\n",
       "                        -9.8597e-02, -1.5317e-01,  1.1679e-02,  1.6567e-01, -9.3235e-02,\n",
       "                        -9.8448e-02, -2.6562e-02, -1.5516e-05,  1.5277e-02, -2.3365e-01,\n",
       "                        -6.7321e-02, -1.0715e-01,  1.3250e-02, -1.2733e-01,  1.5163e-01],\n",
       "                       [ 1.2111e-01, -1.5345e-01, -1.1707e-01, -1.0533e-01,  1.3298e-01,\n",
       "                         3.0306e-01,  1.2485e-01, -2.8435e-01,  3.8677e-02, -2.4517e-01,\n",
       "                         1.1677e-01,  1.0311e-01,  1.6603e-01, -1.7795e-01, -1.2370e-01,\n",
       "                         4.0534e-03, -6.6308e-02,  2.1098e-01, -5.4128e-02, -2.2423e-01],\n",
       "                       [-4.9839e-02, -3.0330e-02, -7.8164e-02,  2.1041e-01, -1.9366e-01,\n",
       "                         2.0909e-01,  1.5351e-01,  6.0956e-02,  2.4620e-01, -9.4805e-02,\n",
       "                        -1.1744e-01, -2.5468e-01, -1.0332e-01,  8.8131e-03,  1.0217e-01,\n",
       "                        -1.0398e-01,  2.2511e-03,  2.3278e-01, -3.3177e-02, -6.2135e-03],\n",
       "                       [ 1.8292e-02, -1.4157e-02, -2.2705e-01, -1.8588e-01, -1.2945e-01,\n",
       "                         3.8631e-02, -7.3492e-03, -8.8663e-03, -2.0458e-01,  2.1295e-02,\n",
       "                        -1.3990e-02, -1.3807e-01,  1.0678e-01, -2.1029e-03,  1.1966e-01,\n",
       "                        -6.6418e-02, -1.2591e-01, -1.9291e-02,  3.6233e-02,  2.2051e-01],\n",
       "                       [-1.1685e-01,  1.1452e-02, -2.0175e-01,  1.5850e-01,  8.0160e-02,\n",
       "                        -1.9378e-01,  1.6206e-01,  7.3142e-02, -1.9323e-01,  1.6016e-01,\n",
       "                         1.3954e-01, -9.7359e-02,  7.9626e-02,  8.1215e-02, -6.1517e-02,\n",
       "                        -5.3786e-02, -7.6293e-02,  1.8609e-01, -1.4415e-01, -1.4242e-01],\n",
       "                       [ 1.9569e-02,  1.4235e-01, -2.0541e-01, -3.4280e-03, -9.5605e-02,\n",
       "                        -1.4892e-01,  2.2709e-02, -6.8772e-03,  1.0573e-01,  2.5979e-02,\n",
       "                        -1.0596e-01,  1.0048e-01, -5.8062e-02,  2.1351e-01,  2.2334e-01,\n",
       "                        -1.5476e-02, -5.8998e-02,  2.2101e-01,  1.0277e-01,  1.6730e-01],\n",
       "                       [-2.9631e-02,  1.3253e-01, -4.1708e-02,  3.8081e-02,  1.1621e-01,\n",
       "                         1.2583e-01,  1.3050e-01, -2.0536e-02, -5.1717e-02, -5.3328e-02,\n",
       "                        -8.9543e-02,  1.3592e-01, -7.6782e-02,  1.3440e-01,  2.1991e-01,\n",
       "                        -1.2321e-02, -8.8287e-02,  1.5680e-01, -2.1245e-01,  5.0083e-02],\n",
       "                       [-9.8790e-02, -1.2586e-01, -2.3993e-02, -1.2588e-01, -9.2258e-03,\n",
       "                         1.5216e-01,  1.1415e-02, -9.5384e-02,  8.9886e-02,  1.9135e-01,\n",
       "                        -2.1565e-02,  2.1140e-01,  2.4223e-02, -1.3407e-01, -1.8610e-01,\n",
       "                         4.0451e-02, -1.4644e-01,  8.2776e-02,  1.3866e-01, -1.6052e-01],\n",
       "                       [-9.5228e-02,  9.8131e-02, -1.6003e-02,  1.5578e-01, -2.3710e-01,\n",
       "                         2.5079e-01,  1.7126e-01,  4.7154e-02,  2.0912e-01, -3.3236e-03,\n",
       "                         9.8692e-03,  1.6021e-01, -4.9074e-02, -2.4271e-01, -1.1373e-01,\n",
       "                         1.8157e-02, -2.4759e-01,  2.1255e-02, -6.8194e-02, -3.0928e-02],\n",
       "                       [-1.0834e-01,  7.0901e-02, -1.4150e-01,  7.1794e-02,  6.9498e-03,\n",
       "                         2.2669e-02, -1.3299e-01,  1.7593e-01, -1.6933e-01, -1.0210e-01,\n",
       "                        -8.3524e-02,  1.7143e-01, -4.9050e-02,  1.8321e-01,  2.1300e-01,\n",
       "                         8.5946e-02,  2.9729e-03,  1.6845e-01, -1.6504e-01, -6.5904e-03],\n",
       "                       [-4.2705e-02, -8.6891e-02, -4.4803e-02, -1.7156e-01,  1.7423e-01,\n",
       "                         2.0799e-01, -1.4196e-02,  1.7490e-01, -1.3003e-01,  1.3961e-01,\n",
       "                        -4.9176e-02, -1.5327e-01, -6.1853e-02, -1.5949e-01, -1.0240e-01,\n",
       "                        -7.9614e-02,  2.1876e-01, -1.0806e-02, -1.0644e-01, -1.9199e-01],\n",
       "                       [-1.0352e-01, -1.4358e-01,  8.2481e-02,  1.9944e-01,  1.0559e-01,\n",
       "                         9.1591e-02, -1.4260e-01, -5.8654e-02, -7.5610e-02,  1.8487e-01,\n",
       "                        -2.2249e-01,  7.8531e-02, -1.3455e-01, -1.0502e-01, -2.0118e-01,\n",
       "                         2.1073e-01, -1.3805e-01,  1.3631e-01,  1.2945e-01,  2.0525e-01],\n",
       "                       [-1.7848e-01,  1.9127e-01,  1.3663e-01,  4.0345e-02,  4.9630e-02,\n",
       "                         2.3967e-01,  1.2982e-01,  3.3339e-02, -1.5220e-01,  7.8522e-03,\n",
       "                         7.7092e-03, -2.4392e-02, -8.1364e-02,  4.9825e-02,  9.6244e-03,\n",
       "                        -1.4192e-01, -7.4288e-02, -9.8871e-02,  1.0569e-01,  4.4777e-04],\n",
       "                       [-1.2435e-01, -1.0425e-01, -1.8117e-01,  1.9130e-02, -2.1752e-02,\n",
       "                        -1.8156e-01, -9.3873e-02,  7.3016e-02, -1.8096e-01,  8.0395e-02,\n",
       "                         5.6006e-02,  5.7305e-02, -2.1246e-01,  1.7333e-01, -1.3368e-01,\n",
       "                         1.6538e-01, -1.6137e-01,  8.2982e-02,  5.9511e-02, -1.4386e-01]])),\n",
       "              ('backbone4.model.layer1.fc1.bias',\n",
       "               tensor([ 0.1272,  0.1215,  0.0582, -0.1582, -0.0458,  0.1473,  0.0859,  0.1059,\n",
       "                        0.0703, -0.0941, -0.1337, -0.0557, -0.0262,  0.2447,  0.1385, -0.0077,\n",
       "                       -0.1708, -0.0197,  0.0740, -0.0443])),\n",
       "              ('backbone4.model.layer2.fc2.weight',\n",
       "               tensor([[-0.1190, -0.1164, -0.1503,  0.0181,  0.2051,  0.0198,  0.1941,  0.0283,\n",
       "                         0.0957, -0.1281, -0.0856,  0.0713, -0.0142, -0.1242,  0.0691, -0.1317,\n",
       "                         0.0370, -0.0726, -0.0482,  0.1999],\n",
       "                       [-0.1435, -0.1632,  0.1480, -0.0444,  0.0334, -0.0551, -0.1586, -0.2258,\n",
       "                         0.1473, -0.1664,  0.1637,  0.0737,  0.0105,  0.0832,  0.0783, -0.2081,\n",
       "                         0.1261,  0.1799,  0.1731,  0.0982],\n",
       "                       [-0.2017, -0.0377,  0.0579, -0.0791, -0.1528,  0.0776, -0.1156, -0.1913,\n",
       "                        -0.1286,  0.1494,  0.0380,  0.0699, -0.0107,  0.0404, -0.0932,  0.0444,\n",
       "                         0.1564, -0.0674,  0.0891,  0.1518],\n",
       "                       [ 0.0204,  0.0155, -0.0187,  0.1652,  0.1597,  0.0751, -0.1651,  0.1731,\n",
       "                         0.0274,  0.0531, -0.1765,  0.0430,  0.0556,  0.1973,  0.1280, -0.0206,\n",
       "                        -0.0228,  0.1301, -0.0934,  0.1911],\n",
       "                       [ 0.0640,  0.2007,  0.1745,  0.0176,  0.2151, -0.0722, -0.1041, -0.1590,\n",
       "                        -0.1338, -0.0275,  0.2007, -0.0288,  0.1778,  0.2142, -0.0800, -0.1288,\n",
       "                         0.2670,  0.0831, -0.1384,  0.0587],\n",
       "                       [ 0.2054,  0.0149, -0.1386,  0.0240,  0.0765,  0.0069, -0.0612,  0.1565,\n",
       "                         0.0126,  0.1737,  0.0697, -0.1277,  0.0342, -0.0752,  0.1459,  0.1717,\n",
       "                         0.2003,  0.1152, -0.1302, -0.1847],\n",
       "                       [-0.1077, -0.2002,  0.1554,  0.1231,  0.0883, -0.2322, -0.0440,  0.0247,\n",
       "                         0.0304, -0.1086, -0.1530, -0.0499, -0.1895, -0.0690, -0.0361, -0.0190,\n",
       "                        -0.0755,  0.1903,  0.0959, -0.0240],\n",
       "                       [-0.1195,  0.2091,  0.1804, -0.0835, -0.2287, -0.1518,  0.1905,  0.1054,\n",
       "                        -0.1443,  0.1470, -0.1861,  0.0680,  0.1112,  0.1481,  0.0232, -0.0654,\n",
       "                        -0.1551, -0.0944, -0.0117, -0.0959],\n",
       "                       [ 0.0636, -0.1870,  0.1659, -0.1849,  0.1997,  0.1722,  0.1411, -0.1880,\n",
       "                         0.1063, -0.1349, -0.0612, -0.0478, -0.0569,  0.0916, -0.0522, -0.1684,\n",
       "                        -0.0699,  0.0833,  0.1628, -0.2236],\n",
       "                       [-0.1856, -0.0623, -0.0969, -0.0769, -0.0827,  0.1262, -0.1035, -0.1242,\n",
       "                         0.1862,  0.0746,  0.0690, -0.0450, -0.0096, -0.1168,  0.1695,  0.0980,\n",
       "                        -0.1453,  0.1018, -0.0406,  0.0714],\n",
       "                       [-0.1667,  0.1549, -0.0642, -0.1678,  0.1939,  0.0875,  0.0128,  0.1828,\n",
       "                        -0.0236,  0.1507,  0.1723, -0.0849,  0.0309, -0.2239, -0.1179, -0.1953,\n",
       "                         0.0341, -0.0399,  0.1321, -0.2258],\n",
       "                       [ 0.1963, -0.1303, -0.2042,  0.1914, -0.1901,  0.0377, -0.0544,  0.0647,\n",
       "                         0.0673, -0.1058,  0.1317,  0.0095, -0.0706,  0.0041, -0.2220, -0.0772,\n",
       "                         0.1597, -0.1639,  0.1605,  0.1623],\n",
       "                       [-0.0648,  0.0233,  0.1587,  0.1908, -0.1186,  0.1642, -0.1061, -0.0207,\n",
       "                        -0.0680,  0.0406,  0.0942, -0.0562, -0.1474,  0.1312, -0.0193, -0.0558,\n",
       "                         0.0953,  0.0587, -0.1597,  0.1766],\n",
       "                       [-0.2215,  0.2032,  0.2000, -0.1267, -0.0413, -0.0958,  0.0504, -0.1025,\n",
       "                        -0.0595,  0.1628,  0.1687, -0.1357,  0.2081,  0.0620,  0.0727,  0.1833,\n",
       "                        -0.1541,  0.1583, -0.0604,  0.0177],\n",
       "                       [-0.0370,  0.1507,  0.0689,  0.1234,  0.1509,  0.0572, -0.0317,  0.0715,\n",
       "                        -0.0093, -0.1591, -0.1082,  0.0420,  0.0406,  0.1782, -0.0261, -0.0620,\n",
       "                         0.1206,  0.0693, -0.0264, -0.0182],\n",
       "                       [ 0.1034,  0.1458,  0.2063,  0.1601,  0.0826,  0.2136, -0.0334,  0.1395,\n",
       "                         0.2197,  0.1769, -0.0249,  0.2123,  0.1369,  0.2195,  0.0974, -0.1208,\n",
       "                         0.1055,  0.0933, -0.1361,  0.1719],\n",
       "                       [-0.0015,  0.0063,  0.0199, -0.1101,  0.0697, -0.2159,  0.1930,  0.0951,\n",
       "                        -0.0470,  0.1810,  0.0183, -0.0619, -0.1678,  0.1226, -0.1665, -0.0436,\n",
       "                        -0.1725, -0.0392,  0.1610, -0.0854],\n",
       "                       [-0.0721,  0.1533, -0.1343, -0.1930,  0.0267,  0.0635, -0.1472, -0.1551,\n",
       "                         0.0926,  0.1168, -0.1891, -0.0453,  0.0777, -0.2030,  0.0596,  0.2171,\n",
       "                        -0.0889,  0.0071,  0.0607,  0.0148],\n",
       "                       [-0.0914,  0.0263, -0.0696, -0.1188,  0.0707,  0.1635,  0.1240, -0.2155,\n",
       "                         0.1350, -0.0131,  0.0753, -0.2497, -0.1305, -0.0761,  0.0945, -0.0500,\n",
       "                        -0.0955,  0.1124, -0.0623, -0.2062],\n",
       "                       [ 0.2002,  0.1284,  0.1599,  0.1494, -0.0950,  0.1443, -0.1935, -0.2189,\n",
       "                         0.0712,  0.2025, -0.0102, -0.1757, -0.1651,  0.0052, -0.0793, -0.0021,\n",
       "                         0.1289,  0.0633, -0.2083,  0.0079]])),\n",
       "              ('backbone4.model.layer2.fc2.bias',\n",
       "               tensor([ 0.0703,  0.0989, -0.1981, -0.1293, -0.1089,  0.0240,  0.1449,  0.0439,\n",
       "                        0.1492,  0.1007,  0.0902, -0.1589, -0.1471,  0.1188,  0.2034,  0.0397,\n",
       "                       -0.0929,  0.0757,  0.1081, -0.1555])),\n",
       "              ('backbone4.model.layer3.fc3.weight',\n",
       "               tensor([[-1.1558e-01, -1.6657e-01, -3.5726e-02, -1.0781e-01,  6.3299e-02,\n",
       "                         1.7170e-01,  1.8239e-01, -1.8367e-01, -2.2027e-01, -1.7512e-02,\n",
       "                        -3.9834e-03, -1.5710e-01,  8.1360e-02, -5.3820e-02,  6.3546e-02,\n",
       "                        -1.1720e-01, -1.9846e-01, -1.7724e-01, -1.6901e-01, -2.1459e-01],\n",
       "                       [ 4.8558e-02,  9.3513e-04, -1.8259e-01,  5.5721e-02,  2.0365e-01,\n",
       "                         1.1977e-02, -1.5360e-01,  9.3347e-02,  1.1980e-02, -4.7982e-02,\n",
       "                        -1.6008e-02, -2.8871e-02,  1.6089e-01,  1.3812e-01, -6.2875e-03,\n",
       "                         1.5022e-01, -1.0126e-01,  1.0178e-01,  1.0819e-02,  7.3914e-04],\n",
       "                       [ 2.4204e-02,  2.0792e-02,  1.7575e-02,  2.1734e-01, -1.5474e-01,\n",
       "                         1.7996e-01,  1.2956e-01,  2.9226e-02, -1.3672e-01, -1.1141e-01,\n",
       "                         9.4503e-02, -9.3607e-02,  5.0203e-02, -1.2184e-01, -1.8722e-01,\n",
       "                        -6.7632e-02, -1.1625e-01, -2.2251e-01,  1.3567e-01,  9.3703e-02],\n",
       "                       [-1.8937e-01,  2.3736e-03,  1.2856e-02, -1.6544e-01,  2.0580e-01,\n",
       "                         3.0623e-02,  1.8471e-01, -1.8320e-01, -2.0567e-01,  1.7898e-02,\n",
       "                        -6.2291e-02, -3.6668e-02,  7.0805e-02, -1.8241e-01,  1.7361e-01,\n",
       "                        -1.4763e-01,  1.9229e-01, -9.0968e-02,  1.3124e-01,  3.4553e-02],\n",
       "                       [-9.1055e-02, -1.6013e-01,  5.9745e-02, -1.2835e-01, -1.4450e-01,\n",
       "                        -1.5739e-01,  1.4191e-01, -7.1262e-03, -1.3305e-01,  2.0632e-01,\n",
       "                        -1.9918e-01,  1.9121e-01, -2.3376e-01,  1.7408e-01,  1.1400e-01,\n",
       "                        -2.5562e-02, -1.6279e-01, -3.9422e-02,  4.9817e-03,  7.4565e-02],\n",
       "                       [-1.4103e-01, -1.2917e-01,  1.2877e-01,  7.3628e-02,  2.1290e-01,\n",
       "                         9.1244e-02,  1.8774e-02,  1.5532e-01,  6.1685e-02, -1.0356e-02,\n",
       "                         1.0399e-01,  9.8229e-02,  1.2363e-01,  1.6111e-01,  1.6644e-02,\n",
       "                         1.8497e-01, -2.1132e-01, -1.0029e-01, -1.1599e-01, -2.2074e-01],\n",
       "                       [-6.0200e-02, -6.4524e-02,  2.1021e-01,  1.6734e-01, -5.8725e-03,\n",
       "                         6.2411e-02, -1.2539e-01, -2.8820e-02, -1.6420e-02, -8.2760e-02,\n",
       "                        -5.8385e-02,  2.0131e-01, -1.2409e-01, -1.8061e-01, -4.4523e-02,\n",
       "                        -5.7615e-02, -5.6556e-02, -1.6918e-01,  1.7282e-01,  1.8469e-01],\n",
       "                       [ 1.0324e-01, -1.4480e-01, -1.2802e-01,  2.1043e-01, -1.1650e-01,\n",
       "                         2.1186e-01, -4.4132e-02, -1.1082e-01, -6.0978e-02,  7.1956e-02,\n",
       "                        -2.2753e-02,  8.0187e-02,  1.3844e-01,  4.4899e-02, -2.0476e-01,\n",
       "                         4.4124e-02, -1.3314e-01, -1.8347e-01, -7.7317e-02, -1.8707e-01],\n",
       "                       [ 1.4268e-01,  1.4190e-01,  6.7932e-02, -9.3340e-02, -1.9861e-01,\n",
       "                        -1.5322e-01,  2.2026e-02, -7.3829e-02, -2.7835e-02, -1.8133e-02,\n",
       "                        -5.8955e-02,  1.5447e-01, -2.6979e-02, -6.6229e-02, -2.0106e-01,\n",
       "                         8.1248e-02, -1.4985e-01, -2.0345e-01,  1.4567e-01, -7.8069e-02],\n",
       "                       [ 4.9632e-02, -1.4224e-01, -3.6422e-02,  9.2490e-02, -1.2511e-01,\n",
       "                         1.3711e-01, -7.8483e-02,  1.3329e-01, -1.8639e-01, -1.8524e-01,\n",
       "                        -2.6484e-01, -1.1423e-01, -1.7104e-01,  1.5338e-01,  1.1907e-01,\n",
       "                         1.0117e-01, -1.5976e-01,  1.4743e-01,  5.7038e-02, -8.5696e-02],\n",
       "                       [-5.0029e-02, -1.0191e-01,  1.4787e-01, -4.1810e-02,  1.5720e-01,\n",
       "                         1.9624e-01,  2.2772e-01, -9.3261e-02,  1.7821e-01, -8.1350e-02,\n",
       "                        -1.0876e-01,  8.7131e-02, -1.0692e-01,  1.1455e-01, -2.4313e-02,\n",
       "                        -7.4612e-02, -1.0500e-01, -1.8225e-01,  2.6309e-01,  1.0920e-01],\n",
       "                       [-1.1228e-01,  1.7167e-01,  2.1462e-01, -7.1849e-03, -6.1767e-02,\n",
       "                        -1.1234e-01,  1.3719e-01, -2.1253e-01,  1.5406e-01, -4.2880e-03,\n",
       "                         8.3905e-02,  1.3680e-01, -2.2000e-01, -1.6437e-01, -1.5324e-01,\n",
       "                         5.1665e-02, -1.8159e-01, -1.3657e-01,  1.5694e-01, -1.5424e-01],\n",
       "                       [ 6.9366e-02, -1.7366e-01,  1.5518e-01,  1.2697e-01,  3.5951e-02,\n",
       "                         1.8066e-01,  5.7963e-02, -8.8632e-02, -1.4802e-01,  6.5820e-02,\n",
       "                        -1.6338e-01,  1.4739e-01,  6.2672e-02,  1.5744e-01, -1.4107e-02,\n",
       "                         1.5783e-01, -1.3306e-01,  8.5026e-02, -1.4048e-01,  1.8464e-01],\n",
       "                       [ 3.9896e-02,  1.8985e-01,  2.2233e-01,  6.3178e-02, -2.0936e-01,\n",
       "                        -8.8693e-03,  1.1249e-01,  8.5855e-02,  5.3635e-02, -1.9109e-01,\n",
       "                         6.2435e-02, -1.8516e-01,  6.4432e-02,  1.2173e-02, -6.9844e-02,\n",
       "                        -6.8442e-02, -1.1094e-01, -7.3919e-02, -1.7001e-01,  1.9108e-01],\n",
       "                       [-1.7968e-01,  5.4910e-02,  7.1716e-03,  1.0635e-01,  1.6227e-01,\n",
       "                        -1.4169e-01, -1.3343e-01,  1.5285e-01,  5.8996e-02,  8.0566e-02,\n",
       "                         1.0489e-01, -2.3592e-01,  1.4353e-02,  1.8947e-01, -1.0386e-01,\n",
       "                        -5.0564e-02, -1.2727e-02,  2.0084e-01, -5.0540e-03,  7.3118e-02],\n",
       "                       [-2.2437e-01,  1.4229e-01, -1.3800e-01, -2.7747e-02,  2.4967e-01,\n",
       "                        -1.7441e-01, -2.3949e-01, -1.3363e-01,  1.1846e-01,  1.4942e-01,\n",
       "                        -1.3394e-01, -1.7617e-01,  1.3899e-01, -1.1530e-01,  1.3538e-01,\n",
       "                        -4.5194e-02,  1.3623e-01, -5.8698e-02, -2.9502e-02,  2.0706e-02],\n",
       "                       [ 1.8636e-01,  1.3211e-01,  2.0562e-02, -2.2139e-01,  1.5853e-01,\n",
       "                        -1.8133e-02, -2.2773e-01,  7.3371e-02,  1.5549e-01,  1.8213e-02,\n",
       "                        -7.5990e-02, -1.8089e-02,  3.3453e-02,  4.6263e-02, -5.6358e-02,\n",
       "                         7.1681e-02, -1.5431e-01, -1.5409e-01, -2.5507e-01,  9.8249e-02],\n",
       "                       [ 5.9648e-02,  6.2019e-02, -2.5749e-02,  2.5355e-01, -1.8032e-01,\n",
       "                        -7.2131e-02, -1.9800e-01,  1.1806e-01, -4.3818e-02,  3.4601e-02,\n",
       "                         2.0193e-01, -1.9333e-04,  1.7330e-01,  1.7420e-01, -1.5365e-01,\n",
       "                         1.2517e-01,  1.4774e-02, -1.4128e-01,  1.4866e-01, -4.1840e-02],\n",
       "                       [-3.5791e-03,  1.7041e-01, -6.3995e-02,  1.1890e-01, -1.3413e-01,\n",
       "                         1.0217e-01,  8.2935e-02,  2.0196e-01, -3.8861e-02,  2.2579e-01,\n",
       "                        -1.2685e-01, -2.0363e-01, -1.0582e-01, -1.1961e-02,  1.1935e-03,\n",
       "                        -1.3981e-01,  9.3895e-02,  1.8514e-02,  1.6908e-01,  9.8176e-02],\n",
       "                       [-8.2150e-02, -1.3076e-01, -1.9168e-01,  6.1441e-02,  5.1366e-02,\n",
       "                         1.7620e-01, -1.9045e-02,  1.3398e-02, -1.6339e-01,  1.0393e-02,\n",
       "                         1.8631e-01, -6.0291e-02,  3.2479e-02,  1.4681e-01,  5.6366e-02,\n",
       "                         1.3844e-01,  3.6595e-02,  2.0436e-01, -2.0208e-01, -1.5768e-01]])),\n",
       "              ('backbone4.model.layer3.fc3.bias',\n",
       "               tensor([ 0.0112,  0.0568,  0.1830,  0.1226,  0.0642,  0.2146, -0.1040,  0.1449,\n",
       "                       -0.0076, -0.0533, -0.1752, -0.0222, -0.1839, -0.2037, -0.1036,  0.0899,\n",
       "                       -0.1614,  0.0477,  0.1297,  0.1608])),\n",
       "              ('backbone4.model.layer4.fc4.weight',\n",
       "               tensor([[ 0.0176, -0.1395,  0.0040, -0.1698,  0.0496,  0.1166, -0.1892,  0.1050,\n",
       "                         0.0513, -0.0005,  0.2117, -0.0074,  0.0839, -0.2134,  0.1565, -0.0012,\n",
       "                        -0.0268,  0.0141, -0.2027, -0.1033]])),\n",
       "              ('backbone5.model.layer0.fc0.weight',\n",
       "               tensor([[ 0.3168, -0.3639],\n",
       "                       [-0.1646,  0.2250],\n",
       "                       [-0.6108,  0.3929],\n",
       "                       [ 0.7267,  0.2821],\n",
       "                       [ 0.4088,  0.5034],\n",
       "                       [-0.5004,  0.0963],\n",
       "                       [ 0.7959,  0.2759],\n",
       "                       [ 0.6414, -0.2279],\n",
       "                       [ 0.5372, -0.2926],\n",
       "                       [ 0.3252,  0.3788],\n",
       "                       [ 0.0423, -0.2840],\n",
       "                       [-0.3873, -0.2383],\n",
       "                       [ 0.0216, -1.1638],\n",
       "                       [ 0.5217,  0.2618],\n",
       "                       [ 0.8778,  0.0130],\n",
       "                       [-0.1850,  0.5542],\n",
       "                       [ 0.5544, -0.6805],\n",
       "                       [ 0.0628, -0.2225],\n",
       "                       [ 0.8183,  0.1757],\n",
       "                       [-0.5482,  0.0865]])),\n",
       "              ('backbone5.model.layer0.fc0.bias',\n",
       "               tensor([ 0.7336, -0.5803, -0.6214, -0.5072, -0.0359,  0.5152,  0.4398,  0.7505,\n",
       "                        0.4550, -0.2480, -0.2404, -0.3346, -0.3292,  0.4727,  0.7200, -0.1821,\n",
       "                       -0.5137,  0.2086, -0.5075,  0.4523])),\n",
       "              ('backbone5.model.layer1.fc1.weight',\n",
       "               tensor([[-9.8708e-02,  1.4854e-01,  1.9949e-01, -6.8589e-02, -5.9944e-02,\n",
       "                        -3.6630e-01, -1.4053e-01,  3.9898e-02,  5.6870e-02,  1.7252e-01,\n",
       "                        -2.0782e-03,  2.3775e-01,  3.2884e-02, -1.5736e-01, -1.0055e-01,\n",
       "                         2.4956e-01, -2.5509e-02,  3.6011e-02, -9.3056e-02, -1.2043e-01],\n",
       "                       [-2.1151e-01, -7.4302e-02,  2.6812e-01,  2.2028e-01,  2.7219e-01,\n",
       "                         1.5850e-01, -1.6670e-01, -5.3618e-02, -3.5711e-02,  1.1870e-01,\n",
       "                        -1.4619e-01,  1.8918e-01, -1.0769e-01, -1.8647e-01,  8.1236e-02,\n",
       "                        -1.0890e-01,  2.6066e-01, -2.0837e-01,  3.1681e-01,  1.7006e-01],\n",
       "                       [ 1.5641e-01,  1.0473e-01, -3.3292e-01,  3.1069e-01,  8.6961e-01,\n",
       "                        -3.7944e-01,  2.4222e-01,  2.4654e-01,  3.5537e-01,  1.0514e-01,\n",
       "                         1.1879e-01, -2.4685e-01, -8.0651e-02,  2.1970e-01,  1.8633e-01,\n",
       "                        -6.0084e-03,  2.0132e-01,  4.6157e-02,  7.8365e-01, -2.4007e-01],\n",
       "                       [ 2.1212e-01, -9.1071e-02,  2.0810e-01,  2.2549e-01,  4.1618e-01,\n",
       "                         4.8676e-02,  2.7620e-02, -1.4877e-01, -4.9614e-02,  2.7502e-01,\n",
       "                        -2.4058e-02,  6.4932e-03, -2.4112e-02, -8.4204e-02,  1.9606e-01,\n",
       "                        -7.1654e-02,  1.3164e-01, -1.2861e-01,  5.3924e-01, -4.5641e-02],\n",
       "                       [ 9.7538e-02, -5.0268e-02,  2.1159e-01,  2.3957e-01,  3.1663e-01,\n",
       "                         8.3489e-02,  1.8640e-01, -1.5078e-01,  1.3071e-01,  2.1511e-01,\n",
       "                         1.5469e-01,  5.0887e-02,  1.3677e-01,  8.1599e-02, -1.0256e-01,\n",
       "                         1.1472e-01,  2.4873e-01, -9.0317e-03,  9.5123e-02,  6.5341e-02],\n",
       "                       [-2.8573e-02,  9.5388e-02,  2.2365e-01, -1.0022e-01,  1.4421e-01,\n",
       "                         6.0552e-02,  1.9856e-01, -2.1804e-01, -1.7300e-02, -6.8181e-03,\n",
       "                        -1.2667e-01,  9.1195e-02,  2.0381e-01,  5.5891e-02,  1.5959e-01,\n",
       "                        -4.0547e-02, -8.9380e-04,  1.3147e-01,  3.9520e-01, -2.4479e-02],\n",
       "                       [-2.0404e-01,  2.1134e-01,  7.3611e-02,  6.0909e-02, -1.2087e-01,\n",
       "                         1.6372e-01, -2.7467e-01, -2.7398e-01, -2.1039e-02, -1.8216e-01,\n",
       "                        -5.6988e-02, -8.8907e-02,  2.2823e-01,  1.2670e-01, -2.5384e-01,\n",
       "                         1.2720e-01, -1.3202e-02, -1.7055e-03,  8.7233e-02,  8.6691e-03],\n",
       "                       [ 9.3271e-02, -2.0822e-01,  3.9416e-02, -2.0474e-01, -3.4227e-01,\n",
       "                         2.7497e-01,  1.6884e-02,  2.7587e-01, -8.1758e-02, -2.5141e-02,\n",
       "                        -1.2013e-02, -2.4160e-01, -1.3760e-01, -5.1651e-02,  1.5933e-01,\n",
       "                        -2.0179e-01, -1.2818e-01,  2.2225e-01, -8.4640e-02,  2.8068e-01],\n",
       "                       [-1.5886e-01,  1.8694e-01,  1.3009e-01,  1.5179e-01, -1.0934e-01,\n",
       "                        -8.2764e-02, -9.0998e-02, -1.1350e-01, -6.1218e-02,  1.8619e-01,\n",
       "                         1.4370e-01,  2.4036e-01,  1.7522e-01, -1.5395e-01, -1.2904e-01,\n",
       "                         2.2421e-01,  5.3629e-02, -2.1863e-01,  1.4467e-01,  7.1822e-02],\n",
       "                       [ 1.9638e-01, -2.7823e-01, -1.7459e-01, -7.1097e-02, -2.0181e-01,\n",
       "                         1.9056e-01,  1.0553e-01, -1.2969e-01,  2.8816e-01, -2.9396e-02,\n",
       "                        -1.9453e-01, -1.8029e-01,  8.9964e-02, -7.9254e-02, -4.7062e-02,\n",
       "                        -2.7140e-01, -1.7888e-01,  2.4433e-01,  6.1666e-02, -8.1171e-02],\n",
       "                       [-2.8449e-01,  2.7271e-01,  3.2245e-01, -4.5328e-02,  2.7248e-01,\n",
       "                        -2.7183e-02, -4.4552e-02, -5.2526e-02, -2.5530e-01,  2.8846e-01,\n",
       "                         9.1139e-02,  1.5048e-01,  1.5320e-01, -2.8289e-01, -2.7031e-01,\n",
       "                         2.0483e-02,  2.7415e-01,  5.1023e-02,  8.7036e-02, -2.2413e-01],\n",
       "                       [ 2.2805e-01, -1.1538e-01,  9.4764e-02,  3.4711e-01,  7.7550e-01,\n",
       "                         5.8900e-02, -1.9487e-02, -1.0293e-01, -5.4350e-02,  1.8351e-01,\n",
       "                         8.3878e-02, -2.0707e-01,  1.4782e-01, -1.9700e-01,  6.0417e-02,\n",
       "                        -4.6015e-02,  3.0114e-01, -1.8488e-01,  6.9156e-01,  2.8695e-02],\n",
       "                       [ 2.8831e-01,  1.1118e-01, -1.3547e-01,  1.3445e-02, -6.0277e-02,\n",
       "                        -1.0370e-01,  2.1195e-01,  2.5929e-01,  2.2021e-02, -7.9157e-02,\n",
       "                        -1.4227e-02, -1.6277e-01, -2.3921e-01, -8.0978e-02,  1.2060e-01,\n",
       "                         6.1001e-02, -2.7996e-01,  1.3202e-01, -2.7722e-02, -1.6744e-01],\n",
       "                       [-1.0234e-01,  3.0094e-01,  2.4197e-01,  2.5098e-01,  1.8012e-01,\n",
       "                        -2.6038e-01,  4.7207e-02, -1.1733e-01,  1.0314e-01, -6.1363e-03,\n",
       "                         2.8077e-01,  1.5512e-01, -3.3448e-03, -1.4680e-01, -2.6779e-01,\n",
       "                         6.9238e-02,  1.3527e-01, -1.1333e-02,  6.9296e-02, -1.5732e-02],\n",
       "                       [ 1.0488e-01,  2.0894e-01,  1.4448e-01, -3.0119e-01, -2.9130e-01,\n",
       "                        -5.1890e-02,  1.2538e-01,  1.0576e-01,  2.5289e-02,  1.0628e-01,\n",
       "                        -1.8230e-02, -2.2964e-01, -1.6166e-01, -1.0437e-01,  1.7462e-01,\n",
       "                        -2.3135e-01, -3.3785e-01,  2.2167e-01, -3.6465e-01,  9.3996e-02],\n",
       "                       [-9.0074e-02,  2.2013e-01,  7.5357e-02,  2.8748e-02, -1.6197e-02,\n",
       "                        -9.8003e-03, -1.4431e-01, -1.7910e-01, -1.6276e-01, -1.6747e-01,\n",
       "                        -2.1451e-01, -8.9980e-02,  2.7030e-02,  1.1659e-01, -9.8060e-02,\n",
       "                        -1.6066e-01, -4.8588e-02, -6.8343e-02, -2.6523e-01,  2.5000e-02],\n",
       "                       [-1.8313e-01, -8.5895e-02,  3.3087e-03, -1.4347e-01, -9.6235e-01,\n",
       "                        -1.6442e-01, -2.0016e-01, -1.1654e-01, -1.9694e-01, -1.0131e-01,\n",
       "                        -3.0473e-02,  2.4898e-01, -1.5159e-01,  5.4359e-02, -6.5306e-02,\n",
       "                        -8.3401e-02,  5.5218e-02,  4.6606e-02, -6.9580e-01, -6.7741e-02],\n",
       "                       [ 4.5824e-02,  2.6612e-01,  2.6686e-01,  6.5445e-02,  6.3460e-02,\n",
       "                         3.6434e-04, -8.1413e-03, -2.2017e-01, -5.3775e-02, -9.7738e-02,\n",
       "                         1.7340e-01,  1.9737e-01,  1.9813e-02, -1.2859e-01, -7.4945e-02,\n",
       "                         1.7907e-01, -3.4671e-02, -1.7175e-01,  3.9121e-02,  3.6619e-02],\n",
       "                       [-1.3200e-01, -1.6711e-02, -2.9141e-01,  2.3030e-02, -2.4247e-01,\n",
       "                         3.7830e-02, -1.4221e-01, -9.4749e-02, -4.8243e-02, -7.6822e-02,\n",
       "                        -3.0636e-01, -2.6518e-01, -2.8110e-01,  1.6054e-01,  1.9030e-01,\n",
       "                         2.0323e-02, -2.0247e-01,  1.9769e-01, -3.3526e-01,  1.1020e-01],\n",
       "                       [-1.0044e-01, -1.2247e-01, -1.1491e-01,  2.6499e-01,  4.3076e-01,\n",
       "                         2.8609e-01,  1.4432e-02, -7.4191e-02,  6.7525e-03,  1.4154e-01,\n",
       "                        -1.6871e-02,  1.3989e-01, -1.4378e-01,  4.7743e-02,  1.9315e-01,\n",
       "                         1.0517e-01,  2.4561e-01,  1.9566e-01,  2.0658e-01,  1.4872e-02]])),\n",
       "              ('backbone5.model.layer1.fc1.bias',\n",
       "               tensor([-0.2631,  0.1011,  0.0226, -0.0767, -0.1138, -0.1896, -0.2138,  0.2473,\n",
       "                       -0.0458,  0.0969, -0.0263, -0.0581,  0.1287,  0.0019,  0.0008, -0.0516,\n",
       "                        0.1361, -0.0394,  0.2721, -0.1935])),\n",
       "              ('backbone5.model.layer2.fc2.weight',\n",
       "               tensor([[ 1.3769e-01,  1.6466e-01,  9.3869e-02,  1.7938e-01,  8.8169e-02,\n",
       "                        -3.3388e-02,  5.7803e-02, -9.0709e-02,  1.1618e-01, -6.4038e-02,\n",
       "                        -3.2304e-02, -1.1077e-01, -3.8832e-02, -4.1401e-03, -1.7448e-01,\n",
       "                         1.8057e-01, -8.1677e-02, -2.6268e-02,  6.2313e-02,  1.3487e-01],\n",
       "                       [ 2.9880e-02, -7.9397e-02, -8.4759e-02,  9.1379e-03,  1.3440e-01,\n",
       "                        -2.3929e-01,  8.3201e-03,  1.0308e-01, -1.9948e-01,  2.7835e-01,\n",
       "                        -8.9155e-02,  1.9151e-01, -1.0310e-01,  5.4061e-02,  1.9139e-01,\n",
       "                         1.2377e-01,  2.5547e-01, -2.6869e-01, -2.5794e-02,  1.1592e-01],\n",
       "                       [-2.3690e-01, -3.9192e-01,  4.6895e-02,  1.5956e-01, -1.9920e-01,\n",
       "                        -1.5790e-01,  1.8697e-02,  4.1344e-02, -1.1710e-01,  2.3835e-01,\n",
       "                        -1.4636e-01,  1.6821e-01,  2.4826e-01, -1.8777e-01,  2.0403e-01,\n",
       "                         6.1774e-02,  2.8723e-02, -2.7139e-01,  2.1042e-01, -2.8843e-02],\n",
       "                       [ 1.8692e-01,  3.0819e-01,  9.7014e-02,  1.2548e-01, -2.2956e-01,\n",
       "                        -3.6789e-02, -1.7039e-03, -2.1450e-01,  2.5082e-01, -2.4531e-01,\n",
       "                         1.1739e-01,  6.2323e-02,  1.7522e-02,  8.4113e-02, -1.3459e-02,\n",
       "                         4.3060e-02, -1.1414e-01, -1.4998e-01, -7.7279e-02,  3.6190e-02],\n",
       "                       [-2.0103e-01,  3.6693e-01,  2.7262e-01,  1.0824e-01,  8.0966e-02,\n",
       "                         2.1883e-01, -1.8261e-01,  1.3127e-02,  1.0647e-01,  1.4460e-01,\n",
       "                        -1.5172e-01, -4.3421e-02,  1.4091e-01, -6.9462e-02, -9.4317e-02,\n",
       "                        -1.4059e-01, -8.6334e-02,  7.2310e-02, -1.0079e-01, -5.1342e-04],\n",
       "                       [-2.0135e-01, -2.1936e-01,  1.2110e-01,  8.7682e-02, -1.2891e-01,\n",
       "                         9.6020e-03, -6.9035e-02,  7.8983e-03, -2.3998e-01,  1.9988e-01,\n",
       "                        -1.8076e-01, -1.8517e-01,  1.0878e-01, -2.3488e-01,  2.0699e-01,\n",
       "                         1.3498e-01, -9.5915e-02, -1.3599e-01, -6.6104e-02, -1.8222e-01],\n",
       "                       [-2.6355e-01, -1.1622e-01, -1.0208e-01,  4.7038e-02, -1.7017e-01,\n",
       "                        -9.7557e-02,  1.2934e-01, -8.9710e-02, -1.3530e-01,  3.1935e-01,\n",
       "                        -3.1423e-01, -2.3269e-01,  8.6900e-02, -2.0992e-01,  1.4011e-01,\n",
       "                        -1.8650e-02,  1.5256e-02, -7.2566e-02,  1.6519e-01,  3.0188e-02],\n",
       "                       [-6.6214e-02, -2.1210e-01, -7.7903e-02,  1.6086e-01, -1.4635e-01,\n",
       "                        -1.3574e-01, -9.8330e-02,  1.4111e-01, -3.3800e-01,  2.9214e-01,\n",
       "                        -8.0595e-02, -1.4735e-01,  3.0092e-01, -3.1356e-01,  9.1362e-02,\n",
       "                        -3.4371e-02, -3.7557e-02,  3.1281e-02,  2.3083e-01, -9.3510e-02],\n",
       "                       [-8.5990e-02, -3.4337e-01, -2.3291e-01, -2.6899e-02,  5.1531e-02,\n",
       "                         1.0808e-01, -1.4785e-01,  2.3426e-01, -2.2443e-01,  1.5948e-01,\n",
       "                        -2.6320e-01, -1.4684e-01,  1.8205e-01,  1.7523e-01, -1.3182e-01,\n",
       "                         1.0661e-01, -1.0856e-02, -2.1434e-01,  1.5034e-01,  1.5320e-01],\n",
       "                       [-1.0007e-01, -3.9302e-01,  1.4750e-01, -9.0898e-02, -7.6431e-02,\n",
       "                         1.2054e-01, -2.0532e-01,  2.5051e-01,  1.0878e-01,  1.8615e-01,\n",
       "                         3.0873e-03, -1.8507e-02,  2.6438e-01,  1.4272e-03, -1.0131e-01,\n",
       "                        -4.0072e-02,  7.5765e-02,  9.0614e-02,  1.2097e-01, -1.6663e-01],\n",
       "                       [ 2.4378e-01,  1.2547e-01, -1.0522e-01,  5.8068e-02,  8.3784e-02,\n",
       "                         2.8155e-01,  2.4319e-01, -1.4432e-01,  1.1884e-01, -2.7897e-01,\n",
       "                         3.1658e-01,  1.3521e-01, -3.2571e-01,  2.9730e-01, -1.3840e-01,\n",
       "                        -1.7696e-01,  8.2192e-02,  7.6400e-02,  1.1191e-01, -1.2716e-01],\n",
       "                       [ 1.0354e-01,  3.6488e-01,  1.0362e-01,  5.1887e-02,  1.3252e-01,\n",
       "                         1.7027e-01, -8.5865e-02, -7.4437e-02, -9.9894e-02, -1.4160e-01,\n",
       "                         3.3386e-02,  7.5019e-03, -1.5649e-01,  1.6472e-01, -9.7205e-02,\n",
       "                         1.0358e-01, -8.0329e-02,  2.4819e-01, -9.2505e-02, -1.9114e-01],\n",
       "                       [-3.9409e-02,  8.2099e-02,  1.8358e-01,  2.2666e-01,  3.0313e-02,\n",
       "                         1.8753e-01, -1.2426e-01,  1.5918e-01,  2.1757e-01,  1.2972e-01,\n",
       "                         9.4690e-02, -6.8963e-02, -1.2131e-01, -1.4669e-01, -1.6337e-01,\n",
       "                        -5.7697e-02, -2.2464e-01,  1.7814e-01, -1.4430e-01,  1.7374e-01],\n",
       "                       [ 4.0787e-02, -9.5070e-02, -2.8697e-01, -2.5010e-01,  2.1537e-02,\n",
       "                        -6.4608e-02,  1.3031e-01,  8.7757e-02, -5.1490e-02,  5.0236e-02,\n",
       "                        -2.1995e-01, -1.7375e-01,  1.3222e-01, -2.1906e-01, -1.8717e-01,\n",
       "                        -3.3100e-02,  7.8346e-02, -8.0232e-05,  3.1881e-02, -6.7757e-02],\n",
       "                       [ 2.7307e-02, -1.8605e-01, -5.3608e-02, -1.4263e-01, -1.7040e-01,\n",
       "                        -3.8929e-01, -2.0822e-01,  4.0564e-01, -1.3331e-01,  5.0840e-03,\n",
       "                        -3.7948e-01,  9.8513e-02,  1.2059e-01, -1.1815e-01,  2.5707e-01,\n",
       "                        -7.4884e-02, -1.1248e-01, -3.3523e-01,  1.4714e-01, -2.2307e-01],\n",
       "                       [-5.0273e-02, -1.2439e-01, -3.4594e-01, -7.6813e-02, -2.0013e-02,\n",
       "                         8.8021e-02,  1.8054e-01, -2.2140e-01,  1.3777e-01,  1.3200e-01,\n",
       "                        -9.7025e-02, -5.6721e-02, -6.5718e-02,  2.0756e-01, -1.2111e-01,\n",
       "                         5.2858e-02,  4.0964e-01, -6.0953e-02,  9.9145e-03, -3.1351e-01],\n",
       "                       [-5.6095e-02, -3.8441e-01, -2.0884e-01, -8.1366e-02,  1.4192e-01,\n",
       "                         1.0557e-01, -2.0137e-01,  1.1974e-02, -1.0531e-01,  1.8079e-01,\n",
       "                        -2.3616e-01,  2.2079e-01,  6.9268e-02, -1.4007e-01, -1.7389e-01,\n",
       "                        -1.2530e-01,  2.2047e-01, -2.7291e-01,  3.1979e-01, -9.7168e-02],\n",
       "                       [ 2.0714e-01,  1.0877e-01,  3.1467e-01, -1.7346e-01, -1.4058e-01,\n",
       "                        -3.7068e-02, -5.9266e-03, -6.1587e-02,  8.7489e-02,  8.3994e-02,\n",
       "                         1.8005e-01, -6.3705e-02,  1.5905e-02,  9.2464e-02,  5.5687e-02,\n",
       "                        -3.3063e-02, -1.9748e-01,  1.7050e-01, -2.0583e-01,  2.5328e-01],\n",
       "                       [-6.7697e-02,  2.9171e-01,  1.5628e-01,  1.0397e-01,  6.9461e-02,\n",
       "                         1.3607e-01, -1.1177e-01,  4.5862e-02, -2.1373e-01, -4.5530e-02,\n",
       "                        -1.2411e-01,  1.1612e-01,  8.1385e-02,  2.0983e-03, -2.1430e-02,\n",
       "                        -1.0821e-01, -1.8800e-01, -2.5611e-01,  2.1496e-01,  5.5941e-02],\n",
       "                       [ 3.6350e-02,  3.9847e-01, -7.5117e-02,  1.7052e-01,  7.9287e-02,\n",
       "                         1.5514e-01, -8.0477e-02, -3.0839e-01, -4.6266e-02,  4.0350e-02,\n",
       "                         3.1614e-01,  1.2727e-01, -3.3156e-01,  1.3998e-01,  8.4537e-02,\n",
       "                         7.2477e-03, -1.4181e-01,  1.4567e-01, -1.8888e-02,  5.1584e-02]])),\n",
       "              ('backbone5.model.layer2.fc2.bias',\n",
       "               tensor([-0.2620,  0.2337,  0.0914, -0.0255, -0.1457, -0.1662,  0.2338,  0.3685,\n",
       "                       -0.0235,  0.2602,  0.0646, -0.0876,  0.1871,  0.2804,  0.2682, -0.1177,\n",
       "                        0.0967,  0.2371, -0.0124, -0.2530])),\n",
       "              ('backbone5.model.layer3.fc3.weight',\n",
       "               tensor([[ 0.1591, -0.0695,  0.2839, -0.0556, -0.2360,  0.2311,  0.2542,  0.1977,\n",
       "                         0.1215,  0.2423, -0.0233, -0.0777, -0.2607,  0.4375,  0.2146, -0.0718,\n",
       "                         0.2925, -0.0853, -0.2214, -0.1931],\n",
       "                       [ 0.1581, -0.1626,  0.0646,  0.1431,  0.1789, -0.1807, -0.2503, -0.1677,\n",
       "                        -0.0980, -0.0274,  0.1714,  0.1578,  0.2878, -0.0812, -0.3171, -0.2272,\n",
       "                        -0.2334,  0.2491, -0.0965,  0.0259],\n",
       "                       [ 0.0639,  0.1196, -0.0966, -0.0305, -0.4074,  0.1918, -0.0091,  0.2778,\n",
       "                        -0.0931,  0.1179, -0.2782, -0.1259, -0.2052,  0.1740,  0.4312,  0.2419,\n",
       "                         0.3413,  0.0498, -0.0131, -0.1366],\n",
       "                       [-0.2133,  0.1052,  0.0528, -0.0488, -0.0628,  0.3041, -0.0841,  0.2160,\n",
       "                         0.2666, -0.0012,  0.0775, -0.0355, -0.2693,  0.1563,  0.4399,  0.2407,\n",
       "                         0.3495, -0.1856, -0.1724, -0.1962],\n",
       "                       [ 0.1150, -0.1202, -0.0884,  0.1576,  0.2256, -0.0917, -0.2350, -0.1269,\n",
       "                        -0.1512, -0.1416,  0.1984,  0.1770,  0.2933, -0.1995, -0.4805, -0.2432,\n",
       "                        -0.1436,  0.2305, -0.1883,  0.1186],\n",
       "                       [-0.1867,  0.1565, -0.0932, -0.1830, -0.3269,  0.2519, -0.0477,  0.1364,\n",
       "                         0.0664,  0.2438, -0.2763, -0.0064, -0.1582,  0.3677,  0.1398,  0.3049,\n",
       "                         0.2634,  0.0910,  0.0045, -0.1539],\n",
       "                       [-0.2203,  0.1364,  0.1715,  0.0082, -0.3227, -0.0806,  0.2026,  0.3084,\n",
       "                         0.2196,  0.0022, -0.2129, -0.0120, -0.1919,  0.1249,  0.2657,  0.1057,\n",
       "                         0.4665, -0.0845,  0.0893, -0.0212],\n",
       "                       [ 0.0973, -0.2702,  0.0733,  0.3114,  0.0078, -0.3866, -0.2138, -0.2667,\n",
       "                        -0.0251,  0.0654, -0.0416,  0.0740,  0.3172, -0.2973, -0.3202, -0.1764,\n",
       "                        -0.5757,  0.0962, -0.0994,  0.3373],\n",
       "                       [-0.2777, -0.0041,  0.0374,  0.0255, -0.0774,  0.0877, -0.1230,  0.3692,\n",
       "                         0.2822,  0.2071, -0.2919, -0.2505, -0.2450,  0.1820,  0.2106,  0.3472,\n",
       "                         0.4908,  0.0262, -0.0470, -0.0802],\n",
       "                       [ 0.1097, -0.3352, -0.2473,  0.0623,  0.0877, -0.2425,  0.0749, -0.3413,\n",
       "                        -0.1055, -0.1928, -0.0253,  0.0915,  0.2443, -0.4396, -0.3992,  0.0206,\n",
       "                        -0.4372,  0.2955,  0.0407,  0.1268],\n",
       "                       [ 0.0439, -0.2290, -0.1323,  0.0329,  0.1707, -0.2632, -0.0149, -0.0481,\n",
       "                         0.0413, -0.0689, -0.1457, -0.0946,  0.2990, -0.3779, -0.1901, -0.2537,\n",
       "                        -0.1405,  0.1231,  0.2893,  0.0579],\n",
       "                       [ 0.0715,  0.0622,  0.0996, -0.1538, -0.0805,  0.2509,  0.1815, -0.0007,\n",
       "                         0.2485, -0.0307, -0.1131, -0.0872, -0.0242,  0.3060,  0.3131,  0.4162,\n",
       "                         0.5260, -0.0275,  0.0456, -0.3058],\n",
       "                       [ 0.2294,  0.1069,  0.0243,  0.2630,  0.2908, -0.1608, -0.2202, -0.1553,\n",
       "                         0.1390, -0.2126,  0.0791,  0.0682,  0.0207, -0.2939, -0.2433, -0.3160,\n",
       "                        -0.5493, -0.0452, -0.1256,  0.1308],\n",
       "                       [-0.0478,  0.0451, -0.1125,  0.2558,  0.1848, -0.2746,  0.1063, -0.2410,\n",
       "                         0.1807, -0.1165, -0.1668,  0.2335,  0.3314,  0.0260, -0.0632, -0.3964,\n",
       "                        -0.4285,  0.1117,  0.2416,  0.0222],\n",
       "                       [-0.0830, -0.3286, -0.2870, -0.0297,  0.2883, -0.2658,  0.0888, -0.0822,\n",
       "                        -0.0484,  0.0873, -0.0868,  0.1259,  0.3387, -0.4978, -0.1597, -0.0139,\n",
       "                        -0.5976,  0.0158, -0.0720,  0.2396],\n",
       "                       [ 0.1816, -0.1546, -0.1716, -0.0343,  0.1130, -0.1108, -0.1715,  0.0701,\n",
       "                         0.1571, -0.1745,  0.2714,  0.2352,  0.2598, -0.3152, -0.4447, -0.3061,\n",
       "                        -0.3742, -0.0627,  0.1767, -0.0396],\n",
       "                       [-0.1402, -0.0100,  0.0046, -0.2263, -0.3452,  0.2161,  0.1898,  0.2365,\n",
       "                        -0.0607,  0.1405, -0.2169, -0.1986, -0.1581,  0.2482,  0.3292,  0.1041,\n",
       "                         0.5678,  0.1003,  0.1236, -0.0938],\n",
       "                       [-0.0759,  0.1107,  0.2269, -0.1769, -0.3949,  0.3012, -0.1525,  0.1728,\n",
       "                         0.0634,  0.0736,  0.0228, -0.1295, -0.3529,  0.0434,  0.1570,  0.0432,\n",
       "                         0.1946, -0.2536, -0.0822, -0.1357],\n",
       "                       [ 0.0392,  0.0956, -0.1278, -0.1767, -0.4233,  0.0555, -0.1155, -0.0011,\n",
       "                         0.0530,  0.1328,  0.1166, -0.2291, -0.0788,  0.2312,  0.3241,  0.1215,\n",
       "                         0.2047, -0.1735, -0.2600, -0.1815],\n",
       "                       [-0.0673, -0.2965, -0.2885,  0.1112,  0.0464, -0.3713, -0.2678, -0.4026,\n",
       "                        -0.2613,  0.1204,  0.2478, -0.0428,  0.1799, -0.1990, -0.1302, -0.0285,\n",
       "                        -0.3404,  0.1204,  0.1410,  0.3195]])),\n",
       "              ('backbone5.model.layer3.fc3.bias',\n",
       "               tensor([ 0.0379,  0.0271,  0.0630, -0.1325,  0.1479, -0.0621,  0.2149, -0.2364,\n",
       "                       -0.0428, -0.1054,  0.0778,  0.1492, -0.1483, -0.0166,  0.1350,  0.1540,\n",
       "                        0.1584,  0.0526,  0.1568,  0.1304])),\n",
       "              ('backbone5.model.layer4.fc4.weight',\n",
       "               tensor([[ 0.8279, -0.9207,  0.6507,  0.5568, -0.8408,  0.9488,  0.4712, -0.5275,\n",
       "                         0.7444, -0.6168, -0.7235,  0.7771, -0.7329, -0.8421, -0.5177, -0.8319,\n",
       "                         0.5424,  0.8106,  0.9045, -0.9435]]))])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(\"./logger.npy\", logger)\n",
    "model_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd0b02",
   "metadata": {},
   "source": [
    "# LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b19af636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LBFGS训练\"\"\"\n",
    "start_time = time.time()\n",
    "\n",
    "dataset = Dataset(domain)\n",
    "X_res, X_ics = dataset.train_data()\n",
    "X_res = torch.from_numpy(X_res).float().to(device)\n",
    "X_ics = torch.from_numpy(X_ics).float().to(device)\n",
    "\n",
    "mu = X_res.mean(dim=0)\n",
    "sigma = X_res.std(dim=0)  # 求样本标准差\n",
    "\n",
    "backbone1 = MLP(backbone_layers)  # 主干网络\n",
    "backbone2 = MLP(backbone_layers)\n",
    "backbone3 = MLP(backbone_layers)\n",
    "backbone4 = MLP(backbone_layers)\n",
    "backbone5 = MLP(backbone_layers)\n",
    "pinn = PINN(backbone1, backbone2, backbone3, backbone4, backbone5, mu, sigma).to(device)\n",
    "\n",
    "optimizer_lbfgs = optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "\n",
    "lr_sche = optim.lr_scheduler.ExponentialLR(optimizer_adam, gamma=0.8)  # 指数衰减学习率\n",
    "\n",
    "model_state = torch.load(os.path.join(model_path, 'pinn_adam.pth'))\n",
    "pinn.load_state_dict(model_state['backbone_state'])\n",
    "\n",
    "optimizer_lbfgs = optim.LBFGS(pinn.parameters(), max_iter=50000, line_search_fn=\"strong_wolfe\",tolerance_grad=1e-5)\n",
    "\n",
    "loss_log_lbfgs = []\n",
    "it = 0\n",
    "with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "    f.write('Training by LBFGS:\\n')\n",
    "\n",
    "def closure():\n",
    "    global it, best_loss, adam_iters\n",
    "    pinn.zero_grad()\n",
    "    \n",
    "    loss_res_1, loss_res_2, loss_res_3, loss_res_4, loss_res_5, loss_ics   = pinn(X_res, X_ics)\n",
    "    loss = loss_res_1 + loss_res_2 + loss_res_3 +loss_res_4 + loss_res_5 + loss_ics \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    loss_log_lbfgs.append(loss.item())\n",
    "    if (it + 1) % 100 == 0:\n",
    "        pinn.train(False)  # 验证 -------\n",
    "        pinn.train(False)\n",
    "        loss_res_1_valid, loss_res_2_valid, loss_res_3_valid, loss_res_4_valid, loss_res_5_valid, loss_ics_valid  = pinn(X_res, X_ics)\n",
    "        loss_valid = loss_res_1_valid + loss_res_2_valid + loss_res_3_valid + loss_res_4_valid + loss_res_4_valid + loss_ics_valid\n",
    "        \n",
    "        logger[\"loss\"].append(loss_valid.item())\n",
    "        logger[\"loss_res_1\"].append(loss_res_1_valid.item())\n",
    "        logger[\"loss_res_2\"].append(loss_res_2_valid.item())\n",
    "        logger[\"loss_res_3\"].append(loss_res_3_valid.item())\n",
    "        logger[\"loss_res_4\"].append(loss_res_4_valid.item())\n",
    "        logger[\"loss_res_5\"].append(loss_res_5_valid.item())\n",
    "        logger[\"loss_ics\"].append(loss_ics_valid.item())\n",
    "        logger[\"iter\"].append(it+1)\n",
    "        \n",
    "        info = f'Iter # {it+1:6d}/{adam_iters}\\t' + \\\n",
    "                f'loss:{loss.item():.2e}, loss_r_1:{loss_res_1.item():.2e}, loss_r_2:{loss_res_2.item():.2e}, loss_r_3:{loss_res_3.item():.2e},loss_r_4:{loss_res_4.item():.2e},loss_r_5:{loss_res_5.item():.2e} loss_i:{loss_ics.item():.2e}  ' + \\\n",
    "                f'Valid # loss:{loss_valid.item():.2e}, loss_r:{loss_res_1_valid.item():.2e}, loss_i:{loss_ics_valid.item():.2e}'\n",
    "        with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "            f.write(info + '\\n')\n",
    "        print(info)\n",
    "        if loss_valid.item() < best_loss:  # 保存训练loss最低的模型 -------\n",
    "            model_state = {'backbone_dict': pinn.state_dict()}\n",
    "            torch.save(model_state, os.path.join(model_path, f'pinn_lbfgs.pth'))\n",
    "            best_loss = loss.item()\n",
    "    it = it + 1\n",
    "    return loss\n",
    "\n",
    "optimizer_lbfgs.step(closure)\n",
    "\n",
    "model_state = {'backbone_state': pinn.state_dict()}\n",
    "backbone_path = os.path.join(model_path, f'pinn_lbfgs.pth')\n",
    "torch.save(model_state, backbone_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158dd93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = np.load(\"./logger.npy\", allow_pickle=True).item()\n",
    "k = 2\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.subplot(111)\n",
    "    # plt.plot(logger[\"iter\"][::k], logger[\"loss\"][::k], label=r\"$L$\")\n",
    "    plt.plot(logger[\"iter\"][::k], logger[\"loss_res_1\"][::k], label=r\"$\\mathcal{L}_{r}$\", linewidth=3)\n",
    "    plt.plot(logger[\"iter\"][::k], logger[\"loss_ics\"][::k], label=r\"$\\mathcal{L}_{data}$\", linewidth=3)\n",
    "    plt.legend()\n",
    "    plt.xticks([0, 5000, 10000, 15000, 20000])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig('loss.png', dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c639cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2, 5)\n",
      "[[-0.00388712]\n",
      " [-0.0038723 ]\n",
      " [-0.00385751]\n",
      " ...\n",
      " [-0.00255739]\n",
      " [-0.00254595]\n",
      " [-0.0025346 ]]\n"
     ]
    }
   ],
   "source": [
    "# 导入模型参数\n",
    "mu = logger[\"mu\"].cpu()\n",
    "sigma = logger[\"sigma\"].cpu()\n",
    "\n",
    "backbone1 = MLP(backbone_layers)  # 主干网络\n",
    "backbone2 = MLP(backbone_layers) \n",
    "backbone3 = MLP(backbone_layers) \n",
    "backbone4 = MLP(backbone_layers) \n",
    "backbone5 = MLP(backbone_layers) \n",
    "pinn = PINN(backbone1,backbone2,backbone3,backbone4,backbone5, mu, sigma)\n",
    "\n",
    "model_state = torch.load(os.path.join(model_path, 'pinn_adam.pth'))\n",
    "pinn.load_state_dict(model_state['backbone_state'])\n",
    "pinn.eval()\n",
    "\n",
    "# 生成网格\n",
    "t_res = np.linspace(tmin, tmax, 100)\n",
    "x_res = np.linspace(xmin, xmax, 100)\n",
    "X_res = dataset.sample_xy(t_res, x_res)\n",
    "\n",
    "X_res = np.expand_dims(X_res, axis=2)\n",
    "X_res = np.repeat(X_res,5,axis=2)\n",
    "print(X_res.shape)\n",
    "\n",
    "X_res = torch.from_numpy(X_res).double()\n",
    "pinn = pinn.cpu().double()\n",
    "X1_pred,X2_pred,X3_pred,X4_pred,X5_pred = pinn.net_X_res_pred(X_res)\n",
    "\n",
    "X1_pred = X1_pred.detach().numpy()\n",
    "X2_pred = X2_pred.detach().numpy()\n",
    "X3_pred = X3_pred.detach().numpy()\n",
    "X4_pred = X4_pred.detach().numpy()\n",
    "X5_pred = X5_pred.detach().numpy()\n",
    "\n",
    "print(X1_pred)\n",
    "# X1_error = np.linalg.norm(X1_pred - X1_star) / np.linalg.norm(X1_star) \n",
    "# print('Relative l2 error of u: {:.3e}'.format(u_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da50d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.rcParams.update({'font.size':18})\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    fig = plt.figure(figsize=(16, 5))\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    plt.plot(t_res, X1_pred[::100], linewidth=3)\n",
    "#     plt.scatter(X1_pred[:,0], X1_pred[:,1])\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('X1')\n",
    "#     plt.xticks([0, 1, 2, 3, 4])\n",
    "    plt.legend(loc='upper right', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    ax.set_aspect(1./ax.get_data_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468bda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
