{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d2238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "from pyDOE import lhs\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "plt.rcParams.update({'font.size':18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f50a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1024):\n",
    "    #     random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9dccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = (0, 1, -1, 1)\n",
    "tmin, tmax, xmin, xmax = domain\n",
    "mlp_layers = [2] + [50]*5 + [1]\n",
    "# adam_iters = 40000\n",
    "adam_iters = 40000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = r'./model'\n",
    "train_info_path = r'./'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb215911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2) (50, 2) (50, 2) (100, 2) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, domain):\n",
    "        self.domain = domain\n",
    "        self.lb = np.array([tmin, xmin])\n",
    "        self.ub = np.array([tmax, xmax])\n",
    "\n",
    "    def train_data(self, verbose=None):\n",
    "        tmin, tmax, xmin, xmax = self.domain\n",
    "        # 内部点采样\n",
    "        t_res = np.linspace(tmin, tmax, 50)\n",
    "        x_res = np.linspace(xmin, xmax, 80)\n",
    "        X_res = self.sample_xy(t_res, x_res)\n",
    "        \n",
    "        # 初始点采样\n",
    "        X_bcs = np.array([]).reshape((-1, 2))\n",
    "        X_bcs_l = np.concatenate([X_bcs, self.sample_xy(np.linspace(tmin, tmax, 50), np.array([xmin]))], axis=0)\n",
    "        X_bcs_u = np.concatenate([X_bcs, self.sample_xy(np.linspace(tmin, tmax, 50), np.array([xmax]))], axis=0)\n",
    "        \n",
    "        # 边界点采样\n",
    "        X_ics =self.sample_xy(np.array([tmin]), np.linspace(xmin, xmax, 100))\n",
    "        \n",
    "        u_ics = self.u_ics_sol(X_ics)\n",
    "\n",
    "        return X_res, X_bcs_l, X_bcs_u, X_ics, u_ics\n",
    "\n",
    "\n",
    "    def sample_xy(self, x, y):\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        X = np.concatenate([xx.reshape((-1, 1)), yy.reshape((-1, 1))], axis=1)\n",
    "        return X\n",
    "    \n",
    "    def u_ics_sol(self, X):\n",
    "        return X[:, [1]]**2 * np.sin(2*np.pi * X[:, [1]])\n",
    "    \n",
    "    def lhs_sample_xy(self, n=10000):\n",
    "        X = (self.ub - self.lb) * lhs(2, n) + self.lb\n",
    "        return X\n",
    "    \n",
    "dataset = Dataset(domain)\n",
    "# 内部点与边界点\n",
    "X_res, X_bcs_l, X_bcs_u, X_ics, u_ics = dataset.train_data()\n",
    "print(X_res.shape,X_bcs_l.shape, X_bcs_u.shape, X_ics.shape, u_ics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7353ecb",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cafebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (fc1): Linear(in_features=2, out_features=50, bias=True)\n",
       "    (act1): Tanh()\n",
       "    (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (act2): Tanh()\n",
       "    (fc3): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (act3): Tanh()\n",
       "    (fc4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (act4): Tanh()\n",
       "    (fc5): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (act5): Tanh()\n",
       "    (fc6)): Linear(in_features=50, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, mlp_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        for i in range(len(mlp_layers) - 2):\n",
    "            self.model.add_module(f'fc{i + 1}', nn.Linear(mlp_layers[i], mlp_layers[i + 1], bias=True))\n",
    "            self.model.add_module(f'act{i + 1}', nn.Tanh())\n",
    "        self.model.add_module(f'fc{len(mlp_layers) - 1})', nn.Linear(mlp_layers[-2], mlp_layers[-1], bias=False))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "mlp = MLP(mlp_layers)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d19c76",
   "metadata": {},
   "source": [
    "## 主干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a0e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs,\n",
    "                               grad_outputs=torch.ones_like(outputs),\n",
    "                               create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd43469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, backbone, mu=None, sigma=None):\n",
    "        super(PINN, self).__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, X_res, X_bcs_l, X_bcs_u, X_ics, u_ics):\n",
    "        \n",
    "        loss_res = torch.mean(self.net_f(X_res) ** 2)\n",
    "        loss_ics = torch.mean((self.net_u(X_ics)-u_ics) ** 2)\n",
    "        loss_bcs = torch.mean((self.net_u(X_bcs_l)-self.net_u(X_bcs_u)) ** 2)\n",
    "        loss_bcs_t = torch.mean((self.net_u_x(X_bcs_l)-self.net_u_x(X_bcs_u)) ** 2)\n",
    "\n",
    "        return loss_res, loss_ics,loss_bcs,loss_bcs_t\n",
    "\n",
    "    def net_u(self, X):\n",
    "        return self.backbone(X)\n",
    "    \n",
    "    def net_u_x(self,X):\n",
    "        X.requires_grad_(True)\n",
    "        u = self.net_u(X)\n",
    "        \n",
    "        # 求梯度\n",
    "        grad_u = grad(u, X)[0]\n",
    "        u_x = grad_u[:, [1]]\n",
    "        return u_x\n",
    "\n",
    "    def net_f(self, X):\n",
    "        X.requires_grad_(True)\n",
    "        u = self.net_u(X)\n",
    "#         print(u.shape)\n",
    "        # 求梯度\n",
    "        grad_u = grad(u, X)[0]\n",
    "        u_t = grad_u[:, [0]]\n",
    "        u_x = grad_u[:, [1]]\n",
    "        u_tt = grad(u_t, X)[0][:, [0]]\n",
    "        u_xx = grad(u_x, X)[0][:, [1]]\n",
    "        \n",
    "        gamma1 = 0.0001\n",
    "        gamma2 = 4\n",
    "        \n",
    "        f = u_t - gamma1*u_xx + gamma2*u**3 - gamma2*u\n",
    "        return f  \n",
    "\n",
    "pinn = PINN(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09b7e9",
   "metadata": {},
   "source": [
    "## Resample策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8217dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_resample(dataset, net_f, device=torch.device('cuda'), n_total_points=4000, n_added_points=500):\n",
    "    # 生成待采样的点集\n",
    "    X_resam = dataset.lhs_sample_xy(n=n_total_points)\n",
    "    X_resam = torch.from_numpy(X_resam).float().to(device)\n",
    "    # 获得residule\n",
    "    f = net_f(X_resam)\n",
    "    f = f.detach().cpu().numpy()\n",
    "    # 依loss_res的值排序得到索引\n",
    "    idx = np.argsort(abs(f).flatten())[-n_added_points:]\n",
    "    return X_resam[idx].detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95020ce5",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73d1081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 2])\n",
      "torch.Size([4500, 2])\n",
      "torch.Size([4500, 2])\n",
      "torch.Size([5000, 2])\n",
      "torch.Size([5000, 2])\n",
      "torch.Size([5500, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-42d1b14ce8a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mpinn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mloss_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_ics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_bcs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_bcs_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_bcs_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_bcs_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_ics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_ics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_res\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_ics\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_bcs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_bcs_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-85ff79169237>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X_res, X_bcs_l, X_bcs_u, X_ics, u_ics)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_bcs_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_bcs_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_ics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_ics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mloss_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mloss_ics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_ics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mu_ics\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss_bcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_bcs_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_bcs_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-85ff79169237>\u001b[0m in \u001b[0;36mnet_f\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mu_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_u\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mu_tt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mu_xx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mgamma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-560cb275494f>\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     return torch.autograd.grad(outputs, inputs,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                create_graph=True)\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Dataset(domain)\n",
    "X_res, X_bcs_l, X_bcs_u, X_ics, u_ics = dataset.train_data()\n",
    "\n",
    "X_res = torch.from_numpy(X_res).float().to(device)\n",
    "X_bcs_l = torch.from_numpy(X_bcs_l).float().to(device)\n",
    "X_bcs_u = torch.from_numpy(X_bcs_u).float().to(device)\n",
    "X_ics = torch.from_numpy(X_ics).float().to(device)\n",
    "u_ics = torch.from_numpy(u_ics).float().to(device)\n",
    "\n",
    "mu = X_res.mean(dim=0)\n",
    "sigma = X_res.std(dim=0)  # 求样本标准差\n",
    "\n",
    "backbone = MLP(mlp_layers)  # 主干网络\n",
    "pinn = PINN(backbone, mu, sigma).to(device)\n",
    "\n",
    "optimizer_adam = optim.Adam(pinn.backbone.parameters(), lr=1e-3)\n",
    "\n",
    "lr_sche = optim.lr_scheduler.ExponentialLR(optimizer_adam, gamma=0.8)  # 指数衰减学习率\n",
    "\n",
    "logger = {\n",
    "    \"loss\": [], \n",
    "    \"loss_res\": [],\n",
    "    \"loss_ics\": [],\n",
    "    \"loss_bcs\": [],\n",
    "    \"loss_bcs_t\": [],\n",
    "    \"iter\": [],\n",
    "    \"mu\": mu,\n",
    "    \"sigma\": sigma\n",
    "}\n",
    "best_loss = 1e9\n",
    "\n",
    "# 训练\n",
    "start_time = time.time()\n",
    "for it in range(adam_iters):\n",
    "    pinn.train()\n",
    "    pinn.zero_grad()\n",
    "    \n",
    "    loss_res, loss_ics,loss_bcs,loss_bcs_t = pinn(X_res, X_bcs_l, X_bcs_u, X_ics, u_ics)\n",
    "    loss = 100*loss_res + 1000*loss_ics + 100*loss_bcs + loss_bcs_t\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_adam.step()\n",
    "    \n",
    "    if (it + 1) % 100 == 0:\n",
    "        # 保存loss信息\n",
    "        pinn.train(False)\n",
    "        loss_res_valid, loss_ics_valid, loss_bcs_valid, loss_bcs_t_valid = pinn(X_res, X_bcs_l, X_bcs_u, X_ics, u_ics)\n",
    "        loss_valid = loss_res_valid + loss_ics_valid + loss_bcs_valid + loss_bcs_t_valid\n",
    "        \n",
    "        logger[\"loss\"].append(loss_valid.item())\n",
    "        logger[\"loss_res\"].append(loss_res_valid.item())\n",
    "        logger[\"loss_ics\"].append(loss_ics_valid.item())\n",
    "        logger[\"loss_bcs\"].append(loss_bcs_valid.item())\n",
    "        logger[\"loss_bcs_t\"].append(loss_bcs_t_valid.item())\n",
    "        logger[\"iter\"].append(it+1)\n",
    "        \n",
    "        \n",
    "        # 保存训练loss最低的模型\n",
    "        if loss_valid.item() < best_loss:\n",
    "            model_state = {'iter': it+1, 'backbone_state': pinn.backbone.state_dict()}\n",
    "            torch.save(model_state, os.path.join(model_path, 'pinn_adam.pth'))\n",
    "            best_loss = loss_valid.item()\n",
    "        \n",
    "        if (it + 1) % 500 == 0:\n",
    "            # 保存并打印训练日志\n",
    "            info = f'Iter # {it+1:6d}/{adam_iters}\\t' + \\\n",
    "                f'loss:{loss.item():.2e}, loss_r:{loss_res.item():.2e}, loss_i:{loss_ics.item():.2e} , loss_b:{loss_bcs.item():.2e}, loss_b_t:{loss_bcs_t.item():.2e}  ' + \\\n",
    "                f'Valid # loss:{loss_valid.item():.2e}, loss_r:{loss_res_valid.item():.2e}, loss_i:{loss_ics_valid.item():.2e}, loss_b:{loss_bcs_valid.item():.2e}, loss_b_t:{loss_bcs_t_valid.item():.2e}'\n",
    "            with open(train_info_path + 'train_info.txt', 'a') as f:\n",
    "                f.write(info + '\\n')\n",
    "            print(info)\n",
    "            \n",
    "        # 衰减学习率\n",
    "        if (it + 1) % 4000 == 0:\n",
    "            lr_sche.step()\n",
    "            \n",
    "    if (it + 1) % 100 == 0:\n",
    "        pinn.zero_grad()\n",
    "        pinn.eval()\n",
    "        # 进行重采样\n",
    "        print(X_res.shape)\n",
    "        X_resam1 = easy_resample(dataset, pinn.net_f, device = device).float()\n",
    "        # 拼接数据\n",
    "        X_res = torch.cat([X_res, X_resam1], dim=0)\n",
    "        print(X_res.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01659246",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./logger.npy\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = np.load(\"./logger.npy\", allow_pickle=True).item()\n",
    "k = 2\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.subplot(111)\n",
    "    # plt.plot(logger[\"iter\"][::k], logger[\"loss\"][::k], label=r\"$L$\")\n",
    "    plt.plot(logger[\"iter\"][::k], logger[\"loss_res\"][::k], label=r\"$\\mathcal{L}_{r}$\", linewidth=3)\n",
    "    plt.plot(logger[\"iter\"][::k], logger[\"loss_ics\"][::k], label=r\"$\\mathcal{L}_{ics}$\", linewidth=3)\n",
    "    plt.legend()\n",
    "    plt.xticks([0, 5000, 10000, 15000, 20000])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig('loss.png', dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463cfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(tmin, tmax, 100)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "tt, xx = np.meshgrid(t, x)\n",
    "X = np.concatenate([tt.reshape((-1, 1)), xx.reshape((-1, 1))], axis=1)\n",
    "\n",
    "X = torch.from_numpy(X).float().to(device)\n",
    "\n",
    "u_pred = pinn.net_u(X).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.pcolor(tt, xx, u_pred.reshape(xx.shape), cmap='jet', vmin = -1, vmax =1)\n",
    "plt.colorbar()\n",
    "# plt.clim([-1., 1.])\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$x$')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_xticks(np.linspace(0, 1, 5))\n",
    "ax.set_yticks(np.linspace(-1, 1, 5))\n",
    "plt.title(r'Predicted $u(t,x)$')\n",
    "ax.set_aspect(1./ax.get_data_ratio())\n",
    "plt.tight_layout()\n",
    "plt.savefig('AC_pred_viridis.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6c765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
